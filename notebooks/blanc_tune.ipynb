{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d9f8b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b872e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('../datasets/DailyNews_300.json')\n",
    "print(data.shape)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "397b468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.features = self.dataset.columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.dataset.iloc[idx, 0], self.dataset.iloc[idx, 1], self.dataset.iloc[idx, 2])\n",
    "    \n",
    "    def map(self, preprocessing_fn, **kwargs):\n",
    "        return CustomDataset(self.dataset.apply(lambda x: preprocessing_fn(x, **kwargs), axis = 1))\n",
    "    \n",
    "    def select_columns(self, columns):\n",
    "        new_dataset = self.dataset[columns] \n",
    "        return CustomDataset(new_dataset)\n",
    "    \n",
    "    def get_sentences(self):\n",
    "        self.dataset['sentences'] = self.dataset['text'].apply(lambda x: x.split('.'))\n",
    "        return CustomDataset(self.dataset)\n",
    "    \n",
    "dataset = CustomDataset(data)\n",
    "dataset = dataset.get_sentences()\n",
    "# print(dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c34df281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_lengths(dataset, tokenizer):\n",
    "    word_lengths = {}\n",
    "    all_tokens = []\n",
    "\n",
    "    for sample in dataset:\n",
    "        summary = sample[0]\n",
    "        preprocessed_result = tokenizer(summary, \n",
    "                                        add_special_tokens = False,\n",
    "                                        truncation = True,\n",
    "                                        max_length = 512,\n",
    "                                        padding = False,\n",
    "                                        return_attention_mask = False)\n",
    "        tokens = preprocessed_result[\"input_ids\"]\n",
    "        decoded_tokens = tokenizer.convert_ids_to_tokens(tokens)\n",
    "        for token in tokens:\n",
    "            if token not in all_tokens:\n",
    "                all_tokens.append(token)\n",
    "\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            if decoded_tokens[i].startswith('##'):\n",
    "                combined_word = decoded_tokens[i - 1] + decoded_tokens[i][2:]\n",
    "                word_lengths[tokens[i - 1]] = len(combined_word)\n",
    "                word_lengths[tokens[i]] = len(combined_word)\n",
    "            else:\n",
    "                word_lengths[tokens[i]] = len(decoded_tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    assert len(all_tokens) == len(word_lengths), \"Association of tokens with word length : FAILED.\"\n",
    "\n",
    "    return word_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e993a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mario Mandzukic pounces to fire the ball past Jordan Pickford and put Croatia into the World Cup final', ' Photo: Reuters Independent', \"ie \\n \\nFormer England defender Gary Neville suggested Gareth Southgate's squad had done more than could have been expected of them at this World Cup as they bowed out with a semi-final defeat against Croatia\", ' \\n \\nhttps://www', 'independent', 'ie/sport/soccer/world-cup-2018/gary-neville-salutes-englands-overachievers-as-alan-shearer-and-rio-ferdinand-give-their-verdicts-37108667', 'html \\n \\nhttps://www', 'independent', 'ie/incoming/article37108634', 'ece/7571a/AUTOCROP/h342/52Man1', \"jpg \\n   Email     \\nFormer England defender Gary Neville suggested Gareth Southgate's squad had done more than could have been expected of them at this World Cup as they bowed out with a semi-final defeat against Croatia\", ' \\n  \\nA jaded England faded after had Kieran Trippier fired England ahead after just five minutes with a superb free-kick, with goals from Ivan Perisic and Mario Mandzukic earned Croatia a date with France after a 2-1 extra-time win in Moscow', ' \\n \\n\"The first thing to say is this team has taken us to a place we never imagined we could get,\" said Neville', ' \\n \\n\"I said before the tournament England never overachieve, this team has overachieved getting to the semi-final and they can all be absolutely proud', ' \\n \\n\"They have taken the nation with them', ' You see all the fans out in the park to see them', \" I never thought I'd see scenes like that in this World Cup\", ' \\n \\n\"They can be absolutely proud', ' We did say before the game these lads have to take this opportunity because it may never come again', ' \\n \\n\"All I hope as I look at them now crying, disappointed, upset is they get another opportunity as good as the one they\\'ve just had', '\" \\n \\n\"They\\'re the youngest team in the tournament', \" I hope they're in that position again, 1-0 up with 20 minutes to go with the opportunity of getting into a World Cup final\", '\" \\n  Croatia\\'s Dejan Lovren and Domagoj Vida celebrate after the match', \" Photo: Reuters   \\nFormer England defender Rio Ferdinand believes the youthful nature of England's squad proved to be their undoing in the semi-final\", ' \\n \\n\"I think experience was a telling factor today,\" Ferdinand told the BBC', ' \"This Croatian team had medals all over the squad but now is not the time to knitpick', \" This bunch of players have brought the nation together and the fans haven't sung like this for years\", ' \\n \\n\"We wanted this team to come out with an identity and a philosophy of playing, and I think they have done that', \" Where we were sat in the stadium, people around us were impressed with England's football and their ability to play out from the back\", ' \\n \\n\"Kieran Trippier\\'s delivery of the ball was brilliant and what a tournament he has had', ' There were question marks over Jordan Pickford but he was the best choice in goal and this team can develop into something very strong', ' I have been an admirer of John Stones for a long time, and he defended unbelievably today', ' We have got a very inexperienced young squad but they have grown and will continue to do so', '\" \\n \\nEx-England striker Alan Shearer also tried to find the positives amid England\\'s anguish', ' \\n \\n\"We said before the tournament that if they gave absolutely everything in every game, everyone at home would be happy,\" said Shearer', ' \\n \\n\"England got off to a very good start and dominated the first 45 minutes but Croatia stepped 10 yards further forward in the second half', ' \\n \\n\"Luka Modric bossed the midfield and we could not get near him with his deft touches and passes, he was superb and a man of the match performance, a vital cog for them', ' We lacked experience to get someone on him and stop him', ' Croatia did not panic when they fell behind', ' \\n \\n\"Kieran Trippier was brilliant in the tournament and so was Jordan Pickford, especially with his delivery', ' Harry Kane was a bit quiet in the knockout games and he had a chance that he could not put away \\n \\n\"So many positives to take out of the tournament, we did not expect to get to the quarters and will go home after this without heads held high', ' Finishing third would be excellent', ' Well done guys, you have given us plenty to shout about', '\" \\n \\nOnline Editors']\n",
      "[[7986, 2158, 2094, 24015, 2278, 13433, 17457, 2015, 2000, 2543, 1996, 3608, 2627, 5207, 4060, 3877, 1998, 2404, 8097, 2046, 1996, 2088, 2452, 2345], [6302, 1024, 26665, 2981], [29464, 2280, 2563, 8291, 5639, 14871, 4081, 20243, 2148, 5867, 1005, 1055, 4686, 2018, 2589, 2062, 2084, 2071, 2031, 2042, 3517, 1997, 2068, 2012, 2023, 2088, 2452, 2004, 2027, 11489, 2041, 2007, 1037, 4100, 1011, 2345, 4154, 2114, 8097], [16770, 1024, 1013, 1013, 7479], [2981], [29464, 1013, 4368, 1013, 4715, 1013, 2088, 1011, 2452, 1011, 2760, 1013, 5639, 1011, 14871, 1011, 17664, 2015, 1011, 2563, 2015, 1011, 2058, 21046, 22507, 2015, 1011, 2004, 1011, 5070, 1011, 18330, 2121, 1011, 1998, 1011, 5673, 1011, 9684, 1011, 2507, 1011, 2037, 1011, 14392, 2015, 1011, 4261, 10790, 20842, 2575, 2581], [16129, 16770, 1024, 1013, 1013, 7479], [2981], [29464, 1013, 14932, 1013, 3720, 24434, 10790, 20842, 22022], [14925, 2063, 1013, 4293, 2581, 2487, 2050, 1013, 8285, 26775, 7361, 1013, 1044, 22022, 2475, 1013, 4720, 2386, 2487], [16545, 2290, 10373, 2280, 2563, 8291, 5639, 14871, 4081, 20243, 2148, 5867, 1005, 1055, 4686, 2018, 2589, 2062, 2084, 2071, 2031, 2042, 3517, 1997, 2068, 2012, 2023, 2088, 2452, 2004, 2027, 11489, 2041, 2007, 1037, 4100, 1011, 2345, 4154, 2114, 8097], [1037, 12323, 2094, 2563, 8105, 2044, 2018, 11382, 23169, 4440, 14756, 2099, 5045, 2563, 3805, 2044, 2074, 2274, 2781, 2007, 1037, 21688, 2489, 1011, 5926, 1010, 2007, 3289, 2013, 7332, 2566, 17417, 2278, 1998, 7986, 2158, 2094, 24015, 2278, 3687, 8097, 1037, 3058, 2007, 2605, 2044, 1037, 1016, 1011, 1015, 4469, 1011, 2051, 2663, 1999, 4924], [1000, 1996, 2034, 2518, 2000, 2360, 2003, 2023, 2136, 2038, 2579, 2149, 2000, 1037, 2173, 2057, 2196, 8078, 2057, 2071, 2131, 1010, 1000, 2056, 14871], [1000, 1045, 2056, 2077, 1996, 2977, 2563, 2196, 2058, 21046, 18697, 1010, 2023, 2136, 2038, 2058, 21046, 18697, 2094, 2893, 2000, 1996, 4100, 1011, 2345, 1998, 2027, 2064, 2035, 2022, 7078, 7098], [1000, 2027, 2031, 2579, 1996, 3842, 2007, 2068], [2017, 2156, 2035, 1996, 4599, 2041, 1999, 1996, 2380, 2000, 2156, 2068], [1045, 2196, 2245, 1045, 1005, 1040, 2156, 5019, 2066, 2008, 1999, 2023, 2088, 2452], [1000, 2027, 2064, 2022, 7078, 7098], [2057, 2106, 2360, 2077, 1996, 2208, 2122, 29126, 2031, 2000, 2202, 2023, 4495, 2138, 2009, 2089, 2196, 2272, 2153], [1000, 2035, 1045, 3246, 2004, 1045, 2298, 2012, 2068, 2085, 6933, 1010, 9364, 1010, 6314, 2003, 2027, 2131, 2178, 4495, 2004, 2204, 2004, 1996, 2028, 2027, 1005, 2310, 2074, 2018], [1000, 1000, 2027, 1005, 2128, 1996, 6587, 2136, 1999, 1996, 2977], [1045, 3246, 2027, 1005, 2128, 1999, 2008, 2597, 2153, 1010, 1015, 1011, 1014, 2039, 2007, 2322, 2781, 2000, 2175, 2007, 1996, 4495, 1997, 2893, 2046, 1037, 2088, 2452, 2345], [1000, 8097, 1005, 1055, 2139, 8405, 8840, 12229, 2078, 1998, 14383, 23692, 3501, 19830, 8439, 2044, 1996, 2674], [6302, 1024, 26665, 2280, 2563, 8291, 5673, 9684, 7164, 1996, 22446, 3267, 1997, 2563, 1005, 1055, 4686, 4928, 2000, 2022, 2037, 25672, 2075, 1999, 1996, 4100, 1011, 2345], [1000, 1045, 2228, 3325, 2001, 1037, 4129, 5387, 2651, 1010, 1000, 9684, 2409, 1996, 4035], [1000, 2023, 7963, 2136, 2018, 6665, 2035, 2058, 1996, 4686, 2021, 2085, 2003, 2025, 1996, 2051, 2000, 22404, 24330, 2243], [2023, 9129, 1997, 2867, 2031, 2716, 1996, 3842, 2362, 1998, 1996, 4599, 4033, 1005, 1056, 7042, 2066, 2023, 2005, 2086], [1000, 2057, 2359, 2023, 2136, 2000, 2272, 2041, 2007, 2019, 4767, 1998, 1037, 4695, 1997, 2652, 1010, 1998, 1045, 2228, 2027, 2031, 2589, 2008], [2073, 2057, 2020, 2938, 1999, 1996, 3346, 1010, 2111, 2105, 2149, 2020, 7622, 2007, 2563, 1005, 1055, 2374, 1998, 2037, 3754, 2000, 2377, 2041, 2013, 1996, 2067], [1000, 11382, 23169, 4440, 14756, 2099, 1005, 1055, 6959, 1997, 1996, 3608, 2001, 8235, 1998, 2054, 1037, 2977, 2002, 2038, 2018], [2045, 2020, 3160, 6017, 2058, 5207, 4060, 3877, 2021, 2002, 2001, 1996, 2190, 3601, 1999, 3125, 1998, 2023, 2136, 2064, 4503, 2046, 2242, 2200, 2844], [1045, 2031, 2042, 2019, 19837, 2099, 1997, 2198, 6386, 2005, 1037, 2146, 2051, 1010, 1998, 2002, 8047, 4895, 8671, 2666, 3567, 6321, 2651], [2057, 2031, 2288, 1037, 2200, 26252, 2402, 4686, 2021, 2027, 2031, 4961, 1998, 2097, 3613, 2000, 2079, 2061], [1000, 4654, 1011, 2563, 11854, 5070, 18330, 2121, 2036, 2699, 2000, 2424, 1996, 3893, 2015, 13463, 2563, 1005, 1055, 21782], [1000, 2057, 2056, 2077, 1996, 2977, 2008, 2065, 2027, 2435, 7078, 2673, 1999, 2296, 2208, 1010, 3071, 2012, 2188, 2052, 2022, 3407, 1010, 1000, 2056, 18330, 2121], [1000, 2563, 2288, 2125, 2000, 1037, 2200, 2204, 2707, 1998, 6817, 1996, 2034, 3429, 2781, 2021, 8097, 3706, 2184, 4210, 2582, 2830, 1999, 1996, 2117, 2431], [1000, 11320, 2912, 16913, 7277, 5795, 2098, 1996, 23071, 1998, 2057, 2071, 2025, 2131, 2379, 2032, 2007, 2010, 13366, 2102, 12817, 1998, 5235, 1010, 2002, 2001, 21688, 1998, 1037, 2158, 1997, 1996, 2674, 2836, 1010, 1037, 8995, 2522, 2290, 2005, 2068], [2057, 10858, 3325, 2000, 2131, 2619, 2006, 2032, 1998, 2644, 2032], [8097, 2106, 2025, 6634, 2043, 2027, 3062, 2369], [1000, 11382, 23169, 4440, 14756, 2099, 2001, 8235, 1999, 1996, 2977, 1998, 2061, 2001, 5207, 4060, 3877, 1010, 2926, 2007, 2010, 6959], [4302, 8472, 2001, 1037, 2978, 4251, 1999, 1996, 11369, 2399, 1998, 2002, 2018, 1037, 3382, 2008, 2002, 2071, 2025, 2404, 2185, 1000, 2061, 2116, 3893, 2015, 2000, 2202, 2041, 1997, 1996, 2977, 1010, 2057, 2106, 2025, 5987, 2000, 2131, 2000, 1996, 7728, 1998, 2097, 2175, 2188, 2044, 2023, 2302, 4641, 2218, 2152], [5131, 2353, 2052, 2022, 6581], [2092, 2589, 4364, 1010, 2017, 2031, 2445, 2149, 7564, 2000, 11245, 2055], [1000, 3784, 10195]]\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_fn(x, tokenizer):\n",
    "    x[\"summary_ids\"] = tokenizer(\n",
    "        x[\"summary\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    x[\"text_ids\"] = tokenizer(\n",
    "        x[\"text\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    x[\"sentences_ids\"] = tokenizer(\n",
    "        x[\"sentences\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    return x\n",
    "\n",
    "splitted_dataset = dataset.select_columns([\"summary\", \"text\", \"sentences\"])\n",
    "# print(splitted_dataset.__getitem__(0))\n",
    "\n",
    "word_lengths = get_word_lengths(splitted_dataset, tokenizer)\n",
    "\n",
    "# Tokenize the dataset\n",
    "splitted_dataset = splitted_dataset.map(\n",
    "    preprocessing_fn, tokenizer = tokenizer\n",
    ")\n",
    "print(splitted_dataset.__getitem__(0)[2])\n",
    "\n",
    "# Remove useless columns\n",
    "splitted_dataset = splitted_dataset.select_columns([\"summary_ids\", \"text_ids\", \"sentences_ids\"])\n",
    "print(splitted_dataset.__getitem__(0)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "871c9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Get the tokenized sequences for each item in the batch\n",
    "    text_ids_batch = [torch.tensor(item[1], dtype = torch.int) for item in batch]\n",
    "    summary_ids_batch = [torch.tensor(item[0], dtype = torch.int) for item in batch]\n",
    "    sentences_ids_batch = [\n",
    "        [torch.tensor(sentence, dtype = torch.int) for sentence in item[2]]\n",
    "        for item in batch\n",
    "    ]\n",
    "\n",
    "    # Pad sequences to the maximum length in the batch\n",
    "    padded_text_ids = pad_sequence([torch.cat([item, torch.zeros(max(0, 512 - len(item)))]) for item in text_ids_batch], batch_first = True, padding_value = 0)\n",
    "    padded_summary_ids = pad_sequence([torch.cat([item, torch.zeros(max(0, 512 - len(item)))]) for item in summary_ids_batch], batch_first = True, padding_value = 0)\n",
    "    padded_sentences_ids = [\n",
    "        pad_sequence(\n",
    "            [torch.cat([sentence, torch.zeros(max(0, 512 - len(sentence)), dtype = torch.int)]) for sentence in item],\n",
    "            batch_first = True,\n",
    "            padding_value = 0\n",
    "        )\n",
    "        for item in sentences_ids_batch\n",
    "    ]\n",
    "\n",
    "    return {\"text_ids\": padded_text_ids, \"summary_ids\": padded_summary_ids, \"sentences_ids\": padded_sentences_ids}\n",
    "\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(splitted_dataset, batch_size = batch_size, collate_fn = collate_fn)\n",
    "\n",
    "epochs = 3\n",
    "def training(summary, text, model, epochs = 10):\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    model_copy.train()\n",
    "\n",
    "    summary = summary.unsqueeze(0)\n",
    "    text = text.unsqueeze(0)\n",
    "    if summary.size(1) != text.size(1):\n",
    "        raise RuntimeError(\"Sizes along the sequence length dimension must match.\")\n",
    "    \n",
    "    for epochs in range(epochs):\n",
    "        whole_input = torch.cat((summary, text), dim = 0).long()\n",
    "        outputs = model_copy(whole_input, labels = whole_input)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82de7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sentence(sentence, i, M, word_lengths, l_min):\n",
    "    tokenized_sentence = []\n",
    "    masked_token_ids = []\n",
    "\n",
    "    for j in range(len(sentence)):\n",
    "        if (j - i) % M == 0 and sentence[j].item() in word_lengths and word_lengths[sentence[j].item()] >= l_min:\n",
    "            tokenized_sentence.append(tokenizer.mask_token_id)\n",
    "            masked_token_ids.append(j)\n",
    "        else:\n",
    "            tokenized_sentence.append(sentence[j].item())\n",
    "            \n",
    "    tokenized_sentence= torch.tensor(tokenized_sentence)\n",
    "    \n",
    "    return tokenized_sentence, masked_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fe719f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_BLANC_help(sentences, model, model_tuned, p_mask = 0.15, l_min = 4):\n",
    "    S = [[0, 0], [0, 0]]\n",
    "    M = int(1/p_mask)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for i in range(M):\n",
    "            masked_sentence, masked_tokens_ids = mask_sentence(sentence, i, M, word_lengths, l_min)\n",
    "            masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n",
    "            sentence = sentence.long()\n",
    "\n",
    "            out_base = model(masked_sentence, labels = sentence).logits\n",
    "            out_help = model_tuned(masked_sentence, labels = sentence).logits\n",
    "\n",
    "            for j in masked_tokens_ids:\n",
    "                predicted_token_model = torch.argmax(out_base[0][j])\n",
    "                predicted_token_model_tuned = torch.argmax(out_help[0][j])\n",
    "                \n",
    "                k = int(predicted_token_model == sentence[j])\n",
    "                m = int(predicted_token_model_tuned == sentence[j])\n",
    "                S[k][m] += 1\n",
    "        break\n",
    "    try:\n",
    "      B = (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
    "    except ZeroDivisionError:\n",
    "      B = 0.0\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "99b978b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 0 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 18.661803245544434 seconds\n",
      "Summary 1 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12\n",
      "Elapsed Time: 24.518627882003784 seconds\n",
      "Summary 2 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "Elapsed Time: 18.158257722854614 seconds\n",
      "Summary 3 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2\n",
      "Elapsed Time: 16.86569356918335 seconds\n",
      "Summary 4 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2631578947368421\n",
      "Elapsed Time: 18.028971910476685 seconds\n",
      "Summary 5 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.043478260869565216\n",
      "Elapsed Time: 17.49683976173401 seconds\n",
      "Summary 6 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 18.282581090927124 seconds\n",
      "Summary 7 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.045454545454545456\n",
      "Elapsed Time: 19.03317379951477 seconds\n",
      "Summary 8 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0625\n",
      "Elapsed Time: 17.374573945999146 seconds\n",
      "Summary 9 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05\n",
      "Elapsed Time: 16.60593342781067 seconds\n",
      "Summary 10 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1\n",
      "Elapsed Time: 17.074475526809692 seconds\n",
      "Summary 11 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 17.69163155555725 seconds\n",
      "Summary 12 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09523809523809523\n",
      "Elapsed Time: 18.318114757537842 seconds\n",
      "Summary 13 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 17.688296794891357 seconds\n",
      "Summary 14 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08695652173913043\n",
      "Elapsed Time: 17.29972767829895 seconds\n",
      "Summary 15 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.15789473684210525\n",
      "Elapsed Time: 17.376991033554077 seconds\n",
      "Summary 16 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 17.198835849761963 seconds\n",
      "Summary 17 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 16.440516233444214 seconds\n",
      "Summary 18 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 17.62704873085022 seconds\n",
      "Summary 19 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 16.76411724090576 seconds\n",
      "Summary 20 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 17.121089458465576 seconds\n",
      "Summary 21 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 17.23695945739746 seconds\n",
      "Summary 22 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.043478260869565216\n",
      "Elapsed Time: 17.109238147735596 seconds\n",
      "Summary 23 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1\n",
      "Elapsed Time: 23.85978865623474 seconds\n",
      "Summary 24 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07142857142857142\n",
      "Elapsed Time: 22.2849862575531 seconds\n",
      "Summary 25 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.125\n",
      "Elapsed Time: 16.91410803794861 seconds\n",
      "Summary 26 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11764705882352941\n",
      "Elapsed Time: 17.520513772964478 seconds\n",
      "Summary 27 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.28\n",
      "Elapsed Time: 18.59769606590271 seconds\n",
      "Summary 28 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.045454545454545456\n",
      "Elapsed Time: 16.348493576049805 seconds\n",
      "Summary 29 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18181818181818182\n",
      "Elapsed Time: 16.924741983413696 seconds\n",
      "Summary 30 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 16.893242597579956 seconds\n",
      "Summary 31 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 17.26734495162964 seconds\n",
      "Summary 0 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.15789473684210525\n",
      "Elapsed Time: 17.016314268112183 seconds\n",
      "Summary 1 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12\n",
      "Elapsed Time: 18.084744691848755 seconds\n",
      "Summary 2 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1111111111111111\n",
      "Elapsed Time: 18.33009648323059 seconds\n",
      "Summary 3 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 20.499070644378662 seconds\n",
      "Summary 4 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 34.80295991897583 seconds\n",
      "Summary 5 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_18268\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def blanc_tune(summary, text, model, p_mask = 0.15, l_min = 4, N = 10, epochs = 10):\n",
    "    N_summary = len(summary)\n",
    "    N_mask = int(N_summary*p_mask)\n",
    "    set_tune = pd.DataFrame(columns = ['summary', 'text'])\n",
    "\n",
    "    for j in range(0, N):\n",
    "        pos = [i for i, token in enumerate(summary.tolist()) if token in word_lengths and word_lengths[token] >= l_min]\n",
    "        random.shuffle(pos)\n",
    "        while len(pos) != 0:\n",
    "            masked_summary = summary.tolist().copy()\n",
    "            for pos_to_mask in pos[:N_mask]:\n",
    "                masked_summary[pos_to_mask] = '[MASK]'\n",
    "                set_tune.loc[set_tune.shape[0]] = [masked_summary, text]\n",
    "            pos = pos[N_mask:]\n",
    "\n",
    "    model_tuned = training(summary, text, model, epochs)\n",
    "    print('\\n')      \n",
    "    return model_tuned\n",
    "\n",
    "def blanc_tune_batch(batch, model, p_mask = 0.15, l_min = 4, N = 10, epochs = 10):\n",
    "    batch_tuned_models = []\n",
    "    batch_accuracies = []\n",
    "    \n",
    "    i = 0\n",
    "    for summary, text, sentences in zip(batch['summary_ids'], batch['text_ids'], batch['sentences_ids']):\n",
    "        print(f\"Summary {i} of batch\")\n",
    "        i += 1\n",
    "        start_time = time.time()\n",
    "        model_tuned = blanc_tune(summary, text, model, p_mask, l_min, N, epochs)\n",
    "        batch_tuned_models.append(model_tuned)\n",
    "        accuracy = modified_BLANC_help(sentences, model, model_tuned)\n",
    "        print(accuracy)\n",
    "        end_time = time.time()\n",
    "        batch_accuracies.append(accuracy)\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "    return batch_tuned_models, batch_accuracies\n",
    "\n",
    "for batch in dataloader:\n",
    "    models_tuned, text_accuracies = blanc_tune_batch(batch, model, epochs = epochs)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "collabfiltering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
