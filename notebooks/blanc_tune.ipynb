{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d9f8b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\clara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b872e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(555, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "filename = \"CNN_DailyMail_555.json\"\n",
    "# filename = \"DailyNews_300.json\"\n",
    "data = pd.read_json('../datasets/' + filename)\n",
    "print(data.shape)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397b468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.features = self.dataset.columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.dataset.iloc[idx, 0], \n",
    "                self.dataset.iloc[idx, 1], \n",
    "                self.dataset.iloc[idx, 2], \n",
    "                self.dataset.iloc[idx, 3])\n",
    "    \n",
    "    def map(self, preprocessing_fn, **kwargs):\n",
    "        return CustomDataset(self.dataset.apply(lambda x: preprocessing_fn(x, **kwargs), axis = 1))\n",
    "    \n",
    "    def select_columns(self, columns):\n",
    "        new_dataset = self.dataset[columns] \n",
    "        return CustomDataset(new_dataset)\n",
    "    \n",
    "    def get_sentences(self, feature = 'text'):\n",
    "        self.dataset['sentences'] = self.dataset[feature].apply(lambda x: sent_tokenize(x))\n",
    "        return CustomDataset(self.dataset)\n",
    "    \n",
    "    # Data cleaning\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        # lower case\n",
    "        text = text.lower()\n",
    "    \n",
    "        # before normalization : manual handling of contractions and line breaks\n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = text.replace(' \\' ', '\\'')\n",
    "        text = text.replace('\\'', '')\n",
    "    \n",
    "        # string normalization.\n",
    "        text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore')\n",
    "        text = str(text)[2:-1]\n",
    "        # the result of previous line adds a few characters to the string,\n",
    "        # we remove them.\n",
    "    \n",
    "        # remove non alpha numeric characters, except dots, question and exclamation marks that will be needed to separate sentences.\n",
    "        text = re.sub(r'[^\\w]', ' ', text)\n",
    "    \n",
    "        # replace numbers by the <NUM> token.\n",
    "        text = re.sub(r'[0-9]+', '<NUM>', text)\n",
    "    \n",
    "        # remove double whitespaces.\n",
    "        text = re.sub(r'( ){2,}', ' ', text).strip()\n",
    "        # removing spaces at beginning and end of string.\n",
    "    \n",
    "        return text\n",
    "    \n",
    "    def apply_preprocess(self):\n",
    "        self.dataset[\"summary\"] = self.dataset['summary'].apply(lambda x: self.preprocess_text(x))\n",
    "        self.dataset[\"text\"] = self.dataset['text'].apply(lambda x: self.preprocess_text(x))\n",
    "        new_sentences_col = []\n",
    "        for sentences in self.dataset['sentences']:\n",
    "            new_sentences_col.append([self.preprocess_text(sentence) for sentence in sentences])\n",
    "        self.dataset['sentences'] = new_sentences_col\n",
    "        return CustomDataset(self.dataset)\n",
    "    \n",
    "    def random_words_summary(self, summary):\n",
    "        random_summary = \"\"\n",
    "        summary = summary.split()\n",
    "        for _ in range(len(summary)):\n",
    "            random_summary += random.choice(summary) + ' '\n",
    "        return random_summary\n",
    "    \n",
    "    def apply_random_words_summary(self):\n",
    "        self.dataset['random_summary'] = self.dataset['summary'].apply(lambda x: self.random_words_summary(x))\n",
    "        return CustomDataset(self.dataset)\n",
    "    \n",
    "dataset = CustomDataset(data)\n",
    "dataset = dataset.get_sentences()\n",
    "#print(dataset[4][1])\n",
    "#print(dataset.__getitem__(4)[2])\n",
    "#print(dataset.__getitem__(4)[3])\n",
    "dataset = dataset.apply_preprocess()\n",
    "dataset = dataset.apply_random_words_summary()\n",
    "# print(dataset.__getitem__(0)[2])\n",
    "# print(dataset.__getitem__(0)[3])\n",
    "# print(dataset.__getitem__(0)[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34df281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_lengths(dataset, tokenizer, l_min = 4):\n",
    "    word_lengths = {}\n",
    "    all_tokens = []\n",
    "\n",
    "    for sample in dataset:\n",
    "        summary = sample[0]\n",
    "        preprocessed_result = tokenizer(summary, \n",
    "                                        add_special_tokens = False,\n",
    "                                        truncation = True,\n",
    "                                        max_length = 256,\n",
    "                                        padding = False,\n",
    "                                        return_attention_mask = False)\n",
    "        tokens = preprocessed_result[\"input_ids\"]\n",
    "        decoded_tokens = tokenizer.convert_ids_to_tokens(tokens)\n",
    "        for token in tokens:\n",
    "            if token not in all_tokens:\n",
    "                all_tokens.append(token)\n",
    "\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            eligible = False\n",
    "            if decoded_tokens[i].startswith('##'):\n",
    "                eligible = True\n",
    "                word_lengths[tokens[i - 1]] = eligible\n",
    "                word_lengths[tokens[i]] = eligible\n",
    "            else:\n",
    "                if len(decoded_tokens[i]) >= l_min:\n",
    "                    eligible = True\n",
    "                word_lengths[tokens[i]] = eligible\n",
    "            i += 1\n",
    "\n",
    "    assert len(all_tokens) == len(word_lengths), \"Association of tokens with word length : FAILED.\"\n",
    "\n",
    "    return word_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e993a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2079, 3501, 2089, 2145, 3288, 5571, 2114, 2577, 27946, 2079, 3501, 2071, 3288, 2976, 2942, 5571, 2114, 27946, 2942, 2916, 5160, 3421, 11851, 17789, 19953, 3008]\n",
      "[1996, 2533, 1997, 3425, 2089, 2145, 3288, 2942, 5571, 2114, 11851, 17789, 3235, 13108, 2577, 27946, 4905, 2236, 4388, 9111, 3936, 2006, 9432, 9111, 2409, 12060, 2006, 9432, 2008, 2079, 3501, 2018, 2025, 5531, 2049, 4812, 2046, 1996, 2337, 1026, 16371, 2213, 1028, 1026, 16371, 2213, 1028, 5043, 1998, 1996, 3043, 2003, 7552, 2045, 2024, 3161, 4084, 2008, 2057, 2024, 2145, 1999, 1996, 2832, 1997, 2635, 9111, 2056, 2429, 2000, 1996, 2940, 2045, 2024, 9390, 2040, 2057, 2215, 2000, 3713, 2000, 2004, 1037, 2765, 1997, 2070, 3522, 8973, 17186, 2091, 2005, 2678, 4905, 2236, 4388, 9111, 2409, 12060, 7483, 2008, 1996, 3425, 7640, 4812, 2046, 11851, 17789, 3235, 13108, 2577, 27946, 2003, 7552, 2372, 1997, 1996, 2047, 2259, 2103, 2473, 4929, 7415, 2666, 28095, 2015, 1999, 3638, 1997, 11851, 17789, 3235, 15885, 2006, 1996, 13082, 2604, 2004, 2027, 3233, 2362, 2006, 1996, 4084, 1997, 2103, 2534, 1999, 2047, 2259, 2076, 1037, 2739, 3034, 1037, 3204, 2044, 1996, 1026, 16371, 2213, 1028, 2095, 2214, 21153, 3516, 6319, 2001, 2915, 1998, 2730, 2011, 5101, 3422, 2386, 2577, 27946, 27946, 1998, 2010, 2522, 9517, 2123, 2225, 2187, 2831, 2076, 1037, 28290, 2006, 1996, 2034, 2154, 1997, 6467, 4989, 1999, 27946, 2015, 4028, 3979, 2197, 2621, 27946, 2001, 4821, 18538, 1997, 1996, 4735, 5571, 2021, 2079, 3501, 2071, 2145, 3288, 2976, 2942, 5571, 2114, 2032, 27946, 2040, 2003, 6696, 2001, 6951, 2007, 2010, 5101, 3422, 1999, 21153, 3516, 2043, 2002, 2018, 1996, 6497, 2039, 2007, 3235, 2008, 4504, 1999, 1996, 1026, 16371, 2213, 1028, 2095, 2214, 3060, 4841, 2331, 2002, 2001, 18538, 1997, 4028, 5571, 2062, 2084, 1037, 2095, 3283, 1999, 1037, 4735, 2457, 1996, 2533, 1997, 3425, 2071, 3288, 2049, 2219, 2275, 1997, 2976, 2942, 5571, 2114, 27946, 2174, 1998, 2049, 2145, 2559, 2000, 2241, 2006, 13304, 7928, 9432, 19867, 2506, 3037, 1999, 27946, 2003, 5866, 2004, 1996, 2533, 5373, 14730, 2049, 27050, 2306, 1037, 3043, 1997, 2706, 1996, 2940, 2758, 1996, 4905, 2236, 2134, 2102, 3749, 2151, 3176, 4751, 2006, 1996, 6867, 4812, 7483, 2107, 2004, 2043, 2009, 3488, 2000, 10236, 2009, 2039, 2043, 9111, 2001, 2356, 2055, 27946, 2197, 2281, 1996, 2406, 2015, 2708, 2375, 7285, 2961, 2134, 2102, 2507, 1037, 15764, 2203, 3058, 2005, 1996, 15113, 2593, 2021, 3264, 2008, 1037, 6937, 2112, 2001, 10395, 1999, 1996, 2553, 2008, 2001, 2699, 10047, 2025, 2469, 3599, 2129, 2172, 2936, 2008, 2097, 2202, 2021, 2057, 2097, 2131, 2000, 1037, 2391, 2073, 2057, 2024, 2583, 2000, 2191, 1037, 9128, 2002, 2056, 9111, 2001, 8781, 2153, 2055, 1996, 3235, 5008, 2006, 9432, 2012, 1037, 2811, 3034, 13856, 1037, 2079, 3501, 4812, 3141, 2000, 1996, 5008, 1997, 2178, 3060, 2137, 9458, 2745, 2829, 1999, 2008, 2553, 9111, 2056, 2079, 3501, 2097, 3319, 1996, 1996, 11262, 5284, 2610, 2486, 2000, 5646, 2065, 2049, 3738, 2031, 1037, 5418, 1998, 3218, 1997, 9147, 1996, 15113, 4076, 1037, 3204, 1997, 2942, 16591, 1999, 1996, 2358, 3434, 7575, 2044, 2028, 1997, 1996, 3262, 2304, 4865, 2317, 2610, 3738, 9382, 2915, 1998, 2730, 1026, 16371, 2213, 1028, 2095, 2214, 2829, 13240, 2155, 2003, 2108, 3421, 2011, 1996, 2168, 2942, 2916, 5160, 2040, 3421]\n",
      "[[1996, 2533, 1997, 3425, 2089, 2145, 3288, 2942, 5571, 2114, 11851, 17789, 3235, 13108, 2577, 27946, 4905, 2236, 4388, 9111, 3936, 2006, 9432], [9111, 2409, 12060, 2006, 9432, 2008, 2079, 3501, 2018, 2025, 5531, 2049, 4812, 2046, 1996, 2337, 1026, 16371, 2213, 1028, 1026, 16371, 2213, 1028, 5043, 1998, 1996, 3043, 2003, 7552], [2045, 2024, 3161, 4084, 2008, 2057, 2024, 2145, 1999, 1996, 2832, 1997, 2635, 9111, 2056, 2429, 2000, 1996, 2940], [2045, 2024, 9390, 2040, 2057, 2215, 2000, 3713, 2000, 2004, 1037, 2765, 1997, 2070, 3522, 8973], [17186, 2091, 2005, 2678, 4905, 2236, 4388, 9111, 2409, 12060, 7483, 2008, 1996, 3425, 7640, 4812, 2046, 11851, 17789, 3235, 13108, 2577, 27946, 2003, 7552, 2372, 1997, 1996, 2047, 2259, 2103, 2473, 4929, 7415, 2666, 28095, 2015, 1999, 3638, 1997, 11851, 17789, 3235, 15885, 2006, 1996, 13082, 2604, 2004, 2027, 3233, 2362, 2006, 1996, 4084, 1997, 2103, 2534, 1999, 2047, 2259, 2076, 1037, 2739, 3034, 1037, 3204, 2044, 1996, 1026, 16371, 2213, 1028, 2095, 2214, 21153, 3516, 6319, 2001, 2915, 1998, 2730, 2011, 5101, 3422, 2386, 2577, 27946, 27946, 1998, 2010, 2522, 9517, 2123, 2225, 2187, 2831, 2076, 1037, 28290, 2006, 1996, 2034, 2154, 1997, 6467, 4989, 1999, 27946, 2015, 4028, 3979, 2197, 2621], [27946, 2001, 4821, 18538, 1997, 1996, 4735, 5571, 2021, 2079, 3501, 2071, 2145, 3288, 2976, 2942, 5571, 2114, 2032, 27946, 2040, 2003, 6696, 2001, 6951, 2007, 2010, 5101, 3422, 1999, 21153, 3516, 2043, 2002, 2018, 1996, 6497, 2039, 2007, 3235, 2008, 4504, 1999, 1996, 1026, 16371, 2213, 1028, 2095, 2214, 3060, 4841, 2331], [2002, 2001, 18538, 1997, 4028, 5571, 2062, 2084, 1037, 2095, 3283, 1999, 1037, 4735, 2457], [1996, 2533, 1997, 3425, 2071, 3288, 2049, 2219, 2275, 1997, 2976, 2942, 5571, 2114, 27946, 2174, 1998, 2049, 2145, 2559, 2000, 2241, 2006, 13304, 7928, 9432], [19867, 2506, 3037, 1999, 27946, 2003, 5866, 2004, 1996, 2533, 5373, 14730, 2049, 27050, 2306, 1037, 3043, 1997, 2706], [1996, 2940, 2758, 1996, 4905, 2236, 2134, 2102, 3749, 2151, 3176, 4751, 2006, 1996, 6867, 4812, 7483, 2107, 2004, 2043, 2009, 3488, 2000, 10236, 2009, 2039], [2043, 9111, 2001, 2356, 2055, 27946, 2197, 2281, 1996, 2406, 2015, 2708, 2375, 7285, 2961, 2134, 2102, 2507, 1037, 15764, 2203, 3058, 2005, 1996, 15113, 2593, 2021, 3264, 2008, 1037, 6937, 2112, 2001, 10395, 1999, 1996, 2553, 2008, 2001, 2699], [10047, 2025, 2469, 3599, 2129, 2172, 2936, 2008, 2097, 2202, 2021, 2057, 2097, 2131, 2000, 1037, 2391, 2073, 2057, 2024, 2583, 2000, 2191, 1037, 9128, 2002, 2056], [9111, 2001, 8781, 2153, 2055, 1996, 3235, 5008, 2006, 9432, 2012, 1037, 2811, 3034, 13856, 1037, 2079, 3501, 4812, 3141, 2000, 1996, 5008, 1997, 2178, 3060, 2137, 9458, 2745, 2829], [1999, 2008, 2553, 9111, 2056, 2079, 3501, 2097, 3319, 1996, 1996, 11262, 5284, 2610, 2486, 2000, 5646, 2065, 2049, 3738, 2031, 1037, 5418, 1998, 3218, 1997, 9147], [1996, 15113, 4076, 1037, 3204, 1997, 2942, 16591, 1999, 1996, 2358, 3434, 7575, 2044, 2028, 1997, 1996, 3262, 2304, 4865, 2317, 2610, 3738, 9382, 2915, 1998, 2730, 1026, 16371, 2213, 1028, 2095, 2214, 2829], [13240, 2155, 2003, 2108, 3421, 2011, 1996, 2168, 2942, 2916, 5160, 2040, 3421, 1996, 11851, 17789, 19953, 3008, 25353, 23736, 2532, 17049, 1998, 10555, 3235, 2044, 2002, 2097, 2001, 2730, 2048, 1998, 1037, 2431, 2086, 3283], [17049, 1998, 3235, 2031, 2036, 3253, 2037, 3167, 2490, 2000, 13240, 2155], [1996, 3940, 6158, 2000, 5284, 2197, 3204, 2000, 3693, 1996, 10181, 13496, 3008, 2012, 2358, 3434, 3521, 14081, 8320, 2019, 3296, 2724, 6461, 2012, 4566, 3282, 4808]]\n",
      "[11851, 17789, 3288, 2079, 3501, 2079, 3501, 27946, 27946, 5571, 3288, 19953, 2916, 2145, 5160, 5571, 2089, 2079, 3501, 2145, 2577, 27946, 2942, 3421, 2079, 3501, 2916, 2577]\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_fn(x, tokenizer):\n",
    "    x[\"summary_ids\"] = tokenizer(\n",
    "        x[\"summary\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 256,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    x[\"text_ids\"] = tokenizer(\n",
    "        x[\"text\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    x[\"sentences_ids\"] = tokenizer(\n",
    "        x[\"sentences\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 256,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    x[\"random_summary_ids\"] = tokenizer(\n",
    "        x[\"random_summary\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 256,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    return x\n",
    "\n",
    "splitted_dataset = dataset.select_columns([\"summary\", \"text\", \"sentences\", \"random_summary\"])\n",
    "\n",
    "word_lengths = get_word_lengths(splitted_dataset, tokenizer)\n",
    "\n",
    "# Tokenize the dataset\n",
    "splitted_dataset = splitted_dataset.map(\n",
    "    preprocessing_fn, tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "# Remove useless columns\n",
    "splitted_dataset = splitted_dataset.select_columns([\"summary_ids\", \"text_ids\", \"sentences_ids\", \"random_summary_ids\"])\n",
    "print(splitted_dataset[0][0]) # summary\n",
    "print(splitted_dataset[0][1]) # text\n",
    "print(splitted_dataset[0][2]) # sentences\n",
    "print(splitted_dataset[0][3]) # random_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dedc67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['members', 'of', 'britain', 'first', 'protesting', 'outside', 'the', 'old', 'bailey', 'after', 'the', 'sentencing', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'clash', 'with', 'police', 'after', 'they', 'mistakenly', 'surround', 'a', 'muslim', 'family', 'who', 'have', 'nothing', 'to', 'do', 'with', 'the', 'rig', '##by', 'case', 'an', 'innocent', 'muslim', 'family', 'cow', '##ers', 'in', 'an', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'harassed', 'by', 'members', 'of', 'britain', 'first', 'who', 'mistakenly', 'believe', 'that', 'they', 'are', 'attending', 'the', 'trial', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'city', 'of', 'london', 'police', 'attempt', 'to', 'def', '##use', 'the', 'situation', 'outside', 'the', 'old', 'bailey', 'the', 'muslim', 'family', 'cow', '##er', 'in', 'the', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'mistakenly', 'linked', 'with', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'the', 'muslim', 'family', 'look', 'on', 'nervously', 'in', 'the', 'background', 'as', 'members', 'of', 'britain', 'first', 'shout', 'menacing', '##ly', 'the', 'scenes', 'are', 'taken', 'from', 'london', '##s', 'holy', 'turf', 'war', 'a', 'new', 'documentary', 'that', 'shows', 'on', 'one', 'side', 'the', 'muslim', 'patrol', 'be', '##rating', 'people', 'who', 'drink', 'or', 'dress', 'provocative', '##ly', 'in', 'the', 'streets', 'while', 'on', 'the', 'other', 'is', 'the', 'christian', 'patrol', 'members', 'of', 'a', 'new', 'group', 'britain', 'first', 'a', 'political', 'party', 'and', 'street', 'defence', 'organisation', 'that', 'says', 'it', 'opposes', 'and', 'fights', 'the', 'many', 'injustice', '##s', 'that', 'are', 'routinely', 'inflicted', 'on', 'the', 'british', 'people']\n",
      "297\n",
      "['members', 'of', 'britain', 'first', 'protesting', 'outside', 'the', 'old', 'bailey', 'after', 'the', 'sentencing', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'clash', 'with', 'police', 'after', 'they', 'mistakenly', 'surround', 'a', 'muslim', 'family', 'who', 'have', 'nothing', 'to', 'do', 'with', 'the', 'rig', '##by', 'case', 'an', 'innocent', 'muslim', 'family', 'cow', '##ers', 'in', 'an', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'harassed', 'by', 'members', 'of', 'britain', 'first', 'who', 'mistakenly', 'believe', 'that', 'they', 'are', 'attending', 'the', 'trial', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'city', 'of', 'london', 'police', 'attempt', 'to', 'def', '##use', 'the', 'situation', 'outside', 'the', 'old', 'bailey', 'the', 'muslim', 'family', 'cow', '##er', 'in', 'the', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'mistakenly', 'linked', 'with', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'the', 'muslim', 'family', 'look', 'on', 'nervously', 'in', 'the', 'background', 'as', 'members', 'of', 'britain', 'first', 'shout', 'menacing', '##ly', 'the', 'scenes', 'are', 'taken', 'from', 'london', '##s', 'holy', 'turf', 'war', 'a', 'new', 'documentary', 'that', 'shows', 'on', 'one', 'side', 'the', 'muslim', 'patrol', 'be', '##rating', 'people', 'who', 'drink', 'or', 'dress', 'provocative', '##ly', 'in', 'the', 'streets', 'while', 'on', 'the', 'other', 'is', 'the', 'christian', 'patrol', 'members', 'of', 'a', 'new', 'group', 'britain', 'first', 'a', 'political', 'party', 'and', 'street', 'defence', 'organisation', 'that', 'says', 'it', 'opposes', 'and', 'fights', 'the', 'many', 'injustice', '##s', 'that', 'are', 'routinely', 'inflicted', 'on', 'the', 'british', 'people']\n",
      "380\n",
      "['members', 'of', 'britain', 'first', 'protesting', 'outside', 'the', 'old', 'bailey', 'after', 'the', 'sentencing', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'clash', 'with', 'police', 'after', 'they', 'mistakenly', 'surround', 'a', 'muslim', 'family', 'who', 'have', 'nothing', 'to', 'do', 'with', 'the', 'rig', '##by', 'case', 'an', 'innocent', 'muslim', 'family', 'cow', '##ers', 'in', 'an', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'harassed', 'by', 'members', 'of', 'britain', 'first', 'who', 'mistakenly', 'believe', 'that', 'they', 'are', 'attending', 'the', 'trial', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'city', 'of', 'london', 'police', 'attempt', 'to', 'def', '##use', 'the', 'situation', 'outside', 'the', 'old', 'bailey', 'the', 'muslim', 'family', 'cow', '##er', 'in', 'the', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'mistakenly', 'linked', 'with', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'the', 'muslim', 'family', 'look', 'on', 'nervously', 'in', 'the', 'background', 'as', 'members', 'of', 'britain', 'first', 'shout', 'menacing', '##ly', 'the', 'scenes', 'are', 'taken', 'from', 'london', '##s', 'holy', 'turf', 'war', 'a', 'new', 'documentary', 'that', 'shows', 'on', 'one', 'side', 'the', 'muslim', 'patrol', 'be', '##rating', 'people', 'who', 'drink', 'or', 'dress', 'provocative', '##ly', 'in', 'the', 'streets', 'while', 'on', 'the', 'other', 'is', 'the', 'christian', 'patrol', 'members', 'of', 'a', 'new', 'group', 'britain', 'first', 'a', 'political', 'party', 'and', 'street', 'defence', 'organisation', 'that', 'says', 'it', 'opposes', 'and', 'fights', 'the', 'many', 'injustice', '##s', 'that', 'are', 'routinely', 'inflicted', 'on', 'the', 'british', 'people']\n",
      "436\n",
      "['members', 'of', 'britain', 'first', 'protesting', 'outside', 'the', 'old', 'bailey', 'after', 'the', 'sentencing', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'clash', 'with', 'police', 'after', 'they', 'mistakenly', 'surround', 'a', 'muslim', 'family', 'who', 'have', 'nothing', 'to', 'do', 'with', 'the', 'rig', '##by', 'case', 'an', 'innocent', 'muslim', 'family', 'cow', '##ers', 'in', 'an', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'harassed', 'by', 'members', 'of', 'britain', 'first', 'who', 'mistakenly', 'believe', 'that', 'they', 'are', 'attending', 'the', 'trial', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'city', 'of', 'london', 'police', 'attempt', 'to', 'def', '##use', 'the', 'situation', 'outside', 'the', 'old', 'bailey', 'the', 'muslim', 'family', 'cow', '##er', 'in', 'the', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'mistakenly', 'linked', 'with', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'the', 'muslim', 'family', 'look', 'on', 'nervously', 'in', 'the', 'background', 'as', 'members', 'of', 'britain', 'first', 'shout', 'menacing', '##ly', 'the', 'scenes', 'are', 'taken', 'from', 'london', '##s', 'holy', 'turf', 'war', 'a', 'new', 'documentary', 'that', 'shows', 'on', 'one', 'side', 'the', 'muslim', 'patrol', 'be', '##rating', 'people', 'who', 'drink', 'or', 'dress', 'provocative', '##ly', 'in', 'the', 'streets', 'while', 'on', 'the', 'other', 'is', 'the', 'christian', 'patrol', 'members', 'of', 'a', 'new', 'group', 'britain', 'first', 'a', 'political', 'party', 'and', 'street', 'defence', 'organisation', 'that', 'says', 'it', 'opposes', 'and', 'fights', 'the', 'many', 'injustice', '##s', 'that', 'are', 'routinely', 'inflicted', 'on', 'the', 'british', 'people']\n",
      "448\n",
      "['members', 'of', 'britain', 'first', 'protesting', 'outside', 'the', 'old', 'bailey', 'after', 'the', 'sentencing', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'clash', 'with', 'police', 'after', 'they', 'mistakenly', 'surround', 'a', 'muslim', 'family', 'who', 'have', 'nothing', 'to', 'do', 'with', 'the', 'rig', '##by', 'case', 'an', 'innocent', 'muslim', 'family', 'cow', '##ers', 'in', 'an', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'harassed', 'by', 'members', 'of', 'britain', 'first', 'who', 'mistakenly', 'believe', 'that', 'they', 'are', 'attending', 'the', 'trial', 'of', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'city', 'of', 'london', 'police', 'attempt', 'to', 'def', '##use', 'the', 'situation', 'outside', 'the', 'old', 'bailey', 'the', 'muslim', 'family', 'cow', '##er', 'in', 'the', 'old', 'bailey', 'doorway', 'as', 'they', 'are', 'mistakenly', 'linked', 'with', 'michael', 'ad', '##eb', '##ola', '##jo', 'and', 'michael', 'ad', '##eb', '##owa', '##l', 'the', 'killers', 'of', 'lee', 'rig', '##by', 'the', 'muslim', 'family', 'look', 'on', 'nervously', 'in', 'the', 'background', 'as', 'members', 'of', 'britain', 'first', 'shout', 'menacing', '##ly', 'the', 'scenes', 'are', 'taken', 'from', 'london', '##s', 'holy', 'turf', 'war', 'a', 'new', 'documentary', 'that', 'shows', 'on', 'one', 'side', 'the', 'muslim', 'patrol', 'be', '##rating', 'people', 'who', 'drink', 'or', 'dress', 'provocative', '##ly', 'in', 'the', 'streets', 'while', 'on', 'the', 'other', 'is', 'the', 'christian', 'patrol', 'members', 'of', 'a', 'new', 'group', 'britain', 'first', 'a', 'political', 'party', 'and', 'street', 'defence', 'organisation', 'that', 'says', 'it', 'opposes', 'and', 'fights', 'the', 'many', 'injustice', '##s', 'that', 'are', 'routinely', 'inflicted', 'on', 'the', 'british', 'people']\n"
     ]
    }
   ],
   "source": [
    "max_summary_length = max(len(summary) for summary in splitted_dataset.dataset[\"summary_ids\"])\n",
    "longest_sentence = max((sentence for sentences in splitted_dataset.dataset[\"sentences_ids\"] for sentence in sentences), key=len)\n",
    "for i in range(len(splitted_dataset.dataset[\"sentences_ids\"])):\n",
    "    sentences = splitted_dataset.dataset[\"sentences_ids\"][i]\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) >= 234:\n",
    "            print(tokenizer.convert_ids_to_tokens(sentence))\n",
    "            print(i)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(longest_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871c9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Get the tokenized sequences for each item in the batch\n",
    "    text_ids_batch = [torch.tensor(item[1], dtype = torch.int) for item in batch]\n",
    "    summary_ids_batch = [torch.tensor(item[0], dtype = torch.int) for item in batch]\n",
    "    sentences_ids_batch = [\n",
    "        [torch.tensor(sentence, dtype = torch.int) for sentence in item[2]]\n",
    "        for item in batch\n",
    "    ]\n",
    "\n",
    "    # Pad sequences to the maximum length in the batch\n",
    "    padded_text_ids = pad_sequence([torch.cat([item, torch.zeros(max(0, 512 - len(item)))]) for item in text_ids_batch], batch_first = True, padding_value = 0)\n",
    "    padded_summary_ids = pad_sequence([torch.cat([item, torch.zeros(max(0, 256 - len(item)))]) for item in summary_ids_batch], batch_first = True, padding_value = 0)\n",
    "    padded_sentences_ids = [\n",
    "        pad_sequence(\n",
    "            [torch.cat([sentence, torch.zeros(max(0, 256 - len(sentence)), dtype = torch.int)]) for sentence in item],\n",
    "            batch_first = True,\n",
    "            padding_value = 0\n",
    "        )\n",
    "        for item in sentences_ids_batch\n",
    "    ]\n",
    "    \n",
    "\n",
    "    return {\"text_ids\": padded_text_ids, \"summary_ids\": padded_summary_ids, \"sentences_ids\": padded_sentences_ids}\n",
    "\n",
    "def collate_fn2(batch):\n",
    "    # Get the tokenized sequences for each item in the batch\n",
    "    text_ids_batch = [torch.tensor(item[1], dtype = torch.int) for item in batch]\n",
    "    summary_ids_batch = [torch.tensor(item[0], dtype = torch.int) for item in batch]\n",
    "    sentences_ids_batch = [\n",
    "        [torch.tensor(sentence, dtype = torch.int) for sentence in item[2]]\n",
    "        for item in batch\n",
    "    ]\n",
    "    \n",
    "\n",
    "    return {\"text_ids\": text_ids_batch, \"summary_ids\": summary_ids_batch, \"sentences_ids\": sentences_ids_batch}\n",
    "\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(splitted_dataset, batch_size = batch_size, collate_fn = collate_fn2)\n",
    "\n",
    "epochs = 3\n",
    "def training(summary, text, model, epochs = 10):\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    model_copy.train()\n",
    "\n",
    "    summary = summary.unsqueeze(0)\n",
    "    text = text.unsqueeze(0)\n",
    "    if summary.size(1) != text.size(1):\n",
    "        raise RuntimeError(\"Sizes along the sequence length dimension must match.\")\n",
    "    \n",
    "    for epochs in range(epochs):\n",
    "        whole_input = torch.cat((summary, text), dim = 0).long()\n",
    "        outputs = model_copy(whole_input, labels = whole_input)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82de7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sentence(sentence, i, M, word_lengths):\n",
    "    tokenized_sentence = []\n",
    "    masked_token_ids = []\n",
    "\n",
    "    for j in range(len(sentence)):\n",
    "        if (j - i) % M == 0 and sentence[j].item() in word_lengths and word_lengths[sentence[j].item()]:\n",
    "            tokenized_sentence.append(tokenizer.mask_token_id) # 103\n",
    "            masked_token_ids.append(j)\n",
    "        else:\n",
    "            tokenized_sentence.append(sentence[j].item())\n",
    "            \n",
    "    tokenized_sentence= torch.tensor(tokenized_sentence)\n",
    "    \n",
    "    return tokenized_sentence, masked_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe719f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 0 of batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clara\\AppData\\Local\\Temp\\ipykernel_10032\\3927567186.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.'] ['for'] ['bring']\n",
      "['.'] ['bring'] ['martin']\n",
      "['...'] ['##j'] ['department']\n",
      "['...'] ['\"'] ['civil']\n",
      "['.'] ['zimmerman'] ['charges']\n",
      "['.'] ['\"'] ['george']\n",
      "['.'] ['\"'] ['revealed']\n",
      "['.'] ['not'] ['justice']\n",
      "['...'] ['do'] ['against']\n",
      "['...'] ['charges'] ['zimmerman']\n",
      "['.'] ['##j'] ['tray']\n",
      "['.'] ['for'] ['attorney']\n",
      "['.'] ['\"'] ['thursday']\n",
      "['.'] ['allegations'] ['still']\n",
      "['.'] ['could'] ['##von']\n",
      "['.'] ['zimmerman'] ['general']\n",
      "[[16, 0], [0, 0]]\n",
      "['.'] ['for'] ['do']\n",
      "['.'] ['bring'] ['investigation']\n",
      "['...'] ['black'] ['##m']\n",
      "['...'] ['martins'] ['incident']\n",
      "['.'] ['##j'] ['told']\n",
      "['.'] ['george'] ['##j']\n",
      "['.'] ['federal'] ['into']\n",
      "['.'] ['may'] ['reporters']\n",
      "['.'] ['charges'] ['february']\n",
      "['...'] ['and'] ['nu']\n",
      "['.'] ['bring'] ['thursday']\n",
      "['...'] ['lee'] ['##m']\n",
      "['.'] ['lee'] ['that']\n",
      "['.'] ['zimmerman'] ['nu']\n",
      "['that'] ['reporters'] ['ongoing']\n",
      "[[31, 0], [0, 0]]\n",
      "['.'] ['\"'] ['there']\n",
      "['.'] ['bring'] ['taking']\n",
      "['.'] ['black'] ['hill']\n",
      "['.'] ['george'] ['still']\n",
      "['.'] ['may'] ['active']\n",
      "['.'] ['justice'] ['said']\n",
      "['.'] ['still'] ['steps']\n",
      "['.'] ['charges'] ['according']\n",
      "['.'] ['bring'] ['that']\n",
      "['.'] ['##j'] ['process']\n",
      "[[41, 0], [0, 0]]\n",
      "['...'] ['\"'] ['there']\n",
      "['.'] ['george'] ['speak']\n",
      "['.'] ['directly'] ['some']\n",
      "['.'] ['direct'] ['recent']\n",
      "['...'] ['charges'] ['want']\n",
      "['...'] ['may'] ['result']\n",
      "[[47, 0], [0, 0]]\n",
      "['.'] ['civil'] ['##von']\n",
      "['.'] ['martin'] ['ongoing']\n",
      "['video'] ['video'] ['city']\n",
      "['reporters'] ['reporters'] ['##s']\n",
      "['investigation'] ['investigation'] ['martin']\n",
      "['the'] ['the'] ['steps']\n",
      "['and'] ['their'] ['york']\n",
      "['of'] ['of'] ['month']\n",
      "['hall'] ['hall'] ['watch']\n",
      "['<'] ['<'] ['talk']\n",
      "['-'] ['-'] ['first']\n",
      "['killed'] ['killed'] ['zimmerman']\n",
      "['.'] ['and'] ['down']\n",
      "['.'] ['federal'] ['justice']\n",
      "['.'] ['rights'] ['martin']\n",
      "['.'] ['\"'] ['members']\n",
      "['attorney'] ['attorney'] ['council']\n",
      "['on'] ['on'] ['pictured']\n",
      "['zimmerman'] ['zimmerman'] ['they']\n",
      "['\"'] ['their'] ['during']\n",
      "['day'] ['the'] ['after']\n",
      "['\"'] ['\"'] ['year']\n",
      "['on'] ['on'] ['shot']\n",
      "['in'] ['in'] ['##man']\n",
      "['\"'] ['\"'] ['co']\n",
      "['\"'] ['no'] ['during']\n",
      "['by'] ['by'] ['##s']\n",
      "['.'] ['zimmerman'] ['told']\n",
      "['.'] ['legal'] ['departments']\n",
      "['general'] ['general'] ['wear']\n",
      "['that'] ['that'] ['memory']\n",
      "['is'] ['is'] ['stand']\n",
      "['york'] ['york'] ['city']\n",
      "['new'] ['new'] ['george']\n",
      "['a'] ['a'] ['counsel']\n",
      "['neighborhood'] ['neighborhood'] ['murder']\n",
      "['.'] ['still'] ['video']\n",
      "['.'] ['do'] ['reporters']\n",
      "['.'] ['charges'] ['investigation']\n",
      "['.'] ['for'] ['george']\n",
      "['eric'] ['eric'] ['hood']\n",
      "['ongoing'] ['ongoing'] ['together']\n",
      "['city'] ['city'] ['hall']\n",
      "['##s'] ['##s'] ['news']\n",
      "['as'] ['as'] ['sanford']\n",
      "['steps'] ['steps'] ['killed']\n",
      "['york'] ['york'] ['zimmerman']\n",
      "['week'] ['week'] ['don']\n",
      "['was'] ['was'] ['jury']\n",
      "['watch'] ['watch'] ['trial']\n",
      "['.'] ['bring'] ['attorney']\n",
      "['.'] ['##j'] ['yesterday']\n",
      "['.'] ['for'] ['into']\n",
      "['.'] ['tea'] ['zimmerman']\n",
      "['\"'] ['\"'] ['##ie']\n",
      "['\"'] ['\"'] ['tray']\n",
      "['\"'] ['\"'] ['poster']\n",
      "['in'] ['in'] ['conference']\n",
      "['as'] ['as'] ['nu']\n",
      "['they'] ['they'] ['florida']\n",
      "['during'] ['during'] ['zimmerman']\n",
      "['after'] ['after'] ['west']\n",
      "['shot'] ['shot'] ['selection']\n",
      "['##man'] ['##man'] ['last']\n",
      "['...'] ['charges'] ['general']\n",
      "['...'] ['could'] ['that']\n",
      "['...'] ['zimmerman'] ['tray']\n",
      "['for'] ['\"'] ['york']\n",
      "['\"'] ['\"'] ['##von']\n",
      "['and'] ['and'] ['board']\n",
      "['on'] ['on'] ['##m']\n",
      "['stand'] ['stand'] ['resident']\n",
      "['the'] ['the'] ['left']\n",
      "['george'] ['george'] ['summer']\n",
      "[[121, 0], [0, 0]]\n",
      "['\"'] ['.'] ['zimmerman']\n",
      "['...'] ['for'] ['criminal']\n",
      "['...'] ['bring'] ['still']\n",
      "['\"'] ['acquitted'] ['sanford']\n",
      "['is'] ['is'] ['year']\n",
      "['.'] ['george'] ['charges']\n",
      "['.'] ['federal'] ['bring']\n",
      "['...'] ['rights'] ['zimmerman']\n",
      "['.'] ['and'] ['with']\n",
      "['of'] ['of'] ['florida']\n",
      "['...'] ['civil'] ['federal']\n",
      "['the'] ['the'] ['when']\n",
      "['can'] ['can'] ['with']\n",
      "['was'] ['was'] ['african']\n",
      "['.'] ['still'] ['acquitted']\n",
      "['...'] ['do'] ['do']\n",
      "['...'] ['charges'] ['civil']\n",
      "['not'] ['not'] ['martin']\n",
      "['him'] [':'] ['nu']\n",
      "['volunteer'] ['volunteer'] ['americans']\n",
      "['.'] ['##j'] ['##j']\n",
      "['.'] ['for'] ['charges']\n",
      "['was'] ['was'] ['watch']\n",
      "['in'] ['be'] ['that']\n",
      "['zimmerman'] ['zimmerman'] ['##m']\n",
      "['with'] ['with'] ['death']\n",
      "['.'] ['may'] ['could']\n",
      "['.'] ['zimmerman'] ['against']\n",
      "[[147, 2], [0, 0]]\n",
      "['.'] ['for'] ['more']\n",
      "['.'] ['george'] ['than']\n",
      "['.'] ['direct'] ['criminal']\n",
      "['.'] ['may'] ['acquitted']\n",
      "['.'] ['possible'] ['court']\n",
      "['.'] ['do'] ['year']\n",
      "['.'] ['bring'] ['murder']\n",
      "['.'] ['up'] ['charges']\n",
      "[[155, 2], [0, 0]]\n",
      "['.'] ['bring'] ['charges']\n",
      "['.'] ['civil'] ['still']\n",
      "['.'] ['her'] ['comments']\n",
      "['.'] ['##j'] ['department']\n",
      "['.'] ['direct'] ['against']\n",
      "['.'] ['rights'] ['looking']\n",
      "['.'] ['\"'] ['thursday']\n",
      "['.'] ['direct'] ['zimmerman']\n",
      "['.'] ['not'] ['justice']\n",
      "['.'] ['charges'] ['however']\n",
      "['.'] ['and'] ['based']\n",
      "['.'] ['bring'] ['could']\n",
      "['.'] ['##j'] ['federal']\n",
      "['.'] ['charges'] ['bring']\n",
      "['.'] ['can'] ['civil']\n",
      "[[170, 2], [0, 0]]\n",
      "['...'] ['for'] ['unusual']\n",
      "['...'] ['civil'] ['months']\n",
      "['...'] ['##j'] ['continued']\n",
      "['.'] ['may'] ['interest']\n",
      "['.'] ['directly'] ['within']\n",
      "['...'] ['do'] ['department']\n",
      "['.'] ['bring'] ['zimmerman']\n",
      "[[177, 2], [0, 0]]\n",
      "['.'] ['for'] ['didn']\n",
      "['...'] ['##j'] ['hill']\n",
      "['...'] ['george'] ['##t']\n",
      "['...'] ['rights'] ['when']\n",
      "['...'] ['may'] ['says']\n",
      "['...'] ['zimmerman'] ['offer']\n",
      "['...'] ['legal'] ['governments']\n",
      "['...'] ['charges'] ['investigation']\n",
      "['...'] ['and'] ['plans']\n",
      "['...'] ['bring'] ['attorney']\n",
      "['...'] ['for'] ['yesterday']\n",
      "['...'] ['up'] ['general']\n",
      "['...'] ['could'] ['details']\n",
      "['...'] ['zimmerman'] ['such']\n",
      "[[191, 2], [0, 0]]\n",
      "['\"'] ['.'] ['when']\n",
      "['.'] ['for'] ['last']\n",
      "['.'] ['\"'] ['probe']\n",
      "['country'] ['country'] ['case']\n",
      "['...'] ['george'] ['november']\n",
      "['about'] ['about'] ['part']\n",
      "['##s'] ['##s'] ['that']\n",
      "['.'] ['legal'] ['officer']\n",
      "['.'] ['still'] ['asked']\n",
      "['.'] ['do'] ['country']\n",
      "['.'] ['charges'] ['didn']\n",
      "['.'] ['and'] ['date']\n",
      "['\"'] ['\"'] ['tried']\n",
      "['.'] ['be'] ['about']\n",
      "['.'] ['##j'] ['##s']\n",
      "['.'] ['for'] ['##t']\n",
      "['he'] ['holder'] ['that']\n",
      "['.'] ['up'] ['zimmerman']\n",
      "['.'] ['could'] ['chief']\n",
      "['.'] ['zimmerman'] ['give']\n",
      "[[211, 2], [0, 0]]\n",
      "['...'] ['for'] ['longer']\n",
      "['...'] ['be'] ['will']\n",
      "['...'] ['george'] ['that']\n",
      "['.'] ['may'] ['sure']\n",
      "['...'] ['zimmerman'] ['will']\n",
      "['...'] ['lee'] ['able']\n",
      "['.'] ['\"'] ['said']\n",
      "['...'] ['still'] ['exactly']\n",
      "['...'] ['do'] ['take']\n",
      "['...'] ['for'] ['point']\n",
      "['...'] ['lee'] ['make']\n",
      "['...'] ['up'] ['much']\n",
      "['...'] ['zimmerman'] ['where']\n",
      "[[224, 2], [0, 0]]\n",
      "['.'] ['for'] ['martin']\n",
      "['.'] ['be'] ['press']\n",
      "['...'] ['black'] ['investigation']\n",
      "['...'] ['and'] ['another']\n",
      "['...'] ['george'] ['shooting']\n",
      "['...'] ['federal'] ['conference']\n",
      "['...'] ['rights'] ['related']\n",
      "['.'] ['parents'] ['african']\n",
      "['.'] ['may'] ['questioned']\n",
      "['\"'] ['and'] ['american']\n",
      "['.'] ['still'] ['again']\n",
      "['...'] ['do'] ['thursday']\n",
      "['and'] ['and'] ['teen']\n",
      "['...'] ['bring'] ['about']\n",
      "['...'] ['for'] ['do']\n",
      "['...'] ['in'] ['shooting']\n",
      "['on'] ['was'] ['michael']\n",
      "['.'] ['zimmerman'] ['##j']\n",
      "['questioned'] ['questioned'] ['brown']\n",
      "[[243, 2], [0, 0]]\n",
      "['.'] ['for'] ['##j']\n",
      "['.'] ['martins'] ['practice']\n",
      "['.'] ['and'] ['that']\n",
      "['.'] ['george'] ['will']\n",
      "['.'] ['federal'] ['police']\n",
      "['.'] ['rights'] ['officers']\n",
      "['.'] ['may'] ['case']\n",
      "['.'] ['civil'] ['force']\n",
      "['.'] ['and'] ['have']\n",
      "['.'] ['bring'] ['said']\n",
      "['.'] ['in'] ['pattern']\n",
      "['.'] ['or'] ['do']\n",
      "['.'] ['can'] ['ferguson']\n",
      "[[256, 2], [0, 0]]\n",
      "['...'] ['for'] ['civil']\n",
      "['...'] ['bring'] ['suburb']\n",
      "['...'] ['child'] ['black']\n",
      "['...'] ['her'] ['shot']\n",
      "['.'] ['##j'] ['probe']\n",
      "['...'] ['george'] ['unrest']\n",
      "['...'] ['federal'] ['after']\n",
      "['\"'] ['\"'] ['year']\n",
      "['...'] ['lawyer'] ['white']\n",
      "['\"'] ['.'] ['killed']\n",
      "['...'] ['for'] ['police']\n",
      "['civil'] ['civil'] ['brown']\n",
      "['...'] ['bring'] ['month']\n",
      "['...'] ['child'] ['officers']\n",
      "['probe'] ['probe'] ['nu']\n",
      "['...'] ['##well'] ['allegedly']\n",
      "['follows'] ['follows'] ['##m']\n",
      "[[273, 2], [0, 0]]\n",
      "['.'] ['.'] ['browns']\n",
      "['.'] ['bring'] ['represented']\n",
      "['.'] ['and'] ['martin']\n",
      "['...'] ['##j'] ['family']\n",
      "['...'] ['george'] ['same']\n",
      "['.'] ['\"'] ['after']\n",
      "['...'] ['zimmerman'] ['civil']\n",
      "['...'] ['direct'] ['tray']\n",
      "['...'] ['and'] ['##na']\n",
      "['.'] ['still'] ['being']\n",
      "['.'] ['do'] ['rights']\n",
      "['.'] ['charges'] ['##von']\n",
      "['the'] ['the'] ['will']\n",
      "['the'] ['the'] ['half']\n",
      "['...'] ['bring'] ['represented']\n",
      "['...'] ['##j'] ['lawyer']\n",
      "['...'] ['for'] ['martins']\n",
      "['same'] ['same'] ['years']\n",
      "['...'] ['zimmerman'] ['parents']\n",
      "['is'] ['is'] ['killed']\n",
      "[[293, 2], [0, 0]]\n",
      "['.'] ['for'] ['their']\n",
      "['.'] ['george'] ['personal']\n",
      "['.'] ['may'] ['martin']\n",
      "['.'] ['zimmerman'] ['support']\n",
      "['.'] ['be'] ['have']\n",
      "['.'] ['bring'] ['also']\n",
      "['.'] ['##j'] ['browns']\n",
      "['...'] ['charges'] ['offered']\n",
      "['...'] ['may'] ['family']\n",
      "[[302, 2], [0, 0]]\n",
      "['.'] ['for'] ['month']\n",
      "['.'] ['be'] ['parents']\n",
      "['.'] ['their'] ['ending']\n",
      "['.'] ['##j'] ['pair']\n",
      "['.'] ['parents'] ['gun']\n",
      "['.'] ['zimmerman'] ['join']\n",
      "['.'] ['lawyer'] ['annual']\n",
      "['.'] ['.'] ['violence']\n",
      "['...'] ['for'] ['event']\n",
      "['.'] ['for'] ['peace']\n",
      "['...'] ['\"'] ['aimed']\n",
      "['.'] ['up'] ['last']\n",
      "[[314, 2], [0, 0]]\n",
      "0.006329113924050633\n",
      "Elapsed Time: 14.400293350219727 seconds\n",
      "Summary 1 of batch\n",
      "['.'] ['##ela'] ['##ela']\n",
      "['.'] ['##s'] ['co']\n",
      "['.'] ['green'] ['##rio']\n",
      "['.'] ['##isa'] ['western']\n",
      "['.'] ['face'] ['long']\n",
      "['.'] ['##zi'] ['##zi']\n",
      "['.'] ['pol'] ['founder']\n",
      "['.'] ['light'] ['front']\n",
      "['.'] ['of'] ['illness']\n",
      "['.'] ['##rio'] ['##mo']\n",
      "['...'] ['##z'] ['##z']\n",
      "['...'] ['to'] ['independence']\n",
      "['...'] ['to'] ['died']\n",
      "['.'] ['leader'] ['##ham']\n",
      "['.'] ['be'] ['movement']\n",
      "['.'] ['defend'] ['tuesday']\n",
      "['in'] ['in'] ['group']\n",
      "['.'] ['mohamed'] ['##ed']\n",
      "['.'] ['the'] ['head']\n",
      "['.'] ['to'] ['pol']\n",
      "['.'] ['rights'] ['after']\n",
      "['algiers'] ['algiers'] ['said']\n",
      "['...'] ['abd'] ['abd']\n",
      "['...'] ['have'] ['##isa']\n",
      "[[20, 4], [0, 0]]\n",
      "['.'] ['##ela'] ['nu']\n",
      "['.'] ['##zi'] ['##m']\n",
      "['.'] ['and'] ['late']\n",
      "[[23, 4], [0, 0]]\n",
      "['.'] ['##isa'] ['chosen']\n",
      "['.'] ['##isa'] ['pol']\n",
      "['.'] ['pol'] ['period']\n",
      "['.'] ['##rio'] ['##isa']\n",
      "['.'] ['##z'] ['nu']\n",
      "['.'] ['##isa'] ['after']\n",
      "['.'] ['to'] ['secretary']\n",
      "['.'] ['leader'] ['##rio']\n",
      "['.'] ['has'] ['##m']\n",
      "['.'] ['##rio'] ['which']\n",
      "['.'] ['be'] ['general']\n",
      "['.'] ['and'] ['front']\n",
      "['...'] ['aggression'] ['will']\n",
      "['.'] ['abd'] ['ordered']\n",
      "['.'] ['have'] ['said']\n",
      "[[38, 4], [0, 0]]\n",
      "['...'] ['##s'] ['week']\n",
      "['...'] ['green'] ['##isa']\n",
      "['...'] ['##isa'] ['based']\n",
      "['...'] ['face'] ['southern']\n",
      "['['] ['##isa'] ['president']\n",
      "['...'] ['##zi'] ['##ef']\n",
      "['...'] ['light'] ['##rio']\n",
      "['...'] ['##rio'] ['abd']\n",
      "['...'] ['to'] ['leader']\n",
      "['...'] ['to'] ['tin']\n",
      "['...'] ['leader'] ['##ela']\n",
      "['...'] ['has'] ['also']\n",
      "['...'] ['be'] ['whose']\n",
      "['...'] ['and'] ['##zi']\n",
      "['...'] ['the'] ['declared']\n",
      "['...'] ['aggression'] ['group']\n",
      "['...'] ['rights'] ['##f']\n",
      "['...'] ['abd'] ['##z']\n",
      "['...'] ['have'] ['pol']\n",
      "[[57, 4], [0, 0]]\n",
      "['.'] ['##ela'] ['##zi']\n",
      "['.'] ['##s'] ['##isa']\n",
      "['.'] ['green'] ['comes']\n",
      "['.'] ['face'] ['western']\n",
      "['...'] ['##isa'] ['death']\n",
      "['.'] ['##zi'] ['##z']\n",
      "['.'] ['pol'] ['##rio']\n",
      "['.'] ['##rio'] ['over']\n",
      "[']'] ['##z'] ['leader']\n",
      "[']'] ['##isa'] ['front']\n",
      "['...'] ['be'] ['time']\n",
      "['.'] ['mohamed'] ['abd']\n",
      "['.'] ['to'] ['four']\n",
      "['.'] ['abd'] ['##ela']\n",
      "['.'] ['hell'] ['pol']\n",
      "['.'] ['have'] ['decades']\n",
      "['.'] ['pol'] ['growing']\n",
      "[[74, 4], [0, 0]]\n",
      "['.'] ['face'] ['withdrew']\n",
      "['.'] ['##isa'] ['pol']\n",
      "['.'] ['light'] ['africa']\n",
      "['.'] ['##rio'] ['##isa']\n",
      "['...'] ['##z'] ['four']\n",
      "['...'] ['to'] ['##s']\n",
      "['.'] ['leader'] ['##rio']\n",
      "['.'] ['has'] ['decades']\n",
      "['.'] ['protect'] ['morocco']\n",
      "['.'] ['.'] ['nu']\n",
      "['.'] ['mohamed'] ['front']\n",
      "['.'] ['to'] ['rich']\n",
      "['.'] ['aggression'] ['coast']\n",
      "['.'] ['rights'] ['after']\n",
      "['the'] ['the'] ['##m']\n",
      "['.'] ['morocco'] ['independence']\n",
      "['.'] ['pol'] ['which']\n",
      "['.'] ['in'] ['spain']\n",
      "[[92, 4], [0, 0]]\n",
      "['.'] ['\"'] ['morocco']\n",
      "['.'] ['##ela'] ['southern']\n",
      "['.'] ['##s'] ['into']\n",
      "['.'] ['green'] ['years']\n",
      "[']'] ['##rio'] ['considers']\n",
      "['.'] ['##rio'] ['development']\n",
      "['.'] ['the'] ['pumped']\n",
      "['.'] ['to'] ['over']\n",
      "[[100, 4], [0, 0]]\n",
      "['.'] ['.'] ['morocco']\n",
      "['...'] ['##ela'] ['##ive']\n",
      "['...'] ['##s'] ['united']\n",
      "['...'] ['green'] ['years']\n",
      "['.'] ['pol'] ['nations']\n",
      "['...'] ['##rio'] ['western']\n",
      "['.'] ['##rio'] ['also']\n",
      "['.'] ['##isa'] ['which']\n",
      "['...'] ['to'] ['help']\n",
      "['.'] ['military'] ['settle']\n",
      "['.'] ['defend'] ['##s']\n",
      "['...'] ['and'] ['increasingly']\n",
      "['...'] ['the'] ['with']\n",
      "['...'] ['to'] ['worked']\n",
      "['...'] ['rights'] ['status']\n",
      "['['] ['pol'] ['issue']\n",
      "[[116, 4], [0, 0]]\n",
      "['.'] ['##ela'] ['born']\n",
      "['.'] ['face'] ['which']\n",
      "['##ela'] ['##ela'] ['nu']\n",
      "['<'] ['<'] ['##s']\n",
      "['##ara'] ['##ara'] ['agency']\n",
      "['.'] ['war'] ['abd']\n",
      "['.'] ['pol'] ['sm']\n",
      "['##zi'] ['##zi'] ['##m']\n",
      "['nu'] ['nu'] ['state']\n",
      "['.'] ['##rio'] ['##ela']\n",
      "['.'] ['to'] ['controlled']\n",
      "['.'] ['to'] ['pol']\n",
      "['.'] ['aggression'] ['helped']\n",
      "['.'] ['leader'] ['##zi']\n",
      "['.'] ['is'] ['nu']\n",
      "['.'] ['##rio'] ['which']\n",
      "['.'] ['military'] ['western']\n",
      "['.'] ['protect'] ['##isa']\n",
      "['.'] ['.'] ['found']\n",
      "['was'] ['was'] ['according']\n",
      "['>'] ['>'] ['ap']\n",
      "['.'] ['mohamed'] ['##z']\n",
      "['.'] ['been'] ['##m']\n",
      "['.'] ['rights'] ['##rio']\n",
      "['mr'] ['mr'] ['since']\n",
      "['in'] ['in'] ['##s']\n",
      "['.'] ['in'] ['front']\n",
      "['sm'] ['sm'] ['news']\n",
      "[[144, 4], [0, 0]]\n",
      "['...'] ['##ela'] ['prompted']\n",
      "['...'] ['##s'] ['african']\n",
      "['...'] ['##isa'] ['issue']\n",
      "['...'] ['pol'] ['neighbors']\n",
      "['.'] ['##isa'] ['morocco']\n",
      "['.'] ['leader'] ['western']\n",
      "['.'] ['has'] ['between']\n",
      "['.'] ['for'] ['north']\n",
      "[[152, 4], [0, 0]]\n",
      "['.'] ['##ela'] ['front']\n",
      "['.'] ['##s'] ['countries']\n",
      "['...'] ['green'] ['democratic']\n",
      "['.'] ['light'] ['republic']\n",
      "['...'] ['##z'] ['like']\n",
      "['.'] ['leader'] ['pol']\n",
      "['.'] ['has'] ['numerous']\n",
      "['.'] ['military'] ['defend']\n",
      "['.'] ['dr'] ['##isa']\n",
      "['.'] ['died'] ['other']\n",
      "['.'] ['to'] ['##wi']\n",
      "['.'] ['aggression'] ['##s']\n",
      "['...'] ['abd'] ['##rio']\n",
      "['...'] ['hell'] ['african']\n",
      "[[166, 4], [0, 0]]\n",
      "['...'] ['pol'] ['pol']\n",
      "['...'] ['light'] ['self']\n",
      "['...'] ['##rio'] ['government']\n",
      "['...'] ['##isa'] ['##isa']\n",
      "['...'] ['to'] ['local']\n",
      "['...'] ['##rio'] ['##rio']\n",
      "['...'] ['military'] ['through']\n",
      "['...'] ['mohamed'] ['proposed']\n",
      "['...'] ['the'] ['region']\n",
      "['...'] ['to'] ['front']\n",
      "['...'] ['abd'] ['wide']\n",
      "['...'] ['have'] ['insists']\n",
      "['...'] ['in'] ['called']\n",
      "[[176, 7], [0, 0]]\n",
      "['\"'] ['\"'] ['morocco']\n",
      "['...'] ['##ela'] ['staff']\n",
      "['...'] ['face'] ['western']\n",
      "['...'] ['##zi'] ['last']\n",
      "['...'] ['pol'] ['chief']\n",
      "['...'] ['##rio'] ['visit']\n",
      "['...'] ['##rio'] ['most']\n",
      "['...'] ['##z'] ['month']\n",
      "['...'] ['##isa'] ['used']\n",
      "['...'] ['aggression'] ['refugees']\n",
      "['...'] ['has'] ['after']\n",
      "['...'] ['to'] ['word']\n",
      "['...'] ['force'] ['situation']\n",
      "['...'] ['rights'] ['camp']\n",
      "['morocco'] ['morocco'] ['southern']\n",
      "['['] ['pol'] ['following']\n",
      "[[192, 7], [0, 0]]\n",
      "['...'] ['face'] ['council']\n",
      "['...'] ['##isa'] ['april']\n",
      "['...'] ['##zi'] ['pol']\n",
      "['...'] ['of'] ['fails']\n",
      "['...'] ['##z'] ['##isa']\n",
      "['...'] ['to'] ['possible']\n",
      "['member'] ['member'] ['vote']\n",
      "['...'] ['has'] ['##rio']\n",
      "['...'] ['##rio'] ['##ed']\n",
      "['...'] ['military'] ['over']\n",
      "['...'] ['and'] ['member']\n",
      "['...'] ['the'] ['front']\n",
      "['...'] ['to'] ['warned']\n",
      "['the'] ['the'] ['self']\n",
      "['...'] ['have'] ['that']\n",
      "['...'] ['pol'] ['disputed']\n",
      "['...'] ['in'] ['security']\n",
      "[[209, 7], [0, 0]]\n",
      "['...'] ['##s'] ['secretary']\n",
      "['...'] ['green'] ['morocco']\n",
      "['...'] ['face'] ['security']\n",
      "['##ela'] ['##ela'] ['direct']\n",
      "['...'] ['##isa'] ['abd']\n",
      "['...'] ['pol'] ['general']\n",
      "['...'] ['light'] ['will']\n",
      "['...'] ['of'] ['council']\n",
      "['##zi'] ['##zi'] ['pressure']\n",
      "['...'] ['##rio'] ['##ela']\n",
      "['...'] ['##z'] ['letter']\n",
      "['...'] ['to'] ['have']\n",
      "['...'] ['to'] ['military']\n",
      "['...'] ['leader'] ['##zi']\n",
      "['...'] ['##rio'] ['ki']\n",
      "['...'] ['defend'] ['aggression']\n",
      "['.'] ['.'] ['##s']\n",
      "['\"'] ['is'] ['morocco']\n",
      "['...'] ['mohamed'] ['##z']\n",
      "['...'] ['to'] ['moon']\n",
      "['...'] ['aggression'] ['green']\n",
      "['...'] ['rights'] ['unless']\n",
      "['mr'] ['mr'] ['real']\n",
      "['secretary'] ['secretary'] ['work']\n",
      "['...'] ['abd'] ['warned']\n",
      "['...'] ['have'] ['that']\n",
      "['...'] ['pol'] ['light']\n",
      "['a'] ['a'] ['restore']\n",
      "[[237, 7], [0, 0]]\n",
      "['...'] ['##ela'] ['##wi']\n",
      "['.'] ['##s'] ['defend']\n",
      "['...'] ['##isa'] ['including']\n",
      "['.'] ['##isa'] ['warned']\n",
      "['.'] ['##zi'] ['people']\n",
      "['.'] ['pol'] ['their']\n",
      "['.'] ['light'] ['aggression']\n",
      "['.'] ['##rio'] ['armed']\n",
      "['.'] ['##rio'] ['that']\n",
      "['.'] ['##isa'] ['rights']\n",
      "['.'] ['as'] ['western']\n",
      "['...'] ['mohamed'] ['sa']\n",
      "['.'] ['for'] ['will']\n",
      "['.'] ['have'] ['face']\n",
      "['.'] ['pol'] ['means']\n",
      "[[252, 7], [0, 0]]\n",
      "['...'] ['##isa'] ['pol']\n",
      "['...'] ['##rio'] ['##isa']\n",
      "['...'] ['leader'] ['##rio']\n",
      "['...'] ['has'] ['against']\n",
      "['.'] ['the'] ['morocco']\n",
      "['...'] ['hell'] ['after']\n",
      "[[258, 7], [0, 0]]\n",
      "['.'] ['##ela'] ['north']\n",
      "['.'] ['##s'] ['international']\n",
      "['.'] ['##isa'] ['death']\n",
      "['project'] ['project'] ['time']\n",
      "['group'] ['group'] ['pressure']\n",
      "['...'] ['##zi'] ['africa']\n",
      "['...'] ['pol'] ['crisis']\n",
      "['...'] ['of'] ['unclear']\n",
      "['director'] ['director'] ['when']\n",
      "['.'] ['##rio'] ['##r']\n",
      "[']'] ['##z'] ['project']\n",
      "['...'] ['##isa'] ['group']\n",
      "['...'] ['to'] ['abd']\n",
      "['am'] ['am'] ['adds']\n",
      "[']'] ['has'] ['director']\n",
      "[']'] ['##rio'] ['said']\n",
      "[']'] ['military'] ['##ela']\n",
      "['##rani'] ['##rani'] ['uncertainty']\n",
      "['the'] ['the'] ['mission']\n",
      "['...'] ['mohamed'] ['am']\n",
      "['...'] ['death'] ['with']\n",
      "['...'] ['force'] ['##zi']\n",
      "['iss'] ['iss'] ['immediate']\n",
      "['...'] ['have'] ['impact']\n",
      "['...'] ['pol'] ['##z']\n",
      "['##and'] ['##and'] ['future']\n",
      "['crisis'] ['crisis'] ['under']\n",
      "[[285, 7], [0, 0]]\n",
      "['.'] ['##s'] ['##isa']\n",
      "['.'] ['pol'] ['##rio']\n",
      "['.'] ['##rio'] ['am']\n",
      "['.'] ['##isa'] ['activists']\n",
      "['.'] ['has'] ['among']\n",
      "['.'] ['the'] ['some']\n",
      "['.'] ['hell'] ['pol']\n",
      "['.'] ['have'] ['absence']\n",
      "[[293, 7], [0, 0]]\n",
      "['.'] ['##ela'] ['will']\n",
      "[\"'\"] ['##isa'] ['next']\n",
      "['...'] ['##zi'] ['have']\n",
      "['.'] ['##rio'] ['pol']\n",
      "['...'] ['leader'] ['##isa']\n",
      "['...'] ['##rio'] ['am']\n",
      "['.'] ['and'] ['##rio']\n",
      "['.'] ['been'] ['with']\n",
      "['.'] ['abd'] ['leader']\n",
      "['.'] ['for'] ['that']\n",
      "['.'] ['have'] ['said']\n",
      "[[304, 7], [0, 0]]\n",
      "['.'] ['##ela'] ['appointed']\n",
      "['.'] ['##s'] ['national']\n",
      "['.'] ['##isa'] ['##rio']\n",
      "['.'] ['##isa'] ['pol']\n",
      "['.'] ['pol'] ['council']\n",
      "['.'] ['light'] ['##h']\n",
      "['.'] ['##rio'] ['leader']\n",
      "['.'] ['##rio'] ['##isa']\n",
      "['...'] ['##z'] ['head']\n",
      "['.'] ['##isa'] ['k']\n",
      "['.'] ['leader'] ['##rio']\n",
      "['...'] ['and'] ['front']\n",
      "['...'] ['to'] ['##ri']\n",
      "['...'] ['use'] ['pol']\n",
      "['.'] ['have'] ['abd']\n",
      "['.'] ['pol'] ['##isa']\n",
      "[[320, 7], [0, 0]]\n",
      "['.'] ['##ela'] ['press']\n",
      "['.'] ['##rio'] ['nu']\n",
      "['.'] ['leader'] ['##m']\n",
      "['.'] ['abd'] ['associated']\n",
      "[[324, 7], [0, 0]]\n",
      "0.021148036253776436\n",
      "Elapsed Time: 12.75370979309082 seconds\n",
      "Summary 2 of batch\n",
      "['.'] ['.'] ['washington']\n",
      "['.'] ['surplus'] ['april']\n",
      "['.'] ['family'] ['years']\n",
      "['...'] ['avoid'] ['stock']\n",
      "['create'] ['\"'] ['##ier']\n",
      "['budget'] ['budget'] ['budget']\n",
      "['...'] ['receipts'] ['##ta']\n",
      "['the'] ['the'] ['americans']\n",
      "['surplus'] ['deficit'] ['picture']\n",
      "['.'] ['boost'] ['##x']\n",
      "['.'] ['out'] ['budget']\n",
      "['.'] ['using'] ['latest']\n",
      "['\"'] ['\"'] ['rising']\n",
      "['.'] ['u'] ['receipts']\n",
      "['.'] ['of'] ['surplus']\n",
      "['.'] ['emergency'] ['sign']\n",
      "['the'] ['\"'] ['##ft']\n",
      "['in'] ['in'] ['incomes']\n",
      "['monthly'] ['\"'] ['improving']\n",
      "['.'] ['$'] ['largest']\n",
      "['.'] ['measures'] ['that']\n",
      "['washington'] ['news'] ['##y']\n",
      "['.'] ['no'] ['monthly']\n",
      "['.'] ['older'] ['seven']\n",
      "['...'] ['to'] ['climbing']\n",
      "['\"'] ['##ta'] ['corporate']\n",
      "['s'] ['s'] ['nations']\n",
      "[[26, 0], [0, 1]]\n",
      "['.'] ['exchequer'] ['record']\n",
      "['.'] ['##m'] ['last']\n",
      "['s'] ['s'] ['billion']\n",
      "['.'] ['>'] ['month']\n",
      "['.'] ['treasury'] ['from']\n",
      "['treasury'] ['treasury'] ['surplus']\n",
      "['.'] ['taxes'] ['nu']\n",
      "['.'] ['u'] ['treasury']\n",
      "['.'] ['are'] ['##m']\n",
      "['.'] ['emergency'] ['year']\n",
      "['.'] ['.'] ['nu']\n",
      "['.'] ['year'] ['nu']\n",
      "['.'] ['measures'] ['earlier']\n",
      "['the'] ['the'] ['##m']\n",
      "['record'] ['record'] ['month']\n",
      "['.'] ['nu'] ['billion']\n",
      "['.'] ['of'] ['##m']\n",
      "['.'] ['to'] ['leading']\n",
      "[[44, 0], [0, 1]]\n",
      "['.'] ['.'] ['while']\n",
      "['.'] ['avoid'] ['more']\n",
      "['u'] ['u'] ['fifth']\n",
      "['.'] ['corporate'] ['surplus']\n",
      "['.'] ['>'] ['filing']\n",
      "['.'] ['ceiling'] ['than']\n",
      "['s'] ['s'] ['largest']\n",
      "['.'] ['out'] ['season']\n",
      "['.'] ['using'] ['nu']\n",
      "['.'] ['deficit'] ['last']\n",
      "['typically'] ['often'] ['monthly']\n",
      "['.'] ['were'] ['april']\n",
      "['.'] ['of'] ['this']\n",
      "['.'] ['emergency'] ['##m']\n",
      "['\"'] ['.'] ['years']\n",
      "['has'] ['has'] ['surplus']\n",
      "['.'] ['year'] ['years']\n",
      "['.'] ['of'] ['surplus']\n",
      "['.'] ['to'] ['billion']\n",
      "['surplus'] ['deficit'] ['record']\n",
      "[[64, 0], [0, 1]]\n",
      "['.'] ['##m'] ['previous']\n",
      "['.'] ['avoid'] ['from']\n",
      "['.'] ['receipts'] ['boost']\n",
      "['receipts'] ['receipts'] ['march']\n",
      "['deficit'] ['deficit'] ['billion']\n",
      "['.'] ['taxes'] ['budget']\n",
      "['.'] ['ahead'] ['nu']\n",
      "['.'] ['using'] ['nu']\n",
      "['.'] ['deficit'] ['nu']\n",
      "['.'] ['u'] ['receipts']\n",
      "['.'] ['running'] ['deficit']\n",
      "['.'] ['of'] ['##m']\n",
      "['.'] ['emergency'] ['##m']\n",
      "['\"'] ['.'] ['##m']\n",
      "['u'] ['u'] ['nu']\n",
      "['.'] ['and'] ['months']\n",
      "['.'] ['to'] ['billion']\n",
      "['\"'] ['increase'] ['billion']\n",
      "['s'] ['s'] ['##m']\n",
      "['\"'] ['\"'] ['year']\n",
      "[[84, 0], [0, 1]]\n",
      "['.'] ['exchequer'] ['since']\n",
      "['.'] ['##m'] ['lowest']\n",
      "['.'] ['financial'] ['last']\n",
      "['.'] ['>'] ['since']\n",
      "['.'] ['taxes'] ['november']\n",
      "['.'] ['ahead'] ['september']\n",
      "['.'] ['u'] ['lowest']\n",
      "['.'] ['s'] ['annual']\n",
      "['.'] ['year'] ['nu']\n",
      "['.'] ['fund'] ['deficit']\n",
      "['.'] ['nu'] ['second']\n",
      "['.'] ['of'] ['##m']\n",
      "[[96, 0], [0, 1]]\n",
      "['\"'] ['.'] ['over']\n",
      "['.'] ['##m'] ['nu']\n",
      "['.'] ['and'] ['earlier']\n",
      "['.'] ['fund'] ['months']\n",
      "['.'] ['>'] ['##m']\n",
      "['...'] ['treasury'] ['level']\n",
      "['.'] ['the'] ['nu']\n",
      "['.'] ['on'] ['past']\n",
      "['.'] ['using'] ['while']\n",
      "['.'] ['deficit'] ['##m']\n",
      "['.'] ['of'] ['above']\n",
      "['.'] ['emergency'] ['spending']\n",
      "['.'] ['s'] ['nu']\n",
      "['.'] ['\"'] ['running']\n",
      "['.'] ['year'] ['their']\n",
      "['over'] ['over'] ['higher']\n",
      "['.'] ['budget'] ['##m']\n",
      "['...'] ['earlier'] ['year']\n",
      "['...'] ['to'] ['running']\n",
      "[[115, 0], [0, 1]]\n",
      "['...'] ['##m'] ['that']\n",
      "['...'] ['level'] ['their']\n",
      "['...'] ['avoid'] ['wind']\n",
      "['illustrate'] ['illustrate'] ['treasury']\n",
      "['...'] ['receipts'] ['figures']\n",
      "['...'] ['corporate'] ['over']\n",
      "['...'] ['treasury'] ['rising']\n",
      "['...'] ['taxes'] ['income']\n",
      "['...'] ['out'] ['rich']\n",
      "['...'] ['using'] ['incomes']\n",
      "['...'] ['s'] ['despite']\n",
      "['...'] ['year'] ['paying']\n",
      "['...'] ['budget'] ['growing']\n",
      "['...'] ['te'] ['taxes']\n",
      "[[129, 0], [0, 1]]\n",
      "['.'] ['##m'] ['april']\n",
      "['.'] ['level'] ['those']\n",
      "['rose'] ['rose'] ['##m']\n",
      "['.'] ['\"'] ['taxes']\n",
      "['.'] ['corporate'] ['from']\n",
      "['.'] ['>'] ['while']\n",
      "['.'] ['tax'] ['incomes']\n",
      "['.'] ['from'] ['rose']\n",
      "['.'] ['ahead'] ['other']\n",
      "['.'] ['using'] ['capital']\n",
      "['.'] ['deficit'] ['were']\n",
      "['...'] ['were'] ['year']\n",
      "['...'] ['emergency'] ['gains']\n",
      "['.'] ['s'] ['nu']\n",
      "['.'] ['<'] ['earlier']\n",
      "['.'] ['year'] ['taxes']\n",
      "['.'] ['budget'] ['##m']\n",
      "['...'] ['of'] ['including']\n",
      "['...'] ['to'] ['self']\n",
      "['taxes'] ['taxes'] ['nu']\n",
      "[[149, 0], [0, 1]]\n",
      "['\"'] ['.'] ['corporate']\n",
      "['...'] ['family'] ['co']\n",
      "['.'] ['on'] ['have']\n",
      "['.'] ['taxes'] ['##s']\n",
      "['.'] ['u'] ['also']\n",
      "['.'] ['fund'] ['federal']\n",
      "[[155, 0], [0, 1]]\n",
      "['.'] ['deficit'] ['last']\n",
      "['.'] ['##m'] ['running']\n",
      "['.'] ['sales'] ['october']\n",
      "['.'] ['treasury'] ['their']\n",
      "['.'] ['taxes'] ['gross']\n",
      "['.'] ['ahead'] ['nu']\n",
      "['...'] ['using'] ['year']\n",
      "['.'] ['u'] ['year']\n",
      "['.'] ['running'] ['corporate']\n",
      "['.'] ['of'] ['##m']\n",
      "['.'] ['emergency'] ['earlier']\n",
      "['.'] ['s'] ['that']\n",
      "['.'] ['<'] ['taxes']\n",
      "['.'] ['measures'] ['level']\n",
      "['.'] ['budget'] ['began']\n",
      "['.'] ['earlier'] ['ahead']\n",
      "[[171, 0], [0, 1]]\n",
      "['...'] ['tax'] ['nu']\n",
      "['.'] ['level'] ['##m']\n",
      "['.'] ['corporate'] ['##m']\n",
      "['.'] ['ceiling'] ['solid']\n",
      "['the'] ['the'] ['energy']\n",
      "['.'] ['boost'] ['first']\n",
      "['.'] ['using'] ['from']\n",
      "['.'] ['deficit'] ['corporate']\n",
      "['of'] ['of'] ['capital']\n",
      "['['] ['<'] ['##s']\n",
      "['.'] ['u'] ['quarter']\n",
      "['.'] ['from'] ['estimated']\n",
      "['.'] ['of'] ['rose']\n",
      "['['] ['<'] ['spending']\n",
      "['and'] ['lia'] ['this']\n",
      "['nu'] ['nu'] ['said']\n",
      "['.'] ['measures'] ['year']\n",
      "['nu'] ['nu'] ['outside']\n",
      "['##bilities'] ['##bilities'] ['year']\n",
      "['##m'] ['##m'] ['tuesday']\n",
      "['.'] ['and'] ['nu']\n",
      "['.'] ['to'] ['earlier']\n",
      "[[193, 0], [0, 1]]\n",
      "['.'] ['treasury'] ['march']\n",
      "['.'] ['##m'] ['rise']\n",
      "['.'] ['family'] ['billion']\n",
      "['.'] ['prevent'] ['##m']\n",
      "['.'] ['taxes'] ['congressional']\n",
      "['.'] ['corporate'] ['that']\n",
      "['.'] ['treasury'] ['this']\n",
      "['.'] ['fund'] ['budget']\n",
      "['.'] ['using'] ['year']\n",
      "['.'] ['deficit'] ['billion']\n",
      "['.'] [\"'\"] ['office']\n",
      "['.'] ['-'] ['federal']\n",
      "['.'] ['of'] ['nu']\n",
      "['.'] ['emergency'] ['from']\n",
      "['.'] ['.'] ['last']\n",
      "['.'] ['s'] ['forecast']\n",
      "['.'] ['$'] ['deficit']\n",
      "['.'] ['year'] ['##m']\n",
      "['the'] ['the'] ['year']\n",
      "['.'] ['nu'] ['would']\n",
      "['.'] ['to'] ['nu']\n",
      "[[214, 0], [0, 1]]\n",
      "['\"'] ['.'] ['analysts']\n",
      "['.'] ['family'] ['deficit']\n",
      "['...'] ['office'] ['forecast']\n",
      "['.'] ['u'] ['latest']\n",
      "['.'] ['running'] ['will']\n",
      "['.'] ['of'] ['receipts']\n",
      "['.'] ['s'] ['figures']\n",
      "['.'] ['$'] ['fall']\n",
      "['...'] ['no'] ['given']\n",
      "[[223, 0], [0, 1]]\n",
      "['.'] ['.'] ['higher']\n",
      "['.'] ['##m'] ['from']\n",
      "['...'] ['avoid'] ['lowering']\n",
      "['.'] ['\"'] ['year']\n",
      "['spending'] ['spending'] ['chief']\n",
      "['...'] ['corporate'] ['government']\n",
      "['...'] ['>'] ['en']\n",
      "['...'] ['treasury'] ['certain']\n",
      "['that'] ['that'] ['said']\n",
      "['this'] ['this'] ['political']\n",
      "['##tlement'] ['##tlement'] ['research']\n",
      "['.'] ['from'] ['mean']\n",
      "['...'] ['taxes'] ['spending']\n",
      "['...'] ['ahead'] ['##ti']\n",
      "['...'] ['using'] ['that']\n",
      "['.'] ['deficit'] ['deficit']\n",
      "['\"'] ['\"'] ['greg']\n",
      "['programs'] ['programs'] ['group']\n",
      "['.'] ['u'] ['that']\n",
      "['...'] ['running'] ['this']\n",
      "['...'] ['emergency'] ['more']\n",
      "['.'] ['s'] ['despite']\n",
      "['...'] ['$'] ['year']\n",
      "['...'] ['higher'] ['likely']\n",
      "['...'] ['fund'] ['increases']\n",
      "['revenues'] ['revenues'] ['this']\n",
      "['government'] ['government'] ['##e']\n",
      "[[249, 1], [0, 1]]\n",
      "['...'] ['debt'] ['potential']\n",
      "['...'] ['avoid'] ['coming']\n",
      "['...'] ['receipts'] ['latest']\n",
      "['...'] ['>'] ['congressional']\n",
      "['...'] ['treasury'] ['government']\n",
      "['could'] ['could'] ['nu']\n",
      "['.'] ['tax'] ['figures']\n",
      "['.'] ['taxes'] ['between']\n",
      "['.'] ['out'] ['republicans']\n",
      "['.'] ['bank'] ['spending']\n",
      "['.'] ['deficit'] ['year']\n",
      "['be'] ['be'] ['##m']\n",
      "['...'] ['u'] ['could']\n",
      "['...'] ['were'] ['president']\n",
      "['...'] ['of'] ['over']\n",
      "['...'] ['emergency'] ['levels']\n",
      "['.'] ['.'] ['that']\n",
      "['...'] ['s'] ['also']\n",
      "['...'] ['<'] ['barack']\n",
      "['...'] ['nu'] ['obama']\n",
      "[[269, 1], [0, 1]]\n",
      "['...'] ['exchequer'] ['rise']\n",
      "['...'] ['##m'] ['caps']\n",
      "['...'] ['and'] ['years']\n",
      "['the'] ['the'] ['spending']\n",
      "['...'] ['\"'] ['obama']\n",
      "['...'] ['corporate'] ['above']\n",
      "['...'] ['>'] ['that']\n",
      "['...'] ['as'] ['congress']\n",
      "['...'] ['deficit'] ['defense']\n",
      "['that'] ['that'] ['increases']\n",
      "['.'] ['u'] ['insisted']\n",
      "['.'] ['running'] ['across']\n",
      "['.'] ['of'] ['agreed']\n",
      "['...'] ['emergency'] ['that']\n",
      "['.'] [','] ['budget']\n",
      "['...'] ['s'] ['that']\n",
      "['mr'] ['mr'] ['should']\n",
      "['rise'] ['rise'] ['other']\n",
      "['...'] ['fund'] ['spending']\n",
      "['...'] ['nu'] ['board']\n",
      "['...'] ['-'] ['four']\n",
      "['...'] ['to'] ['increases']\n",
      "['above'] ['above'] ['domestic']\n",
      "[[292, 1], [0, 1]]\n",
      "['\"'] ['.'] ['republicans']\n",
      "['.'] ['##m'] ['require']\n",
      "['.'] ['and'] ['place']\n",
      "['.'] ['fund'] ['budget']\n",
      "['.'] ['>'] ['presidential']\n",
      "['.'] ['fund'] ['congress']\n",
      "['.'] ['taxes'] ['resolution']\n",
      "['.'] ['as'] ['approval']\n",
      "['.'] ['\"'] ['last']\n",
      "['...'] ['\"'] ['which']\n",
      "['...'] ['emergency'] ['##s']\n",
      "['.'] ['s'] ['week']\n",
      "['.'] ['$'] ['doesn']\n",
      "['.'] ['year'] ['keep']\n",
      "['.'] ['no'] ['##t']\n",
      "[[307, 1], [0, 1]]\n",
      "['...'] ['tax'] ['##m']\n",
      "['...'] ['.'] ['that']\n",
      "['...'] ['avoid'] ['se']\n",
      "['billion'] ['billion'] ['over']\n",
      "['...'] ['\"'] ['they']\n",
      "['...'] ['>'] ['separate']\n",
      "['\"'] ['\"'] ['defense']\n",
      "['in'] ['in'] ['military']\n",
      "['...'] ['on'] ['added']\n",
      "['...'] ['taxes'] ['billion']\n",
      "['...'] ['above'] ['account']\n",
      "['...'] ['\"'] ['##t']\n",
      "['...'] ['deficit'] ['##er']\n",
      "['\"'] ['\"'] ['spending']\n",
      "['...'] ['u'] ['nearly']\n",
      "['...'] ['emergency'] ['subject']\n",
      "['.'] ['<'] ['spending']\n",
      "['but'] ['but'] ['pl']\n",
      "['...'] ['budget'] ['nu']\n",
      "['.'] ['nu'] ['using']\n",
      "['...'] ['and'] ['funding']\n",
      "[[328, 1], [0, 1]]\n",
      "['.'] ['treasury'] ['deficit']\n",
      "['.'] ['avoid'] ['economic']\n",
      "['administration'] ['administration'] ['force']\n",
      "['.'] ['receipts'] ['obama']\n",
      "['.'] ['corporate'] ['##s']\n",
      "['.'] ['>'] ['nu']\n",
      "['.'] ['ceiling'] ['growth']\n",
      "['...'] ['boost'] ['administration']\n",
      "['...'] ['out'] ['##m']\n",
      "['...'] ['emergency'] ['steps']\n",
      "['...'] ['<'] ['contained']\n",
      "['...'] ['measures'] ['that']\n",
      "['...'] ['fund'] ['that']\n",
      "['...'] ['nu'] ['below']\n",
      "['...'] ['to'] ['boost']\n",
      "[[343, 1], [0, 1]]\n",
      "['.'] ['debt'] ['republicans']\n",
      "['.'] ['taxes'] ['their']\n",
      "['.'] ['corporate'] ['proposed']\n",
      "['.'] ['treasury'] ['deficit']\n",
      "['.'] ['boost'] ['budget']\n",
      "['.'] ['ahead'] ['spending']\n",
      "['.'] ['using'] ['over']\n",
      "['.'] ['u'] ['resolution']\n",
      "['.'] ['\"'] ['nu']\n",
      "['.'] ['of'] ['cuts']\n",
      "['.'] ['s'] ['last']\n",
      "['...'] ['$'] ['##m']\n",
      "['...'] ['measures'] ['coming']\n",
      "['.'] ['budget'] ['week']\n",
      "['...'] ['to'] ['decade']\n",
      "[[358, 1], [0, 1]]\n",
      "['('] ['receipts'] ['congress']\n",
      "['('] ['family'] ['federal']\n",
      "['...'] ['running'] ['limit']\n",
      "['...'] ['budget'] ['raise']\n",
      "[[362, 1], [0, 1]]\n",
      "['.'] ['debt'] ['emergency']\n",
      "['.'] ['##m'] ['avoid']\n",
      "['.'] ['receipts'] ['treasury']\n",
      "['.'] ['financial'] ['measures']\n",
      "['.'] ['>'] ['breach']\n",
      "['.'] ['boost'] ['department']\n",
      "['.'] ['taxes'] ['since']\n",
      "['.'] ['ahead'] ['##ing']\n",
      "['.'] ['s'] ['been']\n",
      "['.'] ['/'] ['march']\n",
      "['.'] ['year'] ['ceiling']\n",
      "['.'] ['debt'] ['using']\n",
      "[[374, 1], [0, 1]]\n",
      "['...'] ['the'] ['##o']\n",
      "['...'] ['avoid'] ['measures']\n",
      "['hasn'] ['hasn'] ['november']\n",
      "['...'] ['receipts'] ['treasury']\n",
      "['...'] ['corporate'] ['long']\n",
      "['...'] ['>'] ['do']\n",
      "['...'] ['treasury'] ['estimated']\n",
      "['...'] ['fund'] ['should']\n",
      "['.'] ['fund'] ['hasn']\n",
      "['.'] ['as'] ['that']\n",
      "['...'] ['deficit'] ['last']\n",
      "['...'] ['u'] ['##t']\n",
      "['...'] ['running'] ['might']\n",
      "['...'] ['emergency'] ['march']\n",
      "['...'] ['.'] ['until']\n",
      "['...'] ['measures'] ['that']\n",
      "['the'] ['the'] ['october']\n",
      "['...'] ['fund'] ['said']\n",
      "['...'] ['nu'] ['able']\n",
      "['...'] ['to'] ['those']\n",
      "[[394, 1], [0, 1]]\n",
      "['credits'] ['.'] ['write']\n",
      "['.'] ['##m'] ['##s']\n",
      "['.'] ['fund'] ['nick']\n",
      "['.'] ['>'] ['##j']\n",
      "['.'] ['support'] ['nick']\n",
      "['.'] ['as'] ['com']\n",
      "['.'] ['$'] ['##os']\n",
      "['.'] ['debt'] ['##os']\n",
      "['.'] ['no'] ['w']\n",
      "[[403, 1], [0, 1]]\n",
      "0.0024691358024691358\n",
      "Elapsed Time: 14.130777597427368 seconds\n",
      "Summary 3 of batch\n",
      "['.'] ['.'] ['low']\n",
      "['.'] ['expert'] ['almost']\n",
      "['a'] ['the'] ['##zz']\n",
      "['contains'] ['is'] ['##s']\n",
      "['with'] ['with'] ['dso']\n",
      "['of'] ['of'] ['about']\n",
      "['.'] ['##a'] ['cal']\n",
      "['.'] ['amanda'] ['same']\n",
      "['.'] ['says'] ['half']\n",
      "['.'] ['cal'] ['regular']\n",
      "['.'] ['actually'] ['with']\n",
      "['.'] ['##s'] ['years']\n",
      "['.'] ['low'] ['gu']\n",
      "['\"'] ['\"'] ['##uz']\n",
      "['a'] ['a'] ['champagne']\n",
      "['.'] ['so'] ['##ori']\n",
      "['.'] ['now'] ['amount']\n",
      "['.'] ['##ori'] ['glass']\n",
      "['.'] ['the'] ['over']\n",
      "['.'] ['new'] ['experience']\n",
      "['same'] ['same'] ['much']\n",
      "['half'] ['half'] ['##a']\n",
      "['.'] ['mum'] ['##e']\n",
      "['.'] ['has'] ['cal']\n",
      "['.'] ['##ser'] ['fashion']\n",
      "['amount'] ['amount'] ['that']\n",
      "['the'] ['the'] ['doesn']\n",
      "['.'] ['##a'] ['champagne']\n",
      "['.'] ['cocaine'] ['nu']\n",
      "['of'] ['##e'] ['industry']\n",
      "['of'] ['of'] ['christ']\n",
      "['cal'] ['cal'] ['##t']\n",
      "['.'] ['on'] ['contains']\n",
      "['.'] ['wine'] ['with']\n",
      "['.'] ['sugar'] ['style']\n",
      "['.'] ['amanda'] ['##m']\n",
      "['.'] ['champagne'] ['fi']\n",
      "['champagne'] ['champagne'] ['there']\n",
      "['alcohol'] ['alcohol'] ['##a']\n",
      "['##ories'] ['##ories'] ['know']\n",
      "[[40, 0], [0, 0]]\n",
      "['...'] ['champagne'] ['that']\n",
      "['...'] ['low'] ['much']\n",
      "['...'] ['amanda'] ['things']\n",
      "['...'] ['says'] ['decade']\n",
      "['...'] ['now'] ['doesn']\n",
      "['...'] ['she'] ['##nt']\n",
      "['...'] ['##uz'] ['does']\n",
      "['...'] ['a'] ['##t']\n",
      "['...'] ['has'] ['drink']\n",
      "['...'] ['##a'] ['know']\n",
      "['...'] ['french'] ['actually']\n",
      "['...'] ['wine'] ['like']\n",
      "['...'] ['a'] ['that']\n",
      "[[53, 0], [0, 0]]\n",
      "['of'] ['of'] ['hair']\n",
      "['when'] ['when'] ['british']\n",
      "['magazines'] ['magazines'] ['when']\n",
      "['teeth'] ['teeth'] ['causing']\n",
      "['...'] ['amanda'] ['those']\n",
      "['...'] ['drink'] ['first']\n",
      "['...'] ['actually'] ['those']\n",
      "['...'] ['##s'] ['with']\n",
      "['it'] ['it'] ['slightly']\n",
      "['i'] ['i'] ['nu']\n",
      "['all'] ['all'] ['they']\n",
      "[\"'\"] ['women'] ['latest']\n",
      "[\"'\"] ['her'] ['me']\n",
      "['...'] ['##ori'] ['started']\n",
      "['...'] ['the'] ['over']\n",
      "['had'] ['had'] ['##m']\n",
      "['first'] ['first'] ['told']\n",
      "['those'] ['those'] ['asked']\n",
      "['slightly'] ['slightly'] ['stir']\n",
      "['...'] ['a'] ['##ed']\n",
      "['...'] ['crack'] ['made']\n",
      "['me'] ['me'] ['##ew']\n",
      "['lipstick'] ['lipstick'] ['champagne']\n",
      "['...'] ['##a'] ['much']\n",
      "['...'] ['french'] ['press']\n",
      "[\"'\"] ['free'] ['their']\n",
      "['too'] ['too'] ['w']\n",
      "['go'] ['go'] ['year']\n",
      "['...'] ['wine'] ['launches']\n",
      "['...'] ['a'] ['when']\n",
      "[[83, 0], [0, 0]]\n",
      "['...'] ['expert'] ['call']\n",
      "['...'] ['low'] ['nu']\n",
      "['...'] ['thomson'] ['girl']\n",
      "['...'] ['so'] ['highly']\n",
      "['...'] ['amanda'] ['don']\n",
      "['...'] ['amanda'] ['##o']\n",
      "['...'] ['drink'] ['##m']\n",
      "['...'] ['##s'] ['##ish']\n",
      "['...'] ['de'] ['##t']\n",
      "['...'] ['new'] ['figure']\n",
      "['.'] ['##uz'] ['like']\n",
      "['.'] ['crack'] ['maintaining']\n",
      "['.'] ['##a'] ['champagne']\n",
      "['.'] ['french'] ['used']\n",
      "['.'] ['inspired'] ['early']\n",
      "['.'] ['cocktail'] ['ones']\n",
      "['.'] ['free'] ['being']\n",
      "['...'] ['sugar'] ['with']\n",
      "[[101, 0], [0, 0]]\n",
      "['and'] [')'] ['what']\n",
      "['more'] ['dr'] ['do']\n",
      "['more'] ['##uz'] ['what']\n",
      "['more'] ['on'] ['do']\n",
      "[[105, 0], [0, 0]]\n",
      "[\"'\"] ['champagne'] ['white']\n",
      "[\"'\"] ['low'] ['even']\n",
      "[\"'\"] ['all'] ['there']\n",
      "[\"'\"] ['##a'] ['wine']\n",
      "[\"'\"] ['amanda'] ['wine']\n",
      "[\"'\"] ['says'] ['##d']\n",
      "[\"'\"] ['mum'] ['talk']\n",
      "['\"'] ['\"'] ['that']\n",
      "['...'] ['her'] ['gives']\n",
      "['...'] ['##ori'] ['about']\n",
      "['...'] ['the'] ['##ten']\n",
      "[\"'\"] ['new'] ['only']\n",
      "['...'] ['a'] ['just']\n",
      "['...'] ['has'] ['words']\n",
      "[\"'\"] ['##e'] ['rose']\n",
      "['...'] ['crack'] ['##ing']\n",
      "['the'] ['the'] ['champagne']\n",
      "['...'] ['inspired'] ['don']\n",
      "[\"'\"] ['free'] ['alternative']\n",
      "[\"'\"] ['wine'] ['cl']\n",
      "[\"'\"] ['a'] ['##t']\n",
      "[\"'\"] ['amanda'] ['really']\n",
      "[\"'\"] ['champagne'] ['left']\n",
      "[[128, 0], [0, 0]]\n",
      "['.'] ['\"'] ['champagne']\n",
      "['.'] ['champagne'] ['##m']\n",
      "['.'] ['dr'] ['contains']\n",
      "['.'] ['now'] ['cal']\n",
      "['.'] ['##uz'] ['around']\n",
      "['.'] ['on'] ['nu']\n",
      "['.'] ['wine'] ['glass']\n",
      "[[135, 0], [0, 0]]\n",
      "['.'] ['champagne'] ['added']\n",
      "['.'] ['is'] ['nu']\n",
      "['.'] ['actually'] ['##m']\n",
      "['.'] ['de'] ['##age']\n",
      "['.'] ['##ori'] ['nu']\n",
      "['.'] ['has'] ['finish']\n",
      "['.'] ['##e'] ['##m']\n",
      "['.'] ['mint'] ['cent']\n",
      "['.'] ['on'] ['sugar']\n",
      "['.'] ['wine'] ['fe']\n",
      "['.'] ['a'] ['champagne']\n",
      "['.'] ['amanda'] ['sugar']\n",
      "[[147, 0], [0, 0]]\n",
      "[\"'\"] ['champagne'] ['cal']\n",
      "[\"'\"] ['is'] ['extra']\n",
      "['no'] ['low'] ['even']\n",
      "['is'] ['is'] ['hard']\n",
      "['.'] ['##a'] ['low']\n",
      "['.'] ['amanda'] ['##ori']\n",
      "['...'] ['mum'] ['frances']\n",
      "['no'] ['the'] ['##ft']\n",
      "['all'] ['cal'] ['regular']\n",
      "['.'] ['her'] ['sugar']\n",
      "['...'] ['now'] ['##e']\n",
      "['...'] ['she'] ['brand']\n",
      "[\"'\"] ['##ori'] ['most']\n",
      "['\"'] ['low'] ['##y']\n",
      "[')'] ['\"'] ['champagne']\n",
      "[\"'\"] ['a'] ['fi']\n",
      "[\"'\"] ['sugar'] ['comes']\n",
      "['sugar'] ['alcohol'] ['price']\n",
      "['of'] ['##e'] ['drink']\n",
      "['.'] ['##a'] ['therefore']\n",
      "['.'] ['french'] ['##zz']\n",
      "['.'] ['inspired'] ['idea']\n",
      "['.'] ['cocaine'] ['their']\n",
      "['.'] ['free'] ['with']\n",
      "['and'] ['and'] ['tag']\n",
      "['\"'] ['the'] ['##ers']\n",
      "['.'] ['on'] ['low']\n",
      "['...'] ['a'] ['some']\n",
      "[\"'\"] ['it'] ['offer']\n",
      "[\"'\"] ['amanda'] ['biggest']\n",
      "['\"'] ['the'] ['that']\n",
      "['##zz'] ['##zz'] ['find']\n",
      "[[179, 0], [0, 0]]\n",
      "[']'] ['expert'] ['created']\n",
      "['.'] ['low'] ['##z']\n",
      "[']'] ['amanda'] ['##sh']\n",
      "['...'] [\"'\"] ['price']\n",
      "['...'] ['now'] ['pl']\n",
      "['...'] ['she'] ['british']\n",
      "['...'] ['##ori'] ['amanda']\n",
      "['...'] ['the'] ['free']\n",
      "['...'] ['a'] ['##on']\n",
      "['...'] ['has'] ['ex']\n",
      "['...'] ['##e'] ['thomson']\n",
      "['...'] ['crack'] ['alternative']\n",
      "['...'] ['french'] ['##k']\n",
      "['...'] ['inspired'] ['show']\n",
      "['.'] ['a'] ['##bi']\n",
      "['.'] ['amanda'] ['half']\n",
      "[[195, 0], [0, 0]]\n",
      "['\"'] ['\"'] ['amanda']\n",
      "['...'] ['champagne'] ['trained']\n",
      "['...'] ['is'] ['##e']\n",
      "['\"'] ['amanda'] ['made']\n",
      "['and'] [\"'\"] ['from']\n",
      "['...'] ['says'] ['paris']\n",
      "['...'] ['cry'] ['create']\n",
      "['...'] ['actually'] ['drink']\n",
      "['trained'] ['trained'] ['attending']\n",
      "['...'] ['she'] ['says']\n",
      "['...'] ['the'] ['after']\n",
      "['...'] ['new'] ['show']\n",
      "['...'] ['##uz'] ['french']\n",
      "['...'] ['##e'] ['low']\n",
      "['...'] ['sugar'] ['##bi']\n",
      "['a'] ['a'] ['about']\n",
      "['le'] ['le'] ['parties']\n",
      "['...'] ['##a'] ['wine']\n",
      "['...'] ['french'] ['##on']\n",
      "['...'] ['drink'] ['cal']\n",
      "['...'] ['cocaine'] ['previous']\n",
      "['...'] ['free'] ['##z']\n",
      "['...'] ['on'] ['expert']\n",
      "['...'] ['wine'] ['blue']\n",
      "['...'] ['a'] ['inspired']\n",
      "['...'] ['sugar'] ['##ori']\n",
      "['...'] ['champagne'] ['reporter']\n",
      "['\"'] ['wine'] ['weight']\n",
      "[[223, 0], [0, 0]]\n",
      "['.'] ['\"'] ['working']\n",
      "['.'] ['expert'] ['sugar']\n",
      "['...'] ['low'] ['##e']\n",
      "['...'] ['thomson'] ['scott']\n",
      "['.'] ['##a'] ['with']\n",
      "['.'] ['says'] ['br']\n",
      "['.'] ['mum'] ['grand']\n",
      "['.'] ['actually'] ['selling']\n",
      "['.'] ['a'] ['website']\n",
      "['##et'] ['##et'] ['nu']\n",
      "['sugar'] ['sugar'] ['glass']\n",
      "['.'] ['de'] ['champagne']\n",
      "['.'] ['she'] ['##ut']\n",
      "['...'] ['##ori'] ['cr']\n",
      "['with'] ['with'] ['bottle']\n",
      "['she'] ['she'] ['##m']\n",
      "['...'] ['a'] ['created']\n",
      "['...'] ['has'] ['nature']\n",
      "['...'] ['##e'] ['##u']\n",
      "['.'] ['inspired'] ['cu']\n",
      "['...'] ['drink'] ['which']\n",
      "['.'] ['cocaine'] ['thomson']\n",
      "['.'] ['free'] ['nu']\n",
      "['maker'] ['maker'] ['contains']\n",
      "['created'] ['created'] ['cal']\n",
      "['.'] ['on'] ['pen']\n",
      "['...'] ['a'] ['##ve']\n",
      "['.'] ['champagne'] ['##m']\n",
      "['de'] ['de'] ['just']\n",
      "[[252, 0], [0, 0]]\n",
      "['...'] ['expert'] ['half']\n",
      "['...'] ['low'] ['like']\n",
      "['...'] ['thomson'] ['##bi']\n",
      "['.'] ['##a'] ['drink']\n",
      "['.'] ['amanda'] ['grand']\n",
      "['.'] ['actually'] ['fashion']\n",
      "['.'] ['##s'] ['##z']\n",
      "['.'] ['now'] ['cr']\n",
      "['.'] ['she'] ['cal']\n",
      "['.'] ['leon'] ['described']\n",
      "['.'] ['a'] ['##u']\n",
      "['.'] ['##e'] ['gr']\n",
      "['.'] ['crack'] ['##s']\n",
      "['.'] ['sugar'] ['doing']\n",
      "['...'] ['french'] ['with']\n",
      "['...'] ['inspired'] ['which']\n",
      "['...'] ['drink'] ['##ail']\n",
      "['.'] ['on'] ['high']\n",
      "['.'] ['wine'] ['almost']\n",
      "[\"'\"] ['amanda'] ['show']\n",
      "['.'] ['champagne'] ['rounds']\n",
      "[[273, 0], [0, 0]]\n",
      "['...'] ['champagne'] ['##uz']\n",
      "['.'] ['low'] ['test']\n",
      "['...'] ['thomson'] ['loving']\n",
      "['the'] ['the'] ['more']\n",
      "['her'] ['de'] ['iv']\n",
      "['.'] ['amanda'] ['##a']\n",
      "['.'] ['cal'] ['amanda']\n",
      "['.'] ['actually'] ['british']\n",
      "['.'] ['##s'] ['champagne']\n",
      "['the'] ['the'] ['cal']\n",
      "['##uz'] ['##uz'] ['##e']\n",
      "['test'] ['test'] ['with']\n",
      "['...'] ['she'] ['latest']\n",
      "['...'] ['##ori'] ['said']\n",
      "['...'] ['the'] ['have']\n",
      "['vogue'] ['vogue'] ['##ori']\n",
      "['##a'] ['##a'] ['found']\n",
      "['.'] ['##uz'] ['christ']\n",
      "['.'] ['has'] ['brand']\n",
      "['editor'] ['editor'] ['##e']\n",
      "['latest'] ['latest'] ['##ly']\n",
      "['said'] ['said'] ['added']\n",
      "['...'] ['##a'] ['##a']\n",
      "['...'] ['french'] ['fashion']\n",
      "['...'] ['drink'] ['know']\n",
      "['...'] ['cocaine'] ['history']\n",
      "[\"'\"] ['free'] ['today']\n",
      "['\"'] ['her'] ['producer']\n",
      "['we'] ['we'] ['sugar']\n",
      "['.'] ['on'] ['dso']\n",
      "['.'] ['wine'] ['friends']\n",
      "['.'] ['sugar'] ['that']\n",
      "['.'] ['champagne'] ['##s']\n",
      "['\"'] ['\"'] ['market']\n",
      "['to'] ['to'] ['champagne']\n",
      "[[307, 1], [0, 0]]\n",
      "['.'] ['champagne'] ['idea']\n",
      "['.'] ['expert'] ['less']\n",
      "['etc'] ['##a'] ['fashion']\n",
      "['.'] ['de'] ['crowd']\n",
      "['.'] ['now'] ['drinking']\n",
      "['.'] ['a'] ['fi']\n",
      "['.'] ['has'] ['what']\n",
      "['.'] ['##a'] ['loves']\n",
      "['.'] ['british'] ['##zz']\n",
      "['.'] ['wine'] ['with']\n",
      "[[317, 1], [0, 0]]\n",
      "['.'] ['\"'] ['christ']\n",
      "['just'] ['##a'] ['##a']\n",
      "['...'] ['says'] ['thing']\n",
      "['...'] ['dr'] ['says']\n",
      "['...'] ['now'] ['going']\n",
      "['.'] ['##a'] ['seriously']\n",
      "['...'] ['on'] ['think']\n",
      "[[323, 2], [0, 0]]\n",
      "['.'] ['\"'] ['part']\n",
      "['.'] ['champagne'] ['never']\n",
      "['.'] ['expert'] ['y']\n",
      "['.'] ['amanda'] ['liked']\n",
      "['.'] ['now'] ['champagne']\n",
      "['is'] ['##uz'] ['reason']\n",
      "['.'] ['has'] ['gives']\n",
      "['.'] ['##a'] ['iv']\n",
      "['...'] ['on'] ['##e']\n",
      "['.'] ['a'] ['straight']\n",
      "[[333, 2], [0, 0]]\n",
      "['.'] ['.'] ['there']\n",
      "['and'] ['low'] ['super']\n",
      "[')'] ['##a'] ['##s']\n",
      "['.'] ['says'] ['after']\n",
      "['.'] ['drink'] ['expensive']\n",
      "['.'] ['de'] ['also']\n",
      "['.'] ['on'] ['##on']\n",
      "['.'] ['a'] ['super']\n",
      "[[341, 2], [0, 0]]\n",
      "['and'] ['amanda'] ['here']\n",
      "['.'] ['dr'] ['##s']\n",
      "['.'] ['##a'] ['thing']\n",
      "[[344, 2], [0, 0]]\n",
      "['\"'] ['.'] ['because']\n",
      "['...'] ['champagne'] ['champagne']\n",
      "['.'] ['expert'] ['br']\n",
      "['etc'] ['##a'] ['this']\n",
      "['...'] ['says'] ['##ut']\n",
      "['...'] ['actually'] ['do']\n",
      "['...'] ['##s'] ['need']\n",
      "['...'] ['##ori'] ['##ly']\n",
      "['...'] ['##uz'] ['cu']\n",
      "['...'] ['a'] ['very']\n",
      "['...'] ['has'] ['don']\n",
      "['...'] ['crack'] ['wake']\n",
      "['...'] ['sugar'] ['take']\n",
      "['...'] ['##a'] ['##ve']\n",
      "['...'] ['french'] ['very']\n",
      "['...'] ['made'] ['##t']\n",
      "['...'] ['drink'] ['taste']\n",
      "['champagne'] ['cu'] ['seriously']\n",
      "['...'] ['on'] ['##e']\n",
      "['...'] ['wine'] ['very']\n",
      "['...'] ['amanda'] ['feeling']\n",
      "['...'] ['champagne'] ['whole']\n",
      "['\"'] ['\"'] ['might']\n",
      "[[366, 3], [0, 0]]\n",
      "['\"'] ['\"'] ['more']\n",
      "['.'] ['amanda'] ['than']\n",
      "['.'] ['a'] ['single']\n",
      "['.'] ['##a'] ['less']\n",
      "['.'] ['british'] ['shot']\n",
      "['.'] ['on'] ['cal']\n",
      "[[372, 3], [0, 0]]\n",
      "['...'] ['champagne'] ['dinner']\n",
      "['...'] ['expert'] ['have']\n",
      "['...'] ['is'] ['loved']\n",
      "['...'] ['says'] ['been']\n",
      "['...'] ['drink'] ['friend']\n",
      "['...'] ['##ori'] ['james']\n",
      "['had'] ['had'] ['with']\n",
      "['...'] ['##uz'] ['last']\n",
      "['...'] ['##a'] ['night']\n",
      "['...'] ['french'] ['might']\n",
      "['...'] ['inspired'] ['enough']\n",
      "['...'] ['cocaine'] ['d']\n",
      "['...'] ['free'] ['perfectly']\n",
      "['...'] ['champagne'] ['able']\n",
      "[[386, 3], [0, 0]]\n",
      "['\"'] ['\"'] ['does']\n",
      "['etc'] ['##a'] ['that']\n",
      "['.'] ['##uz'] ['like']\n",
      "['a'] ['on'] ['champagne']\n",
      "[[390, 3], [0, 0]]\n",
      "['.'] ['\"'] ['like']\n",
      "['.'] ['champagne'] ['##able']\n",
      "['.'] ['\"'] ['that']\n",
      "['.'] ['amanda'] ['marketing']\n",
      "['.'] ['says'] ['make']\n",
      "['.'] ['leon'] ['just']\n",
      "['.'] ['now'] ['campaign']\n",
      "['.'] ['##uz'] ['##ly']\n",
      "['.'] ['wine'] ['##c']\n",
      "[[399, 3], [0, 0]]\n",
      "['\"'] ['\"'] ['well']\n",
      "['it'] ['##uz'] ['##t']\n",
      "[[401, 3], [0, 0]]\n",
      "['.'] ['champagne'] ['perfectly']\n",
      "['.'] ['low'] ['with']\n",
      "['.'] ['is'] ['making']\n",
      "['...'] ['says'] ['most']\n",
      "['...'] ['actually'] ['ones']\n",
      "['...'] ['dso'] ['friend']\n",
      "['...'] ['now'] ['enough']\n",
      "['.'] ['##uz'] ['james']\n",
      "['.'] ['french'] ['serve']\n",
      "['.'] ['cocaine'] ['like']\n",
      "[[411, 3], [0, 0]]\n",
      "['.'] ['\"'] ['doesn']\n",
      "['.'] ['expert'] ['make']\n",
      "['...'] ['laura'] ['##t']\n",
      "['...'] ['amanda'] ['##age']\n",
      "['...'] ['says'] ['sense']\n",
      "['...'] ['cal'] ['##ly']\n",
      "['...'] ['actually'] ['##ly']\n",
      "['...'] ['she'] ['given']\n",
      "['...'] ['##ori'] ['proven']\n",
      "['...'] ['the'] ['keep']\n",
      "['...'] ['leon'] ['idea']\n",
      "['...'] ['a'] ['women']\n",
      "['...'] ['has'] ['that']\n",
      "['...'] ['##e'] ['that']\n",
      "['...'] ['drink'] ['front']\n",
      "['...'] ['french'] ['kind']\n",
      "['...'] ['cocktail'] ['with']\n",
      "['...'] ['on'] ['low']\n",
      "['...'] ['a'] ['been']\n",
      "[\"'\"] ['sugar'] ['cannot']\n",
      "[[431, 3], [0, 0]]\n",
      "['and'] ['amanda'] ['another']\n",
      "['.'] ['dr'] ['thing']\n",
      "[[433, 3], [0, 0]]\n",
      "['.'] ['expert'] ['actually']\n",
      "['.'] ['thomson'] ['woman']\n",
      "['.'] ['tea'] ['nu']\n",
      "['.'] ['actually'] ['think']\n",
      "['.'] ['me'] ['down']\n",
      "['.'] ['now'] ['evidence']\n",
      "['.'] ['she'] ['crack']\n",
      "['...'] ['##ori'] ['##m']\n",
      "['.'] ['##uz'] ['here']\n",
      "['.'] ['a'] ['that']\n",
      "['...'] ['has'] ['cocaine']\n",
      "['.'] ['crack'] ['should']\n",
      "[\"'\"] ['british'] ['sugar']\n",
      "[\"'\"] ['free'] ['##er']\n",
      "['['] ['on'] ['with']\n",
      "['['] ['sugar'] ['century']\n",
      "[[449, 3], [0, 0]]\n",
      "['\"'] ['\"'] ['amanda']\n",
      "['...'] ['is'] ['sugar']\n",
      "['-'] ['amanda'] ['food']\n",
      "['career'] ['career'] ['lower']\n",
      "['new'] ['new'] ['##gent']\n",
      "['the'] ['the'] ['champagne']\n",
      "['that'] ['that'] ['something']\n",
      "['better'] ['better'] ['champagne']\n",
      "['sure'] ['sure'] ['com']\n",
      "[\"'\"] ['##a'] ['thomson']\n",
      "['...'] ['says'] ['paris']\n",
      "['...'] ['actually'] ['free']\n",
      "['as'] ['as'] ['cal']\n",
      "['in'] ['in'] ['round']\n",
      "['and'] ['and'] ['works']\n",
      "['\"'] ['sugar'] ['drink']\n",
      "['the'] ['the'] ['have']\n",
      "['...'] ['her'] ['gave']\n",
      "['...'] ['the'] ['champagne']\n",
      "['she'] ['thomson'] ['drink']\n",
      "['grace'] ['##ls'] ['low']\n",
      "['round'] ['round'] ['that']\n",
      "['...'] ['##e'] ['launched']\n",
      "['...'] ['crack'] ['br']\n",
      "['...'] ['sugar'] ['mail']\n",
      "['now'] ['now'] ['this']\n",
      "['the'] ['the'] ['cal']\n",
      "['drink'] ['drink'] ['important']\n",
      "['...'] ['launched'] ['wine']\n",
      "['...'] ['cocaine'] ['##ut']\n",
      "['...'] ['free'] ['online']\n",
      "['a'] ['a'] ['##t']\n",
      "['launched'] ['launched'] ['extra']\n",
      "['\"'] ['mail'] ['##ori']\n",
      "['blogger'] ['blogger'] ['thing']\n",
      "['etc'] ['on'] ['carrier']\n",
      "['...'] ['wine'] ['study']\n",
      "['...'] ['a'] ['expert']\n",
      "['...'] ['amanda'] ['nature']\n",
      "['...'] ['champagne'] ['##s']\n",
      "['her'] ['her'] ['that']\n",
      "['to'] ['to'] ['better']\n",
      "['wine'] ['wine'] ['sure']\n",
      "['a'] ['a'] ['##va']\n",
      "['##ut'] ['##ut'] ['fantastic']\n",
      "['\"'] ['\"'] ['##e']\n",
      "[')'] ['\"'] ['with']\n",
      "[[496, 3], [0, 0]]\n",
      "['.'] ['expert'] ['almost']\n",
      "['('] ['dr'] ['##age']\n",
      "['.'] ['##uz'] ['champagne']\n",
      "['.'] ['a'] ['that']\n",
      "['.'] ['##a'] ['##s']\n",
      "['.'] ['french'] ['they']\n",
      "['.'] ['wine'] ['taste']\n",
      "[[503, 3], [0, 0]]\n",
      "['...'] ['expert'] ['those']\n",
      "['('] ['is'] ['fabulous']\n",
      "['('] ['so'] ['something']\n",
      "[\"'\"] ['mum'] ['having']\n",
      "[\"'\"] ['actually'] ['rather']\n",
      "['etc'] ['##s'] ['that']\n",
      "['...'] ['now'] ['might']\n",
      "['...'] ['she'] ['where']\n",
      "['...'] ['the'] ['than']\n",
      "['...'] ['new'] ['doesn']\n",
      "['...'] ['##uz'] ['watching']\n",
      "['...'] ['##e'] ['glass']\n",
      "['...'] ['champagne'] ['##t']\n",
      "['...'] ['##a'] ['your']\n",
      "['('] ['free'] ['taste']\n",
      "['...'] ['on'] ['cal']\n",
      "['...'] ['a'] ['better']\n",
      "['...'] ['sugar'] ['something']\n",
      "['...'] ['champagne'] ['great']\n",
      "[[522, 3], [0, 0]]\n",
      "['\"'] ['\"'] ['however']\n",
      "[\"'\"] ['low'] ['##rit']\n",
      "['no'] ['mum'] ['##if']\n",
      "['.'] ['mum'] ['this']\n",
      "[\"'\"] ['she'] ['champagne']\n",
      "['...'] ['a'] ['clearly']\n",
      "[\"'\"] ['##e'] ['choice']\n",
      "[\"'\"] ['french'] ['worth']\n",
      "[\"'\"] ['inspired'] ['your']\n",
      "['...'] ['on'] ['both']\n",
      "['...'] ['wine'] ['buying']\n",
      "[[533, 3], [0, 0]]\n",
      "0.005597014925373134\n",
      "Elapsed Time: 19.524670600891113 seconds\n",
      "Summary 4 of batch\n",
      "['...'] ['marketing'] ['##m']\n",
      "['...'] ['advertising'] ['years']\n",
      "['...'] ['##m'] ['born']\n",
      "['...'] ['billion'] ['never']\n",
      "['...'] ['to'] ['coming']\n",
      "['...'] ['to'] ['nu']\n",
      "['...'] ['spending'] ['later']\n",
      "['...'] ['>'] ['after']\n",
      "['.'] ['launch'] ['special']\n",
      "['.'] ['launch'] ['##m']\n",
      "['the'] ['the'] ['their']\n",
      "['...'] ['on'] ['nu']\n",
      "['...'] ['nu'] ['terror']\n",
      "['...'] ['video'] ['children']\n",
      "['...'] ['digital'] ['##m']\n",
      "['...'] ['<'] ['five']\n",
      "['...'] ['##m'] ['attacks']\n",
      "['...'] ['cinema'] ['nu']\n",
      "['...'] ['nu'] ['teenagers']\n",
      "[[19, 0], [0, 0]]\n",
      "['.'] ['time'] ['almost']\n",
      "['...'] ['to'] ['viewers']\n",
      "['.'] ['to'] ['hour']\n",
      "['.'] ['s'] ['major']\n",
      "['.'] ['streaming'] ['##t']\n",
      "['.'] ['new'] ['program']\n",
      "['.'] ['on'] ['television']\n",
      "['.'] ['video'] ['find']\n",
      "[[27, 0], [0, 0]]\n",
      "['\"'] ['.'] ['instead']\n",
      "['...'] ['advertising'] ['time']\n",
      "['...'] ['##m'] ['video']\n",
      "['...'] ['to'] ['part']\n",
      "['...'] ['>'] ['service']\n",
      "['.'] ['launch'] ['will']\n",
      "['.'] ['s'] ['people']\n",
      "['.'] ['streaming'] ['make']\n",
      "['...'] ['on'] ['entertainment']\n",
      "['...'] ['be'] ['advertising']\n",
      "['...'] ['digital'] ['tuesday']\n",
      "['...'] ['digital'] ['weekly']\n",
      "['...'] ['<'] ['supported']\n",
      "['.'] ['service'] ['debut']\n",
      "['.'] ['video'] ['launch']\n",
      "['.'] ['video'] ['network']\n",
      "['...'] ['nu'] ['streaming']\n",
      "[[44, 0], [0, 0]]\n",
      "['.'] ['advertising'] ['peoples']\n",
      "['.'] ['##m'] ['latest']\n",
      "['.'] ['to'] ['channel']\n",
      "['.'] ['spending'] ['website']\n",
      "['.'] ['launch'] ['which']\n",
      "['.'] ['s'] ['connected']\n",
      "['.'] ['to'] ['represents']\n",
      "['.'] ['new'] ['will']\n",
      "['.'] ['on'] ['devices']\n",
      "['.'] ['hit'] ['time']\n",
      "['.'] ['nu'] ['digital']\n",
      "['.'] ['digital'] ['streaming']\n",
      "['.'] ['##m'] ['advertising']\n",
      "['.'] ['service'] ['available']\n",
      "['.'] ['video'] ['service']\n",
      "[[59, 0], [0, 0]]\n",
      "['...'] ['programming'] ['opportunity']\n",
      "['.'] ['billion'] ['advertising']\n",
      "['...'] ['to'] ['print']\n",
      "['...'] ['to'] ['decline']\n",
      "['the'] ['and'] ['business']\n",
      "['.'] ['launch'] ['ad']\n",
      "['.'] ['streaming'] ['page']\n",
      "['...'] ['new'] ['launch']\n",
      "['...'] ['nu'] ['fast']\n",
      "['.'] ['video'] ['sales']\n",
      "['.'] ['digital'] ['represents']\n",
      "['.'] ['##m'] ['growing']\n",
      "['.'] ['service'] ['continue']\n",
      "['.'] ['>'] ['video']\n",
      "[[73, 0], [0, 0]]\n",
      "['\"'] ['.'] ['this']\n",
      "['...'] ['time'] ['rich']\n",
      "['...'] ['service'] ['digital']\n",
      "['\"'] ['\"'] ['future']\n",
      "['...'] [\"'\"] ['executive']\n",
      "['and'] ['and'] ['where']\n",
      "['president'] ['president'] ['where']\n",
      "['were'] ['were'] ['going']\n",
      "['...'] ['s'] ['recently']\n",
      "['rich'] ['\"'] ['long']\n",
      "['digital'] ['digital'] ['consumption']\n",
      "['of'] ['of'] ['ad']\n",
      "['...'] ['new'] ['veteran']\n",
      "['...'] ['on'] ['promoted']\n",
      "['...'] ['hit'] ['time']\n",
      "[','] [','] ['form']\n",
      "['brands'] ['brands'] ['##vert']\n",
      "['the'] ['the'] ['where']\n",
      "['the'] ['the'] ['video']\n",
      "['at'] ['at'] ['##iser']\n",
      "['.'] ['service'] ['said']\n",
      "['.'] ['video'] ['president']\n",
      "['.'] ['nu'] ['were']\n",
      "['.'] ['>'] ['world']\n",
      "['promoted'] ['promoted'] ['going']\n",
      "['time'] ['time'] ['##s']\n",
      "[[99, 0], [0, 0]]\n",
      "['...'] ['advertising'] ['human']\n",
      "['...'] ['##m'] ['game']\n",
      "['.'] ['to'] ['free']\n",
      "['.'] ['to'] ['available']\n",
      "['.'] [\"'\"] ['demand']\n",
      "['.'] ['spending'] ['interest']\n",
      "['will'] ['will'] ['emmy']\n",
      "['.'] ['launch'] ['video']\n",
      "['.'] ['s'] ['will']\n",
      "['.'] ['to'] ['stories']\n",
      "['.'] ['<'] ['throne']\n",
      "['the'] ['the'] ['live']\n",
      "['be'] ['be'] ['awards']\n",
      "['.'] ['streaming'] ['service']\n",
      "['.'] ['new'] ['watch']\n",
      "['.'] ['on'] ['focus']\n",
      "['.'] ['hit'] ['entertainment']\n",
      "['.'] ['nu'] ['##s']\n",
      "['free'] ['free'] ['events']\n",
      "['...'] ['film'] ['which']\n",
      "['.'] ['digital'] ['live']\n",
      "['-'] ['\"'] ['such']\n",
      "['...'] ['service'] ['will']\n",
      "['.'] ['video'] ['celebrities']\n",
      "['.'] ['>'] ['star']\n",
      "[[124, 0], [0, 0]]\n",
      "['...'] ['time'] ['##m']\n",
      "['...'] ['programming'] ['with']\n",
      "['.'] ['to'] ['will']\n",
      "['.'] [\"'\"] ['five']\n",
      "['.'] ['spending'] ['week']\n",
      "['.'] ['>'] ['websites']\n",
      "['.'] ['launch'] ['live']\n",
      "['.'] ['s'] ['hours']\n",
      "['.'] ['new'] ['nu']\n",
      "['.'] ['nu'] ['time']\n",
      "['...'] ['digital'] ['##m']\n",
      "['...'] ['digital'] ['original']\n",
      "['...'] ['<'] ['shows']\n",
      "['.'] ['service'] ['nu']\n",
      "['.'] ['cinema'] ['programming']\n",
      "['.'] ['nu'] ['from']\n",
      "['.'] ['>'] ['archives']\n",
      "[[141, 0], [0, 0]]\n",
      "['...'] ['time'] ['##y']\n",
      "['...'] ['programming'] ['jessica']\n",
      "['.'] ['to'] ['series']\n",
      "['.'] ['spending'] ['hottest']\n",
      "['...'] ['launch'] ['include']\n",
      "['...'] ['acquire'] ['program']\n",
      "['...'] ['to'] ['shows']\n",
      "['.'] ['new'] ['bing']\n",
      "['.'] ['on'] ['tour']\n",
      "['.'] ['video'] ['##ew']\n",
      "['.'] ['digital'] ['which']\n",
      "['.'] ['digital'] ['##e']\n",
      "['.'] ['cinema'] ['discuss']\n",
      "[[154, 0], [0, 0]]\n",
      "[')'] ['.'] ['time']\n",
      "['['] ['advertising'] ['from']\n",
      "['...'] ['to'] ['video']\n",
      "['...'] ['spending'] ['outside']\n",
      "['['] ['to'] ['producers']\n",
      "['.'] ['streaming'] ['produces']\n",
      "['.'] ['film'] ['most']\n",
      "['.'] ['digital'] ['house']\n",
      "['.'] ['digital'] ['acquire']\n",
      "['.'] ['film'] ['programming']\n",
      "[[164, 0], [0, 0]]\n",
      "['\"'] ['.'] ['time']\n",
      "['...'] ['time'] ['premium']\n",
      "['...'] ['advertising'] ['digital']\n",
      "['...'] ['##m'] ['crack']\n",
      "['.'] ['\"'] ['cars']\n",
      "['...'] ['spending'] ['video']\n",
      "['...'] ['>'] ['##le']\n",
      "['.'] ['.'] ['getting']\n",
      "['into'] ['into'] ['##ons']\n",
      "['.'] ['launch'] ['programming']\n",
      "['.'] ['s'] ['market']\n",
      "['.'] ['to'] ['services']\n",
      "['.'] ['<'] ['home']\n",
      "['time'] ['time'] ['coffee']\n",
      "['a'] ['a'] ['free']\n",
      "['digital'] ['digital'] ['nu']\n",
      "['crack'] ['crack'] ['viewers']\n",
      "['.'] ['streaming'] ['wage']\n",
      "['.'] ['on'] ['where']\n",
      "['.'] ['hit'] ['from']\n",
      "['new'] ['new'] ['mobile']\n",
      "['video'] ['\"'] ['##m']\n",
      "['.'] ['digital'] ['break']\n",
      "['.'] ['digital'] ['dozens']\n",
      "['.'] ['<'] ['sony']\n",
      "['market'] ['market'] ['video']\n",
      "['home'] ['home'] ['younger']\n",
      "['.'] ['video'] ['into']\n",
      "['...'] ['nu'] ['pictures']\n",
      "['wage'] ['wage'] ['cent']\n",
      "['to'] ['to'] ['ve']\n",
      "['of'] ['of'] ['consumers']\n",
      "['to'] ['to'] ['advertising']\n",
      "[[197, 0], [0, 0]]\n",
      "['.'] ['\"'] ['spending']\n",
      "['.'] ['time'] ['digital']\n",
      "['.'] ['production'] ['nu']\n",
      "['.'] ['##m'] ['nu']\n",
      "['.'] ['\"'] ['nu']\n",
      "['>'] ['>'] ['services']\n",
      "['nu'] ['nu'] ['based']\n",
      "['for'] ['for'] ['##ers']\n",
      "['she'] ['she'] ['such']\n",
      "['.'] ['to'] ['video']\n",
      "['.'] ['time'] ['##m']\n",
      "['.'] ['>'] ['##m']\n",
      "['the'] ['billion'] ['##m']\n",
      "['on'] ['on'] ['billion']\n",
      "['to'] ['to'] ['according']\n",
      "['<'] ['<'] ['firm']\n",
      "['['] ['['] ['group']\n",
      "['##m'] ['##m'] ['advertising']\n",
      "['leslie'] ['leslie'] ['##rem']\n",
      "['dallas'] ['dallas'] ['with']\n",
      "['network'] ['network'] ['sports']\n",
      "['.'] ['acquire'] ['advertising']\n",
      "['.'] ['s'] ['nu']\n",
      "['nu'] ['nu'] ['cow']\n",
      "['nu'] ['nu'] ['media']\n",
      "['>'] ['>'] ['agency']\n",
      "['family'] ['richards'] ['part']\n",
      "['.'] ['on'] ['##m']\n",
      "['.'] ['hit'] ['billion']\n",
      "['['] ['<'] ['estimates']\n",
      "['##m'] ['##m'] ['##en']\n",
      "['##m'] ['##m'] ['director']\n",
      "['billion'] ['billion'] ['said']\n",
      "['\"'] ['firm'] ['included']\n",
      "['the'] ['the'] ['charge']\n",
      "['financial'] ['advertising'] ['time']\n",
      "['.'] ['digital'] ['expected']\n",
      "['.'] ['##m'] ['from']\n",
      "['the'] ['the'] ['nu']\n",
      "['and'] ['advertising'] ['nu']\n",
      "['nu'] ['nu'] ['from']\n",
      "['>'] ['>'] ['co']\n",
      "['>'] ['>'] ['independent']\n",
      "['in'] ['in'] ['related']\n",
      "['u'] ['u'] ['##m']\n",
      "['is'] ['is'] ['##m']\n",
      "['##m'] ['##m'] ['financial']\n",
      "['<'] ['<'] ['might']\n",
      "['estimates'] ['estimates'] ['network']\n",
      "['director'] ['director'] ['market']\n",
      "['an'] ['an'] ['larger']\n",
      "['included'] ['included'] ['issue']\n",
      "[[249, 0], [0, 0]]\n",
      "['...'] ['time'] ['want']\n",
      "['...'] ['service'] ['low']\n",
      "['...'] ['##m'] ['interest']\n",
      "['.'] ['to'] ['viewers']\n",
      "['.'] [\"'\"] ['price']\n",
      "['...'] ['>'] ['among']\n",
      "['.'] ['launch'] ['said']\n",
      "['...'] ['introduce'] ['##hip']\n",
      "['...'] ['<'] ['viewers']\n",
      "['...'] ['digital'] ['started']\n",
      "['...'] ['##m'] ['proven']\n",
      "['...'] ['service'] ['would']\n",
      "['...'] ['cinema'] ['until']\n",
      "[[262, 0], [0, 0]]\n",
      "['.'] ['time'] ['will']\n",
      "['...'] ['to'] ['question']\n",
      "['...'] ['to'] ['there']\n",
      "['...'] ['new'] ['whether']\n",
      "['...'] ['new'] ['enough']\n",
      "['...'] ['on'] ['##ent']\n",
      "['...'] ['video'] ['their']\n",
      "['.'] ['service'] ['programming']\n",
      "['.'] ['film'] ['people']\n",
      "['.'] ['film'] ['##ized']\n",
      "['.'] ['nu'] ['said']\n",
      "[[273, 0], [0, 0]]\n",
      "['\"'] ['\"'] ['this']\n",
      "['['] ['time'] ['people']\n",
      "['.'] ['to'] ['going']\n",
      "['so'] [\"'\"] ['must']\n",
      "['.'] ['launch'] ['##t']\n",
      "['etc'] ['on'] ['programming']\n",
      "['is'] ['film'] ['same']\n",
      "['so'] ['digital'] ['where']\n",
      "['.'] ['film'] ['there']\n",
      "[[282, 0], [0, 0]]\n",
      "['.'] ['programming'] ['including']\n",
      "['network'] ['network'] ['nu']\n",
      "['.'] ['to'] ['people']\n",
      "['.'] [\"'\"] ['ro']\n",
      "['.'] ['spending'] ['##er']\n",
      "['.'] ['>'] ['fire']\n",
      "['has'] ['has'] ['##m']\n",
      "['tv'] ['tv'] ['ad']\n",
      "[\"'\"] [\"'\"] ['service']\n",
      "['.'] ['launch'] ['entertainment']\n",
      "['the'] ['\"'] ['##fin']\n",
      "['and'] ['\"'] ['website']\n",
      "['amazon'] ['amazon'] ['##vert']\n",
      "['.'] ['new'] ['weekly']\n",
      "['.'] ['on'] ['google']\n",
      "['.'] ['nu'] ['com']\n",
      "['\"'] ['\"'] ['##ity']\n",
      "['\"'] ['\"'] ['##fin']\n",
      "['fire'] ['fire'] ['##iser']\n",
      "['.'] ['video'] ['network']\n",
      "['.'] ['new'] ['launch']\n",
      "['.'] ['digital'] ['##s']\n",
      "['.'] ['['] ['apple']\n",
      "['\"'] ['\"'] ['##ity']\n",
      "['-'] ['fire'] ['supported']\n",
      "['.'] ['video'] ['media']\n",
      "['fire'] ['com'] ['online']\n",
      "[[309, 0], [0, 0]]\n",
      "['\"'] ['.'] ['much']\n",
      "['...'] ['time'] ['over']\n",
      "['...'] ['programming'] ['things']\n",
      "['...'] ['##m'] ['chairman']\n",
      "['.'] ['\"'] ['former']\n",
      "['...'] ['to'] ['like']\n",
      "['...'] ['to'] ['##pr']\n",
      "['...'] [\"'\"] ['people']\n",
      "['...'] ['spending'] ['said']\n",
      "['as'] ['more'] ['chief']\n",
      "['.'] ['introduce'] ['##ice']\n",
      "['...'] ['s'] ['don']\n",
      "['much'] ['much'] ['content']\n",
      "['...'] ['new'] ['##d']\n",
      "['...'] ['on'] ['##t']\n",
      "['like'] ['like'] ['officer']\n",
      "['['] ['digital'] ['want']\n",
      "['...'] ['video'] ['traditional']\n",
      "['...'] ['nu'] ['executive']\n",
      "['cd'] ['cd'] ['spot']\n",
      "[[329, 0], [0, 0]]\n",
      "['\"'] ['.'] ['time']\n",
      "['.'] ['time'] ['network']\n",
      "['.'] ['service'] ['consumers']\n",
      "['.'] [\"'\"] ['seek']\n",
      "['.'] ['acquire'] ['become']\n",
      "['.'] ['digital'] ['destination']\n",
      "['.'] ['digital'] ['original']\n",
      "['.'] ['film'] ['where']\n",
      "['.'] ['film'] ['content']\n",
      "[[338, 0], [0, 0]]\n",
      "['\"'] ['.'] ['license']\n",
      "['.'] ['on'] ['this']\n",
      "['.'] ['to'] ['service']\n",
      "['.'] ['new'] ['from']\n",
      "['.'] ['service'] ['jones']\n",
      "[[343, 0], [0, 0]]\n",
      "0.0\n",
      "Elapsed Time: 11.286656618118286 seconds\n",
      "Summary 5 of batch\n",
      "['...'] ['##ak'] ['##na']\n",
      "['.'] ['myself'] ['california']\n",
      "['.'] ['she'] ['miss']\n",
      "['.'] ['director'] ['keep']\n",
      "['.'] ['##ler'] ['mo']\n",
      "['super'] ['miss'] ['head']\n",
      "[\"'\"] ['believe'] ['organization']\n",
      "['...'] ['mo'] ['trump']\n",
      "['...'] ['quit'] ['california']\n",
      "['...'] ['i'] ['##ak']\n",
      "['and'] ['##ak'] ['##s']\n",
      "['.'] ['gala'] ['title']\n",
      "['.'] ['could'] ['##ler']\n",
      "['...'] ['##ler'] ['decision']\n",
      "['...'] ['miss'] ['carrie']\n",
      "['...'] ['mo'] ['shan']\n",
      "['...'] ['stay'] ['quit']\n",
      "['well'] ['no'] ['##s']\n",
      "[[18, 0], [0, 0]]\n",
      "['\"'] ['.'] ['shan']\n",
      "['...'] ['why'] ['with']\n",
      "['...'] ['usa'] ['##nos']\n",
      "['...'] ['##ak'] ['director']\n",
      "['\"'] ['##na'] ['##na']\n",
      "['...'] ['she'] ['h']\n",
      "['...'] ['director'] ['about']\n",
      "['.'] ['mo'] ['mo']\n",
      "['.'] ['i'] ['miss']\n",
      "['...'] ['##ak'] ['##ak']\n",
      "['...'] ['with'] ['##s']\n",
      "['...'] ['could'] ['california']\n",
      "['.'] ['##ler'] ['##ler']\n",
      "['.'] ['miss'] ['mike']\n",
      "['.'] ['##non'] ['resigned']\n",
      "['.'] ['talks'] ['talks']\n",
      "['.'] ['team'] ['gala']\n",
      "[[30, 5], [0, 0]]\n",
      "['.'] ['\"'] ['mo']\n",
      "['.'] ['usa'] ['with']\n",
      "['.'] ['##ak'] ['when']\n",
      "['\"'] ['##na'] ['##ak']\n",
      "['.'] ['she'] ['said']\n",
      "['.'] ['director'] ['trump']\n",
      "['.'] ['mo'] ['##ler']\n",
      "['.'] ['mike'] ['##s']\n",
      "['.'] ['with'] ['could']\n",
      "['.'] ['gala'] ['miss']\n",
      "['.'] ['can'] ['longer']\n",
      "['.'] ['##ler'] ['former']\n",
      "['.'] ['not'] ['believe']\n",
      "['.'] ['talks'] ['miss']\n",
      "['.'] ['\"'] ['stay']\n",
      "['.'] ['mo'] ['organization']\n",
      "[[46, 5], [0, 0]]\n",
      "['...'] ['why'] ['executive']\n",
      "['...'] ['with'] ['same']\n",
      "[']'] ['she'] ['director']\n",
      "[']'] ['##ler'] ['during']\n",
      "['.'] ['mo'] ['miss']\n",
      "['.'] ['quit'] ['mo']\n",
      "['.'] ['usa'] ['marriage']\n",
      "['.'] ['in'] ['semi']\n",
      "['.'] ['##ak'] ['california']\n",
      "['.'] ['with'] ['##ak']\n",
      "['.'] ['but'] ['comments']\n",
      "[']'] ['miss'] ['##ler']\n",
      "[']'] ['##nos'] ['with']\n",
      "[']'] ['not'] ['over']\n",
      "['.'] ['have'] ['photos']\n",
      "['.'] ['talks'] ['co']\n",
      "[[62, 5], [0, 0]]\n",
      "['.'] ['\"'] ['mo']\n",
      "['.'] ['why'] ['mike']\n",
      "['.'] ['she'] ['##ak']\n",
      "['.'] ['she'] ['gala']\n",
      "['.'] ['with'] ['##s']\n",
      "['.'] ['##ler'] ['resigned']\n",
      "['.'] ['mo'] ['##ler']\n",
      "['.'] ['quit'] ['##nos']\n",
      "['.'] ['mike'] ['prime']\n",
      "['.'] ['##ak'] ['spoke']\n",
      "['.'] ['with'] ['host']\n",
      "['.'] ['gala'] ['news']\n",
      "['.'] ['##nos'] ['about']\n",
      "['.'] ['talks'] ['with']\n",
      "['.'] ['teen'] ['h']\n",
      "[[77, 5], [0, 0]]\n",
      "['.'] ['usa'] ['gala']\n",
      "['.'] ['##ak'] ['heart']\n",
      "[\"'\"] ['##na'] ['following']\n",
      "['...'] ['she'] ['br']\n",
      "['...'] ['director'] ['##nos']\n",
      "['.'] ['##ler'] ['after']\n",
      "['.'] ['mo'] ['interview']\n",
      "['...'] ['quit'] ['##ev']\n",
      "['.'] ['with'] ['##ity']\n",
      "['.'] ['could'] ['press']\n",
      "['.'] ['##ler'] ['been']\n",
      "['.'] ['##nos'] ['change']\n",
      "['.'] ['not'] ['conference']\n",
      "[[90, 5], [0, 0]]\n",
      "['\"'] ['.'] ['mo']\n",
      "['...'] ['why'] ['really']\n",
      "['.'] ['##ak'] ['conference']\n",
      "['.'] ['##na'] ['##ak']\n",
      "['.'] ['mo'] ['##ler']\n",
      "['.'] ['with'] ['what']\n",
      "['.'] ['##ler'] ['wasn']\n",
      "['...'] ['talks'] ['##t']\n",
      "['...'] ['us'] ['going']\n",
      "['.'] ['mo'] ['press']\n",
      "[[100, 5], [0, 0]]\n",
      "['...'] ['why'] ['office']\n",
      "['...'] ['##na'] ['were']\n",
      "['.'] ['with'] ['spoke']\n",
      "['.'] ['##ler'] ['trump']\n",
      "['.'] ['miss'] ['with']\n",
      "['.'] ['talks'] ['##s']\n",
      "[[106, 5], [0, 0]]\n",
      "['.'] ['.'] ['carrie']\n",
      "['him'] ['##ak'] ['family']\n",
      "['.'] ['##ler'] ['spoke']\n",
      "['.'] ['talks'] ['with']\n",
      "[[110, 5], [0, 0]]\n",
      "['...'] ['why'] ['together']\n",
      "['...'] ['usa'] ['things']\n",
      "['more'] ['with'] ['were']\n",
      "['up'] ['miss'] ['hash']\n",
      "['...'] ['talks'] ['spoke']\n",
      "['...'] ['usa'] ['##ing']\n",
      "[[116, 5], [0, 0]]\n",
      "['.'] ['why'] ['nu']\n",
      "['.'] ['usa'] ['never']\n",
      "['.'] ['she'] ['##m']\n",
      "['.'] ['director'] ['really']\n",
      "['.'] ['mo'] ['never']\n",
      "['.'] ['mike'] ['felt']\n",
      "['...'] ['##ak'] ['really']\n",
      "['...'] ['with'] ['percent']\n",
      "['...'] ['gala'] ['truly']\n",
      "['.'] ['##ler'] ['felt']\n",
      "['.'] ['##nos'] ['heard']\n",
      "[[127, 5], [0, 0]]\n",
      "['.'] ['mo'] ['hoping']\n",
      "['\"'] ['talks'] ['best']\n",
      "[[129, 5], [0, 0]]\n",
      "['\"'] ['\"'] ['after']\n",
      "['...'] ['why'] ['went']\n",
      "['...'] ['##ak'] ['myself']\n",
      "['...'] ['she'] ['back']\n",
      "['...'] ['director'] ['just']\n",
      "['.'] ['mo'] ['press']\n",
      "['...'] ['mike'] ['really']\n",
      "['...'] ['##ak'] ['conference']\n",
      "['...'] ['gala'] ['sat']\n",
      "['...'] ['##ler'] ['when']\n",
      "['...'] ['miss'] ['hotel']\n",
      "['...'] ['##nos'] ['down']\n",
      "['...'] ['usa'] ['room']\n",
      "['...'] ['mo'] ['with']\n",
      "[[143, 5], [0, 0]]\n",
      "['...'] ['why'] ['going']\n",
      "['...'] ['##ak'] ['with']\n",
      "['...'] ['with'] ['conference']\n",
      "['she'] ['she'] ['don']\n",
      "['...'] ['##ler'] ['what']\n",
      "['...'] ['mo'] ['##t']\n",
      "['...'] ['mike'] ['wasn']\n",
      "['...'] ['i'] ['happened']\n",
      "['...'] ['##ak'] ['believe']\n",
      "['...'] ['with'] ['with']\n",
      "['...'] ['gala'] ['##t']\n",
      "['.'] ['##nos'] ['really']\n",
      "['...'] ['usa'] ['contract']\n",
      "['...'] ['mo'] ['happy']\n",
      "['.'] ['stay'] ['press']\n",
      "[[157, 6], [0, 0]]\n",
      "['and'] ['##na'] ['slept']\n",
      "['...'] ['director'] ['watching']\n",
      "['...'] ['with'] ['next']\n",
      "['...'] ['gala'] ['today']\n",
      "['...'] ['miss'] ['morning']\n",
      "['...'] ['##nos'] ['show']\n",
      "[[163, 6], [0, 0]]\n",
      "['herself'] ['she'] ['still']\n",
      "['herself'] ['quit'] ['make']\n",
      "['her'] ['##ak'] ['there']\n",
      "['her'] ['##ler'] ['watching']\n",
      "[[167, 6], [0, 0]]\n",
      "['herself'] ['why'] ['##s']\n",
      "['herself'] ['usa'] ['herself']\n",
      "['herself'] ['##na'] ['biggest']\n",
      "['...'] ['she'] ['never']\n",
      "['...'] ['mo'] ['problem']\n",
      "['.'] ['quit'] ['really']\n",
      "['herself'] ['with'] ['taken']\n",
      "['...'] ['##ler'] ['that']\n",
      "['.'] ['miss'] ['responsibility']\n",
      "[[175, 6], [1, 0]]\n",
      "['and'] ['##na'] ['##s']\n",
      "['.'] ['she'] ['everybody']\n",
      "['herself'] ['quit'] ['else']\n",
      "['herself'] ['talks'] ['finger']\n",
      "[[179, 6], [1, 0]]\n",
      "['.'] ['\"'] ['gala']\n",
      "['\"'] ['she'] ['##nos']\n",
      "['\"'] ['she'] ['pictures']\n",
      "['and'] ['mo'] ['your']\n",
      "['shows'] ['##ak'] ['##e']\n",
      "['.'] ['##ler'] ['talking']\n",
      "['and'] ['questions'] ['about']\n",
      "[[186, 6], [1, 0]]\n",
      "['the'] ['\"'] ['mo']\n",
      "['and'] ['\"'] ['##ak']\n",
      "['and'] ['mo'] ['##ler']\n",
      "['more'] ['talks'] ['pictures']\n",
      "[[190, 6], [1, 0]]\n",
      "['...'] ['why'] ['anymore']\n",
      "['it'] ['##na'] ['couldn']\n",
      "['it'] ['director'] ['lying']\n",
      "['...'] ['mo'] ['##t']\n",
      "['...'] ['##ak'] ['stand']\n",
      "[[195, 6], [1, 0]]\n",
      "['.'] ['why'] ['were']\n",
      "['.'] ['##s'] ['contracts']\n",
      "['.'] ['quit'] ['made']\n",
      "['.'] ['##ak'] ['state']\n",
      "['.'] ['with'] ['invalid']\n",
      "['.'] ['##ler'] ['license']\n",
      "['.'] ['talks'] ['##es']\n",
      "[[202, 6], [1, 0]]\n",
      "['.'] ['why'] ['much']\n",
      "['and'] ['##na'] ['me']\n",
      "['.'] ['##ler'] ['just']\n",
      "[[205, 6], [1, 0]]\n",
      "['the'] ['.'] ['gala']\n",
      "['and'] ['usa'] ['pictures']\n",
      "['and'] ['##na'] ['##nos']\n",
      "['...'] ['director'] ['where']\n",
      "['well'] ['mo'] ['when']\n",
      "['and'] ['with'] ['talking']\n",
      "['.'] ['gala'] ['says']\n",
      "['.'] ['but'] ['open']\n",
      "['and'] ['miss'] ['about']\n",
      "['##t'] ['stay'] ['wind']\n",
      "[[215, 6], [1, 0]]\n",
      "['.'] ['\"'] ['mo']\n",
      "['.'] ['\"'] ['##ak']\n",
      "['.'] ['she'] ['point']\n",
      "['.'] ['mo'] ['##ler']\n",
      "['.'] ['questions'] ['that']\n",
      "[[220, 6], [1, 0]]\n",
      "['and'] ['##na'] ['such']\n",
      "['.'] ['she'] ['many']\n",
      "['and'] ['quit'] ['factors']\n",
      "['and'] ['##ak'] ['complicated']\n",
      "['.'] ['##ler'] ['story']\n",
      "['and'] ['talks'] ['with']\n",
      "[[226, 6], [1, 0]]\n",
      "['\"'] ['##na'] ['me']\n",
      "['.'] ['she'] ['contract']\n",
      "['.'] ['##ler'] ['always']\n",
      "['.'] ['talks'] ['about']\n",
      "[[230, 6], [1, 0]]\n",
      "['...'] ['why'] ['york']\n",
      "['her'] ['##na'] ['didn']\n",
      "['...'] ['mo'] ['##t']\n",
      "[[233, 6], [1, 0]]\n",
      "['.'] ['why'] ['point']\n",
      "['...'] ['usa'] ['conference']\n",
      "['...'] ['##ak'] ['accountability']\n",
      "['...'] ['director'] ['that']\n",
      "['.'] ['quit'] ['time']\n",
      "['.'] ['mike'] ['there']\n",
      "['.'] ['i'] ['there']\n",
      "['.'] ['##ak'] ['hoping']\n",
      "['.'] ['gala'] ['would']\n",
      "['...'] ['could'] ['wasn']\n",
      "['...'] ['miss'] ['that']\n",
      "['...'] ['not'] ['##t']\n",
      "['.'] ['talks'] ['some']\n",
      "['.'] ['usa'] ['press']\n",
      "['.'] ['mo'] ['some']\n",
      "[[248, 6], [1, 0]]\n",
      "['\"'] ['\"'] ['gala']\n",
      "['more'] ['why'] ['meeting']\n",
      "['her'] ['##s'] ['##nos']\n",
      "['.'] ['mo'] ['what']\n",
      "['.'] ['##ak'] ['happened']\n",
      "['more'] ['talks'] ['that']\n",
      "[[254, 6], [1, 0]]\n",
      "['and'] ['##ak'] ['carrie']\n",
      "['it'] ['##ler'] ['talk']\n",
      "[[256, 6], [1, 0]]\n",
      "[[256, 6], [1, 0]]\n",
      "['.'] ['\"'] ['mo']\n",
      "['.'] ['and'] ['##ak']\n",
      "['.'] ['mo'] ['##ler']\n",
      "['.'] ['##ak'] ['there']\n",
      "['.'] ['miss'] ['little']\n",
      "['.'] ['questions'] ['tension']\n",
      "[[262, 6], [1, 0]]\n",
      "['and'] ['why'] ['miss']\n",
      "['.'] ['usa'] ['together']\n",
      "['.'] ['quit'] ['that']\n",
      "['.'] ['##ak'] ['first']\n",
      "['.'] ['gala'] ['room']\n",
      "['.'] ['##ler'] ['time']\n",
      "['.'] ['miss'] ['were']\n",
      "['.'] ['talks'] ['since']\n",
      "[[270, 6], [1, 0]]\n",
      "['her'] ['why'] ['read']\n",
      "['so'] ['##ak'] ['feelings']\n",
      "['her'] ['mo'] ['read']\n",
      "['so'] ['mike'] ['seen']\n",
      "[\"'\"] ['miss'] ['seen']\n",
      "['more'] ['##nos'] ['there']\n",
      "['more'] ['mo'] ['were']\n",
      "[[277, 6], [1, 0]]\n",
      "['.'] ['why'] ['iv']\n",
      "['.'] ['usa'] ['long']\n",
      "['.'] ['she'] ['##e']\n",
      "['.'] ['director'] ['time']\n",
      "['.'] ['quit'] ['known']\n",
      "['.'] ['with'] ['carrie']\n",
      "[[283, 6], [1, 0]]\n",
      "['and'] ['##na'] ['stayed']\n",
      "['her'] ['quit'] ['friend']\n",
      "['her'] ['##ler'] ['home']\n",
      "[[286, 6], [1, 0]]\n",
      "[\"'\"] ['why'] ['there']\n",
      "['yeah'] ['##ak'] ['working']\n",
      "[\"'\"] ['##na'] ['cared']\n",
      "['...'] ['##ler'] ['things']\n",
      "['yeah'] ['mo'] ['about']\n",
      "['yeah'] ['mike'] ['were']\n",
      "['and'] ['##ak'] ['each']\n",
      "['yeah'] ['gala'] ['talking']\n",
      "['yeah'] ['##ler'] ['other']\n",
      "['yeah'] ['usa'] ['hurt']\n",
      "['like'] ['mo'] ['were']\n",
      "[[297, 6], [1, 0]]\n",
      "['.'] ['##na'] ['went']\n",
      "['.'] ['mo'] ['very']\n",
      "['.'] ['##ak'] ['quickly']\n",
      "[[300, 6], [1, 0]]\n",
      "['others'] ['\"'] ['gala']\n",
      "['and'] ['##na'] ['##nos']\n",
      "['and'] ['she'] ['that']\n",
      "['more'] ['miss'] ['your']\n",
      "['and'] ['questions'] ['cared']\n",
      "['her'] ['usa'] ['friend']\n",
      "[[306, 6], [1, 0]]\n",
      "['.'] ['mo'] ['relationship']\n",
      "['.'] ['##ak'] ['over']\n",
      "[[308, 6], [1, 0]]\n",
      "['.'] ['\"'] ['mo']\n",
      "['.'] ['##na'] ['##ak']\n",
      "['.'] ['mo'] ['##ler']\n",
      "['.'] ['talks'] ['mother']\n",
      "[[312, 6], [1, 0]]\n",
      "['.'] ['why'] ['still']\n",
      "['.'] ['##na'] ['have']\n",
      "['.'] ['she'] ['care']\n",
      "['.'] ['mo'] ['three']\n",
      "['.'] ['quit'] ['about']\n",
      "['.'] ['##ak'] ['children']\n",
      "['.'] ['with'] ['carrie']\n",
      "[[319, 6], [1, 0]]\n",
      "['...'] ['usa'] ['some']\n",
      "['...'] ['##ak'] ['##s']\n",
      "['...'] ['##na'] ['think']\n",
      "['...'] ['she'] ['used']\n",
      "['.'] ['mike'] ['these']\n",
      "['.'] ['i'] ['these']\n",
      "['...'] ['##ak'] ['##s']\n",
      "['...'] ['gala'] ['other']\n",
      "['...'] ['could'] ['different']\n",
      "['...'] ['##ler'] ['been']\n",
      "['...'] ['##nos'] ['peoples']\n",
      "['...'] ['not'] ['organizations']\n",
      "[[331, 6], [1, 0]]\n",
      "['...'] ['usa'] ['never']\n",
      "['...'] ['##na'] ['biggest']\n",
      "['.'] ['she'] ['never']\n",
      "['...'] ['director'] ['rep']\n",
      "['...'] ['##ler'] ['that']\n",
      "['...'] ['##nos'] ['##ed']\n",
      "[[337, 6], [1, 0]]\n",
      "['.'] ['why'] ['state']\n",
      "['.'] ['##na'] ['makes']\n",
      "['.'] ['she'] ['director']\n",
      "['.'] ['##ak'] ['contract']\n",
      "[[341, 6], [1, 0]]\n",
      "['.'] ['usa'] ['fair']\n",
      "['.'] ['she'] ['don']\n",
      "['.'] ['quit'] ['##t']\n",
      "['.'] ['with'] ['think']\n",
      "['.'] ['##ler'] ['that']\n",
      "['.'] ['miss'] ['that']\n",
      "['.'] ['usa'] ['##s']\n",
      "[[348, 6], [1, 0]]\n",
      "['.'] ['\"'] ['gala']\n",
      "['\"'] ['\"'] ['##nos']\n",
      "['.'] ['she'] ['beginning']\n",
      "['a'] ['##ak'] ['back']\n",
      "['.'] ['##ler'] ['track']\n",
      "[[353, 6], [1, 0]]\n",
      "['.'] ['.'] ['when']\n",
      "['.'] ['why'] ['your']\n",
      "['a'] ['she'] ['##e']\n",
      "['.'] ['director'] ['were']\n",
      "['.'] ['mo'] ['heard']\n",
      "['.'] ['##ak'] ['that']\n",
      "['and'] ['with'] ['same']\n",
      "['.'] ['gala'] ['angry']\n",
      "['a'] ['##ler'] ['answer']\n",
      "['.'] ['##nos'] ['with']\n",
      "['a'] ['usa'] ['marriage']\n",
      "['more'] ['mo'] ['carrie']\n",
      "[[365, 6], [1, 0]]\n",
      "['.'] ['she'] ['that']\n",
      "['and'] ['mo'] ['want']\n",
      "['the'] ['quit'] ['point']\n",
      "['.'] ['questions'] ['lose']\n",
      "[[369, 6], [1, 0]]\n",
      "['.'] ['\"'] ['what']\n",
      "['.'] ['mo'] ['your']\n",
      "['a'] ['##ak'] ['reaction']\n",
      "[[372, 6], [1, 0]]\n",
      "['and'] ['\"'] ['mo']\n",
      "['and'] ['why'] ['angry']\n",
      "['and'] ['##na'] ['##ak']\n",
      "['\"'] ['mo'] ['##ler']\n",
      "['is'] ['##ler'] ['wasn']\n",
      "['more'] ['miss'] ['little']\n",
      "['and'] ['talks'] ['##t']\n",
      "['and'] ['and'] ['hurt']\n",
      "[[380, 6], [1, 0]]\n",
      "['she'] ['##na'] ['great']\n",
      "['herself'] ['mo'] ['deal']\n",
      "['.'] ['with'] ['have']\n",
      "['shot'] ['miss'] ['supported']\n",
      "['and'] ['talks'] ['sponsors']\n",
      "[[385, 6], [1, 0]]\n",
      "['.'] ['quit'] ['after']\n",
      "['.'] ['mike'] ['write']\n",
      "[[387, 6], [1, 0]]\n",
      "['.'] ['##na'] ['cong']\n",
      "['.'] ['mo'] ['##rat']\n",
      "['.'] ['##ak'] ['##ulated']\n",
      "[[390, 6], [1, 0]]\n",
      "['no'] ['why'] ['that']\n",
      "['i'] ['##ak'] ['think']\n",
      "['shot'] ['with'] ['really']\n",
      "['t'] ['##na'] ['told']\n",
      "['shot'] ['miss'] ['loved']\n",
      "['and'] ['quit'] ['stayed']\n",
      "['and'] ['mike'] ['also']\n",
      "['shot'] ['i'] ['hurt']\n",
      "['...'] ['with'] ['true']\n",
      "['shot'] ['could'] ['some']\n",
      "['shot'] ['but'] ['cared']\n",
      "['.'] ['##nos'] ['that']\n",
      "['shot'] ['not'] ['people']\n",
      "['shot'] ['i'] ['about']\n",
      "['more'] ['talks'] ['happy']\n",
      "['t'] ['usa'] ['herself']\n",
      "['shot'] ['stay'] ['that']\n",
      "[[407, 6], [1, 0]]\n",
      "['and'] ['.'] ['gala']\n",
      "['.'] ['why'] ['give']\n",
      "['and'] ['##na'] ['##nos']\n",
      "['.'] ['she'] ['that']\n",
      "['.'] ['director'] ['still']\n",
      "['a'] ['quit'] ['answer']\n",
      "['.'] ['gala'] ['miss']\n",
      "['.'] ['##ler'] ['##t']\n",
      "['.'] ['miss'] ['that']\n",
      "['.'] ['talks'] ['someone']\n",
      "['.'] ['usa'] ['question']\n",
      "[[418, 6], [1, 0]]\n",
      "['more'] ['\"'] ['mo']\n",
      "['herself'] ['why'] ['absolutely']\n",
      "['and'] ['she'] ['##ak']\n",
      "['her'] ['mo'] ['##ler']\n",
      "[[422, 6], [1, 0]]\n",
      "['so'] ['usa'] ['were']\n",
      "['so'] ['##ak'] ['like']\n",
      "['\"'] ['##na'] ['there']\n",
      "['...'] ['she'] ['panel']\n",
      "['.'] ['director'] ['some']\n",
      "['.'] ['##ler'] ['that']\n",
      "['.'] ['mo'] ['were']\n",
      "['...'] ['mike'] ['people']\n",
      "['...'] ['i'] ['answer']\n",
      "['so'] ['gala'] ['that']\n",
      "['.'] ['##nos'] ['didn']\n",
      "['...'] ['usa'] ['there']\n",
      "['...'] ['mo'] ['##t']\n",
      "[[435, 6], [1, 0]]\n",
      "['.'] ['she'] ['take']\n",
      "['.'] ['quit'] ['into']\n",
      "['.'] ['##ak'] ['things']\n",
      "['...'] ['talks'] ['have']\n",
      "['...'] ['usa'] ['your']\n",
      "[[440, 6], [1, 0]]\n",
      "['\"'] ['\"'] ['gala']\n",
      "['her'] ['why'] ['lost']\n",
      "['and'] ['##na'] ['##nos']\n",
      "['and'] ['mo'] ['do']\n",
      "['her'] ['quit'] ['because']\n",
      "['and'] ['##ler'] ['think']\n",
      "['and'] ['miss'] ['that']\n",
      "['her'] ['usa'] ['answer']\n",
      "[[448, 6], [1, 0]]\n",
      "['.'] ['.'] ['mo']\n",
      "['.'] ['why'] ['been']\n",
      "['.'] ['she'] ['##ak']\n",
      "['.'] ['she'] ['shown']\n",
      "['.'] ['director'] ['wasn']\n",
      "['.'] ['##ler'] ['that']\n",
      "['.'] ['mo'] ['##ler']\n",
      "['.'] ['quit'] ['through']\n",
      "['.'] ['mike'] ['##t']\n",
      "['...'] ['gala'] ['winning']\n",
      "['...'] ['could'] ['point']\n",
      "['...'] ['miss'] ['scores']\n",
      "['.'] ['usa'] ['that']\n",
      "['.'] ['mo'] ['points']\n",
      "[[462, 6], [1, 0]]\n",
      "['.'] ['\"'] ['this']\n",
      "['and'] ['why'] ['opinion']\n",
      "['herself'] ['mo'] ['never']\n",
      "['.'] ['##ak'] ['been']\n",
      "['.'] ['##ler'] ['about']\n",
      "[[467, 6], [1, 0]]\n",
      "['her'] ['she'] ['opinion']\n",
      "['.'] ['mo'] ['want']\n",
      "['her'] ['talks'] ['have']\n",
      "[[470, 6], [1, 0]]\n",
      "['.'] ['why'] ['where']\n",
      "['.'] ['usa'] ['come']\n",
      "['herself'] ['director'] ['into']\n",
      "['...'] ['mo'] ['able']\n",
      "['...'] ['left'] ['first']\n",
      "['...'] ['mike'] ['this']\n",
      "['.'] ['with'] ['amendment']\n",
      "['her'] ['##ler'] ['this']\n",
      "[[478, 6], [1, 0]]\n",
      "['...'] ['why'] ['young']\n",
      "['...'] ['usa'] ['public']\n",
      "['...'] ['##ak'] ['think']\n",
      "['.'] ['anymore'] ['other']\n",
      "['.'] ['carrie'] ['side']\n",
      "[\"'\"] ['##na'] ['thing']\n",
      "['.'] ['she'] ['girl']\n",
      "['.'] ['director'] ['stage']\n",
      "['...'] ['miss'] ['handle']\n",
      "['...'] ['believe'] ['side']\n",
      "['...'] ['for'] ['that']\n",
      "['...'] ['you'] ['voice']\n",
      "['...'] ['lot'] ['what']\n",
      "['.'] ['say'] ['their']\n",
      "['...'] ['##ak'] ['this']\n",
      "['...'] ['could'] ['prepared']\n",
      "['...'] ['but'] ['backlash']\n",
      "['.'] ['it'] ['there']\n",
      "['...'] ['you'] ['opinion']\n",
      "['...'] ['our'] ['said']\n",
      "['.'] ['##nos'] ['don']\n",
      "['.'] ['time'] ['same']\n",
      "['.'] ['mo'] ['##t']\n",
      "['.'] ['stay'] ['ready']\n",
      "['.'] ['been'] ['another']\n",
      "['.'] ['gala'] ['right']\n",
      "[[504, 6], [1, 0]]\n",
      "['.'] ['\"'] ['there']\n",
      "[[505, 6], [1, 0]]\n",
      "['.'] ['why'] ['people']\n",
      "['and'] ['##na'] ['just']\n",
      "['.'] ['she'] ['that']\n",
      "['and'] ['mo'] ['that']\n",
      "['so'] ['##ak'] ['there']\n",
      "['so'] ['with'] ['allowed']\n",
      "['.'] ['talks'] ['other']\n",
      "[[512, 6], [1, 0]]\n",
      "['\"'] ['\"'] ['gala']\n",
      "['.'] ['usa'] ['your']\n",
      "[\"'\"] ['##na'] ['##nos']\n",
      "['...'] ['she'] ['office']\n",
      "['...'] ['director'] ['##e']\n",
      "['...'] ['miss'] ['keeping']\n",
      "['.'] ['mo'] ['when']\n",
      "['.'] ['quit'] ['with']\n",
      "['.'] ['mike'] ['about']\n",
      "['.'] ['i'] ['press']\n",
      "['.'] ['gala'] ['ready']\n",
      "['.'] ['could'] ['conference']\n",
      "['.'] ['but'] ['crown']\n",
      "['.'] ['##ler'] ['were']\n",
      "['.'] ['miss'] ['trump']\n",
      "['.'] ['stay'] ['says']\n",
      "[[528, 6], [1, 0]]\n",
      "['.'] ['mo'] ['object']\n",
      "['.'] ['##ler'] ['that']\n",
      "['...'] ['talks'] ['point']\n",
      "[[531, 6], [1, 0]]\n",
      "['.'] ['\"'] ['mo']\n",
      "[\"'\"] ['she'] ['##ak']\n",
      "['.'] ['she'] ['keeping']\n",
      "['.'] ['director'] ['there']\n",
      "['.'] ['mo'] ['##ler']\n",
      "['\"'] ['with'] ['title']\n",
      "['...'] ['miss'] ['before']\n",
      "['.'] ['usa'] ['going']\n",
      "[[539, 6], [1, 0]]\n",
      "['...'] ['why'] ['happens']\n",
      "[']'] ['usa'] ['##ch']\n",
      "['her'] ['mo'] ['said']\n",
      "['...'] ['mike'] ['contract']\n",
      "[']'] ['talks'] ['what']\n",
      "[[544, 6], [1, 0]]\n",
      "['.'] ['mo'] ['said']\n",
      "['.'] ['##ler'] ['fire']\n",
      "[[546, 6], [1, 0]]\n",
      "['her'] ['why'] ['pictures']\n",
      "['and'] ['##na'] ['said']\n",
      "['and'] ['she'] ['come']\n",
      "['and'] ['mo'] ['what']\n",
      "['and'] ['##ak'] ['happens']\n",
      "['her'] ['talks'] ['more']\n",
      "[[552, 6], [1, 0]]\n",
      "['.'] ['##s'] ['said']\n",
      "['.'] ['##ak'] ['fire']\n",
      "[[554, 6], [1, 0]]\n",
      "['...'] ['usa'] ['didn']\n",
      "['...'] ['##na'] ['thought']\n",
      "['...'] ['director'] ['##t']\n",
      "['.'] ['quit'] ['press']\n",
      "['...'] ['##ak'] ['would']\n",
      "['...'] ['with'] ['conference']\n",
      "['...'] ['gala'] ['that']\n",
      "['...'] ['talks'] ['that']\n",
      "[[562, 6], [1, 0]]\n",
      "['and'] ['she'] ['being']\n",
      "['.'] ['mo'] ['more']\n",
      "['.'] ['##ak'] ['finger']\n",
      "['...'] ['with'] ['again']\n",
      "[[566, 6], [1, 0]]\n",
      "['.'] ['##ak'] ['hard']\n",
      "[[567, 6], [1, 0]]\n",
      "['myself'] ['##ak'] ['me']\n",
      "['...'] ['##na'] ['have']\n",
      "['...'] ['she'] ['business']\n",
      "['...'] ['director'] ['california']\n",
      "['.'] ['mike'] ['makes']\n",
      "['.'] ['##ak'] ['understand']\n",
      "['.'] ['##ler'] ['that']\n",
      "['.'] ['miss'] ['york']\n",
      "['.'] ['##nos'] ['hard']\n",
      "['.'] ['talks'] ['taking']\n",
      "['.'] ['usa'] ['back']\n",
      "[[578, 6], [1, 0]]\n",
      "['\"'] ['\"'] ['gala']\n",
      "['like'] ['why'] ['could']\n",
      "['?'] ['##na'] ['##nos']\n",
      "['.'] ['she'] ['have']\n",
      "['.'] ['quit'] ['done']\n",
      "['.'] ['##ak'] ['there']\n",
      "['you'] ['##ler'] ['something']\n",
      "['.'] ['miss'] ['calm']\n",
      "['.'] ['usa'] ['things']\n",
      "[[587, 6], [1, 0]]\n",
      "['...'] ['.'] ['mo']\n",
      "['...'] ['why'] ['spoken']\n",
      "['...'] ['with'] ['what']\n",
      "['...'] ['##na'] ['##ak']\n",
      "['...'] ['director'] ['would']\n",
      "['...'] ['##ler'] ['supported']\n",
      "['...'] ['believe'] ['might']\n",
      "['...'] ['mo'] ['##ler']\n",
      "['...'] ['quit'] ['me']\n",
      "['...'] ['mike'] ['have']\n",
      "['...'] ['usa'] ['next']\n",
      "['...'] ['in'] ['have']\n",
      "['...'] ['with'] ['after']\n",
      "['...'] ['gala'] ['stayed']\n",
      "['...'] ['but'] ['steps']\n",
      "['...'] ['it'] ['wanted']\n",
      "['...'] ['not'] ['found']\n",
      "['...'] ['i'] ['were']\n",
      "['.'] ['no'] ['that']\n",
      "['.'] ['been'] ['take']\n",
      "[[607, 6], [1, 0]]\n",
      "['and'] ['why'] ['some']\n",
      "['me'] ['##na'] ['would']\n",
      "['herself'] ['mo'] ['have']\n",
      "['.'] ['##ak'] ['helped']\n",
      "['herself'] ['with'] ['media']\n",
      "['her'] ['miss'] ['training']\n",
      "['herself'] ['talks'] ['with']\n",
      "[[614, 6], [1, 0]]\n",
      "['...'] ['anymore'] ['pressure']\n",
      "['...'] ['me'] ['would']\n",
      "['...'] ['##nos'] ['##ly']\n",
      "['...'] ['##na'] ['would']\n",
      "['...'] ['she'] ['more']\n",
      "['...'] ['mo'] ['have']\n",
      "['...'] ['mike'] ['speaking']\n",
      "['...'] ['i'] ['do']\n",
      "['...'] ['a'] ['able']\n",
      "['...'] ['say'] ['clearly']\n",
      "['...'] ['##ak'] ['made']\n",
      "['...'] ['gala'] ['about']\n",
      "['...'] ['could'] ['these']\n",
      "['...'] ['##ler'] ['sure']\n",
      "['...'] ['have'] ['that']\n",
      "['...'] ['time'] ['speak']\n",
      "['...'] ['mo'] ['when']\n",
      "['...'] ['no'] ['this']\n",
      "[[632, 6], [1, 0]]\n",
      "['that'] ['##na'] ['would']\n",
      "['her'] ['##ak'] ['able']\n",
      "[[634, 6], [1, 0]]\n",
      "['.'] ['##ak'] ['these']\n",
      "['etc'] ['##na'] ['would']\n",
      "['etc'] ['director'] ['##s']\n",
      "['etc'] ['##ler'] ['things']\n",
      "['.'] ['mike'] ['getting']\n",
      "['...'] ['##ak'] ['able']\n",
      "['...'] ['gala'] ['attacked']\n",
      "['...'] ['could'] ['coming']\n",
      "['...'] ['miss'] ['understand']\n",
      "['.'] ['not'] ['from']\n",
      "['a'] ['mo'] ['where']\n",
      "[[645, 6], [1, 0]]\n",
      "['\"'] ['\"'] ['there']\n",
      "['.'] ['usa'] ['didn']\n",
      "['she'] ['##na'] ['were']\n",
      "['...'] ['she'] ['##ed']\n",
      "['herself'] ['director'] ['##t']\n",
      "['herself'] ['mike'] ['even']\n",
      "['her'] ['##ak'] ['many']\n",
      "['.'] ['gala'] ['stand']\n",
      "['her'] ['##ler'] ['organizations']\n",
      "['.'] ['talks'] ['that']\n",
      "['.'] ['mo'] ['chance']\n",
      "[[656, 6], [1, 0]]\n",
      "0.007541478129713424\n",
      "Elapsed Time: 52.29053616523743 seconds\n",
      "Summary 6 of batch\n",
      "['...'] ['measurement'] ['number']\n",
      "['...'] ['to'] ['significantly']\n",
      "['...'] ['has'] ['dangerous']\n",
      "['...'] ['va'] ['phoenix']\n",
      "['...'] ['performers'] ['veterans']\n",
      "['...'] ['demonstrate'] ['higher']\n",
      "['...'] ['been'] ['infections']\n",
      "['...'] ['##s'] ['facility']\n",
      "['...'] ['phoenix'] ['crisis']\n",
      "['...'] ['##s'] ['va']\n",
      "['...'] ['improvement'] ['rates']\n",
      "['...'] ['used'] ['than']\n",
      "['...'] ['database'] ['hospitals']\n",
      "['...'] ['programs'] ['hospitals']\n",
      "['...'] ['offers'] ['internal']\n",
      "['...'] ['##s'] ['among']\n",
      "['...'] ['that'] ['that']\n",
      "['...'] ['inspector'] ['mortality']\n",
      "['...'] ['data'] ['agency']\n",
      "['...'] ['increased'] ['records']\n",
      "['...'] ['\"'] ['heart']\n",
      "['...'] ['among'] ['department']\n",
      "['...'] ['fail'] ['show']\n",
      "['...'] ['for'] ['##s']\n",
      "['...'] ['variation'] ['show']\n",
      "[[24, 1], [0, 0]]\n",
      "['...'] ['common'] ['##ated']\n",
      "['...'] ['top'] ['secretary']\n",
      "['...'] ['measurement'] ['focused']\n",
      "['...'] ['hospitals'] ['system']\n",
      "['...'] ['va'] ['criticism']\n",
      "['...'] ['infections'] ['last']\n",
      "['...'] ['va'] ['largely']\n",
      "['...'] ['been'] ['nu']\n",
      "['...'] ['hospitals'] ['that']\n",
      "['...'] ['in'] ['weeks']\n",
      "['...'] ['improvement'] ['across']\n",
      "['...'] ['used'] ['##m']\n",
      "['...'] ['va'] ['resignation']\n",
      "['...'] ['va'] ['##se']\n",
      "['...'] ['##s'] ['##ki']\n",
      "['...'] ['that'] ['wait']\n",
      "['...'] ['inspector'] ['va']\n",
      "['...'] ['data'] ['hospital']\n",
      "['...'] ['mortality'] ['##pit']\n",
      "['...'] ['among'] ['va']\n",
      "['...'] ['fail'] ['times']\n",
      "['...'] ['general'] ['##s']\n",
      "['...'] ['for'] ['medical']\n",
      "[[47, 1], [0, 0]]\n",
      "['...'] ['common'] ['outcomes']\n",
      "['...'] ['top'] ['made']\n",
      "['...'] ['measurement'] ['journal']\n",
      "['...'] ['to'] ['di']\n",
      "['...'] ['has'] ['what']\n",
      "['...'] ['in'] ['recent']\n",
      "['...'] ['performers'] ['available']\n",
      "['...'] ['been'] ['some']\n",
      "['...'] ['medical'] ['years']\n",
      "['...'] ['improvement'] ['##ate']\n",
      "['...'] ['used'] ['va']\n",
      "['...'] ['va'] ['dozen']\n",
      "['...'] ['va'] ['treatment']\n",
      "['...'] ['the'] ['doctors']\n",
      "['...'] ['or'] ['some']\n",
      "['...'] ['hospitals'] ['va']\n",
      "['...'] ['##s'] ['wall']\n",
      "['...'] ['that'] ['challenge']\n",
      "['...'] ['inspector'] ['results']\n",
      "['...'] ['##s'] ['va']\n",
      "['...'] ['among'] ['hospitals']\n",
      "['...'] ['independent'] ['street']\n",
      "['['] ['medical'] ['facilities']\n",
      "[[70, 1], [0, 0]]\n",
      "['.'] ['.'] ['some']\n",
      "['.'] ['common'] ['##cies']\n",
      "['.'] ['top'] ['agency']\n",
      "['.'] ['measurement'] ['care']\n",
      "['.'] ['to'] ['states']\n",
      "['.'] ['performers'] ['known']\n",
      "['.'] ['programs'] ['nu']\n",
      "['.'] ['higher'] ['##re']\n",
      "['.'] ['##s'] ['high']\n",
      "['.'] ['that'] ['##m']\n",
      "[[80, 1], [0, 0]]\n",
      "['.'] ['top'] ['##ous']\n",
      "['.'] ['measurement'] ['nu']\n",
      "['.'] ['to'] ['among']\n",
      "['.'] ['has'] ['than']\n",
      "['.'] ['hospitals'] ['hospitals']\n",
      "['.'] ['in'] ['march']\n",
      "['.'] ['families'] ['nu']\n",
      "['...'] ['va'] ['rate']\n",
      "['.'] ['infections'] ['infections']\n",
      "['...'] ['performers'] ['lines']\n",
      "['...'] ['va'] ['##m']\n",
      "['.'] ['exhibit'] ['patients']\n",
      "['...'] ['va'] ['data']\n",
      "['...'] ['should'] ['##m']\n",
      "['.'] ['phoenix'] ['from']\n",
      "['.'] ['database'] ['from']\n",
      "['.'] ['issues'] ['nu']\n",
      "['.'] ['va'] ['central']\n",
      "['.'] ['va'] ['more']\n",
      "['.'] ['programs'] ['times']\n",
      "['.'] ['-'] ['##m']\n",
      "['.'] ['public'] ['show']\n",
      "['.'] ['increased'] ['lethal']\n",
      "['.'] ['hospitals'] ['intra']\n",
      "['.'] ['##s'] ['than']\n",
      "['.'] ['inspector'] ['phoenix']\n",
      "['.'] ['increased'] ['year']\n",
      "['.'] ['mortality'] ['blood']\n",
      "['.'] ['fail'] ['high']\n",
      "['.'] ['general'] ['facility']\n",
      "['.'] ['for'] ['va']\n",
      "['.'] ['variability'] ['ended']\n",
      "[[110, 3], [0, 0]]\n",
      "['\"'] ['.'] ['those']\n",
      "['...'] ['\"'] ['quickly']\n",
      "['...'] ['top'] ['kill']\n",
      "['...'] ['measurement'] ['within']\n",
      "['or'] ['va'] ['infections']\n",
      "['.'] ['\"'] ['cause']\n",
      "['.'] ['va'] ['days']\n",
      "['.'] ['hospitals'] ['called']\n",
      "['.'] ['in'] ['multiple']\n",
      "['.'] ['in'] ['otherwise']\n",
      "['.'] ['have'] ['sep']\n",
      "['.'] ['va'] ['relatively']\n",
      "['.'] ['facilities'] ['even']\n",
      "['.'] ['higher'] ['##sis']\n",
      "['.'] ['that'] ['hours']\n",
      "['.'] ['independent'] ['patient']\n",
      "[[126, 3], [0, 0]]\n",
      "['.'] ['top'] ['result']\n",
      "['.'] ['the'] ['data']\n",
      "['.'] ['hospitals'] ['don']\n",
      "['.'] ['in'] ['patients']\n",
      "['.'] ['are'] ['##t']\n",
      "['.'] ['va'] ['died']\n",
      "['.'] ['higher'] ['show']\n",
      "['.'] ['mortality'] ['what']\n",
      "[[134, 3], [0, 0]]\n",
      "['.'] ['.'] ['among']\n",
      "['.'] ['top'] ['health']\n",
      "['.'] ['measurement'] ['nu']\n",
      "['.'] ['to'] ['##m']\n",
      "['...'] ['in'] ['##ly']\n",
      "['...'] ['outcomes'] ['medical']\n",
      "['.'] ['va'] ['patients']\n",
      "['.'] ['performers'] ['care']\n",
      "['.'] ['va'] ['##m']\n",
      "['.'] ['va'] ['finding']\n",
      "['.'] ['medical'] ['significant']\n",
      "['.'] ['should'] ['analysts']\n",
      "['.'] ['hospitals'] ['admitted']\n",
      "['...'] ['phoenix'] ['care']\n",
      "['...'] ['in'] ['system']\n",
      "['.'] ['database'] ['flag']\n",
      "['.'] ['programs'] ['higher']\n",
      "['.'] ['va'] ['death']\n",
      "['.'] ['the'] ['performing']\n",
      "['.'] ['hospitals'] ['phoenix']\n",
      "['.'] ['inspector'] ['rate']\n",
      "['.'] ['data'] ['va']\n",
      "['.'] ['##s'] ['agency']\n",
      "['.'] ['mortality'] ['hospital']\n",
      "['...'] ['among'] ['va']\n",
      "['.'] ['fail'] ['nu']\n",
      "['.'] ['general'] ['than']\n",
      "['.'] ['for'] ['hospitals']\n",
      "['.'] ['medical'] ['##s']\n",
      "[[163, 3], [0, 0]]\n",
      "['.'] ['common'] ['considered']\n",
      "['.'] ['to'] ['##m']\n",
      "['.'] ['va'] ['contrast']\n",
      "['.'] ['\"'] ['among']\n",
      "['.'] ['performers'] ['central']\n",
      "['.'] ['va'] ['rate']\n",
      "['.'] ['hospitals'] ['boston']\n",
      "['.'] ['in'] ['iv']\n",
      "['.'] ['##s'] ['that']\n",
      "['.'] ['improvement'] ['below']\n",
      "['.'] ['used'] ['performing']\n",
      "['...'] ['have'] ['##s']\n",
      "['...'] ['va'] ['systems']\n",
      "['...'] ['va'] ['line']\n",
      "['.'] ['the'] ['hospitals']\n",
      "['...'] ['higher'] ['va']\n",
      "['...'] ['hospitals'] ['best']\n",
      "['...'] ['##s'] ['blood']\n",
      "['.'] ['inspector'] ['average']\n",
      "['.'] ['mortality'] ['hospital']\n",
      "['.'] ['fail'] ['nu']\n",
      "[[184, 3], [0, 0]]\n",
      "['.'] ['common'] ['than']\n",
      "['.'] ['va'] ['also']\n",
      "['.'] ['\"'] ['average']\n",
      "['.'] ['performers'] ['mortality']\n",
      "['.'] ['in'] ['rate']\n",
      "['.'] ['va'] ['nu']\n",
      "['.'] ['higher'] ['slightly']\n",
      "['.'] [')'] ['##m']\n",
      "['.'] ['mortality'] ['better']\n",
      "['.'] ['internal'] ['care']\n",
      "[[194, 3], [0, 0]]\n",
      "['...'] ['\"'] ['scott']\n",
      "['...'] ['top'] ['system']\n",
      "['...'] ['to'] ['bench']\n",
      "['...'] ['va'] ['mc']\n",
      "['...'] ['performers'] ['said']\n",
      "['.'] ['hospitals'] ['##ro']\n",
      "['.'] ['in'] ['phoenix']\n",
      "['...'] ['monitoring'] ['internal']\n",
      "['.'] ['used'] ['public']\n",
      "['...'] ['va'] ['va']\n",
      "['...'] ['va'] ['monday']\n",
      "['...'] ['programs'] ['measurement']\n",
      "['...'] ['va'] ['improvement']\n",
      "['...'] ['the'] ['consumption']\n",
      "['...'] ['lower'] ['##s']\n",
      "['...'] ['hospitals'] ['health']\n",
      "['...'] ['that'] ['system']\n",
      "['.'] ['mortality'] ['spokesman']\n",
      "['...'] ['among'] ['care']\n",
      "['...'] ['internal'] ['database']\n",
      "[[213, 4], [0, 0]]\n",
      "['...'] ['common'] ['care']\n",
      "['...'] ['performers'] ['well']\n",
      "['...'] ['va'] ['measure']\n",
      "['...'] ['demonstrate'] ['hospital']\n",
      "['...'] ['been'] ['medical']\n",
      "['...'] ['in'] ['outside']\n",
      "['...'] ['in'] ['though']\n",
      "['...'] ['##s'] ['because']\n",
      "['...'] ['improvement'] ['groups']\n",
      "['...'] ['used'] ['outcomes']\n",
      "['...'] ['programs'] ['relatively']\n",
      "['...'] ['va'] ['report']\n",
      "['...'] ['hospitals'] ['va']\n",
      "['...'] ['that'] ['small']\n",
      "['...'] ['many'] ['health']\n",
      "['...'] ['were'] ['system']\n",
      "['...'] ['failure'] ['numbers']\n",
      "['...'] ['general'] ['range']\n",
      "[[231, 4], [0, 0]]\n",
      "['.'] ['common'] ['measurement']\n",
      "['.'] ['va'] ['some']\n",
      "['.'] ['performers'] ['##cies']\n",
      "['and'] ['hospitals'] ['experts']\n",
      "['.'] ['in'] ['stand']\n",
      "['.'] ['va'] ['va']\n",
      "['and'] ['higher'] ['medical']\n",
      "['.'] ['among'] ['##re']\n",
      "[[238, 5], [0, 0]]\n",
      "['.'] ['\"'] ['wide']\n",
      "['.'] ['common'] ['both']\n",
      "['.'] ['in'] ['va']\n",
      "['.'] ['higher'] ['problem']\n",
      "['.'] ['hospitals'] ['private']\n",
      "['.'] ['among'] ['hospitals']\n",
      "[[244, 5], [0, 0]]\n",
      "['...'] ['common'] ['much']\n",
      "['...'] ['measurement'] ['said']\n",
      "['...'] ['to'] ['professor']\n",
      "['...'] ['has'] ['public']\n",
      "['.'] ['been'] ['health']\n",
      "['.'] ['va'] ['va']\n",
      "['...'] ['hospitals'] ['would']\n",
      "['...'] ['in'] ['system']\n",
      "['...'] ['##s'] ['##ish']\n",
      "['...'] ['database'] ['system']\n",
      "['...'] ['have'] ['expect']\n",
      "['...'] ['va'] ['like']\n",
      "['...'] ['programs'] ['j']\n",
      "['...'] ['va'] ['harvard']\n",
      "['...'] ['that'] ['##ha']\n",
      "['...'] ['inspector'] ['school']\n",
      "['.'] ['as'] ['national']\n",
      "['.'] ['independent'] ['va']\n",
      "[[261, 6], [0, 0]]\n",
      "['...'] ['common'] ['va']\n",
      "['...'] ['measurement'] ['systems']\n",
      "['.'] ['has'] ['among']\n",
      "['.'] ['hospitals'] ['va']\n",
      "['...'] ['infections'] ['hospitals']\n",
      "['...'] ['performers'] ['dublin']\n",
      "['...'] ['va'] ['lower']\n",
      "['...'] ['demonstrate'] ['boston']\n",
      "['...'] ['va'] ['officials']\n",
      "['.'] ['in'] ['ga']\n",
      "['.'] ['often'] ['data']\n",
      "['.'] ['va'] ['phoenix']\n",
      "['.'] ['programs'] ['facilities']\n",
      "['.'] ['the'] ['performers']\n",
      "['.'] ['offers'] ['internal']\n",
      "['.'] ['novel'] ['point']\n",
      "['.'] ['##s'] ['atlanta']\n",
      "['.'] ['##s'] ['among']\n",
      "['.'] ['that'] ['while']\n",
      "['.'] ['data'] ['according']\n",
      "['.'] ['increased'] ['documents']\n",
      "['...'] ['among'] ['houston']\n",
      "['...'] ['fail'] ['those']\n",
      "[[284, 6], [0, 0]]\n",
      "['.'] ['measurement'] ['known']\n",
      "['.'] ['va'] ['findings']\n",
      "['.'] ['infections'] ['##bl']\n",
      "['.'] ['hospitals'] ['come']\n",
      "['.'] ['in'] ['##ic']\n",
      "['.'] ['data'] ['sail']\n",
      "['...'] ['have'] ['from']\n",
      "['...'] ['va'] ['va']\n",
      "['...'] ['va'] ['improvement']\n",
      "['.'] ['hospitals'] ['database']\n",
      "['.'] ['among'] ['called']\n",
      "[[294, 7], [0, 0]]\n",
      "['.'] ['\"'] ['sail']\n",
      "['.'] ['common'] ['va']\n",
      "['.'] ['top'] ['five']\n",
      "['.'] ['measurement'] ['star']\n",
      "['.'] ['va'] ['tracks']\n",
      "['.'] ['infections'] ['hospitals']\n",
      "['.'] ['performers'] ['stars']\n",
      "['.'] ['-'] ['lowest']\n",
      "['.'] ['have'] ['outcomes']\n",
      "['.'] ['va'] ['best']\n",
      "[[304, 7], [0, 0]]\n",
      "['.'] ['dangerous'] ['performance']\n",
      "['.'] ['top'] ['safety']\n",
      "['.'] ['measurement'] ['death']\n",
      "['.'] ['to'] ['heart']\n",
      "['.'] ['has'] ['from']\n",
      "['.'] ['in'] ['##ila']\n",
      "['.'] ['va'] ['sail']\n",
      "['.'] ['\"'] ['across']\n",
      "['.'] ['performers'] ['measures']\n",
      "['.'] ['va'] ['death']\n",
      "['.'] ['been'] ['avoid']\n",
      "['.'] ['va'] ['##ry']\n",
      "['.'] ['medical'] ['##tor']\n",
      "['.'] ['hospitals'] ['data']\n",
      "['...'] ['in'] ['such']\n",
      "['...'] ['##s'] ['from']\n",
      "['.'] ['used'] ['##able']\n",
      "['.'] ['reports'] ['associated']\n",
      "['.'] ['va'] ['wide']\n",
      "['.'] ['facilities'] ['cong']\n",
      "['.'] ['sail'] ['causes']\n",
      "['.'] ['offers'] ['infections']\n",
      "['.'] ['hospitals'] ['range']\n",
      "['.'] ['that'] ['##est']\n",
      "['.'] ['data'] ['like']\n",
      "['.'] ['often'] ['hospital']\n",
      "['.'] ['internal'] ['care']\n",
      "['.'] ['fail'] ['##ive']\n",
      "['.'] ['general'] ['deaths']\n",
      "[[333, 7], [0, 0]]\n",
      "['...'] ['measurement'] ['very']\n",
      "['...'] ['to'] ['whose']\n",
      "['...'] ['has'] ['agency']\n",
      "['...'] ['va'] ['va']\n",
      "['...'] ['va'] ['much']\n",
      "['...'] ['been'] ['gains']\n",
      "['...'] ['hospitals'] ['spokesman']\n",
      "['...'] ['in'] ['agency']\n",
      "['.'] ['improvement'] ['will']\n",
      "['.'] ['used'] ['more']\n",
      "['...'] ['and'] ['said']\n",
      "['...'] ['programs'] ['work']\n",
      "['...'] ['va'] ['increase']\n",
      "['...'] ['sail'] ['experience']\n",
      "['...'] ['high'] ['sail']\n",
      "['...'] ['data'] ['with']\n",
      "['...'] ['data'] ['development']\n",
      "['...'] ['independent'] ['still']\n",
      "[[350, 8], [0, 0]]\n",
      "['...'] ['top'] ['targets']\n",
      "['.'] ['measurement'] ['improvement']\n",
      "['.'] ['\"'] ['increasing']\n",
      "['...'] ['va'] ['tuesday']\n",
      "['...'] ['infections'] ['va']\n",
      "['...'] ['performers'] ['facilities']\n",
      "['.'] ['demonstrate'] ['degrees']\n",
      "['...'] ['hospitals'] ['morning']\n",
      "['...'] ['in'] ['##s']\n",
      "['...'] ['in'] ['that']\n",
      "['...'] ['used'] ['##ha']\n",
      "['...'] ['va'] ['veterans']\n",
      "['...'] ['va'] ['fail']\n",
      "['...'] ['performances'] ['those']\n",
      "['.'] ['the'] ['leadership']\n",
      "['.'] ['higher'] ['spokesman']\n",
      "['.'] ['and'] ['health']\n",
      "['.'] ['that'] ['hospitals']\n",
      "['...'] ['mortality'] ['said']\n",
      "['...'] ['were'] ['administration']\n",
      "['...'] ['internal'] ['demonstrate']\n",
      "['...'] ['general'] ['oversight']\n",
      "[[372, 8], [0, 0]]\n",
      "['.'] ['common'] ['specific']\n",
      "['.'] ['top'] ['subject']\n",
      "['\"'] ['va'] ['va']\n",
      "['...'] ['infections'] ['hospital']\n",
      "['.'] ['hospitals'] ['spokesman']\n",
      "['.'] ['in'] ['higher']\n",
      "['.'] ['have'] ['didn']\n",
      "['.'] ['va'] ['that']\n",
      "['.'] ['higher'] ['##t']\n",
      "['.'] ['hospitals'] ['might']\n",
      "[[381, 9], [0, 0]]\n",
      "['...'] ['common'] ['recent']\n",
      "['...'] ['top'] ['sail']\n",
      "['...'] ['measurement'] ['problems']\n",
      "['...'] ['to'] ['valued']\n",
      "['...'] ['va'] ['va']\n",
      "['...'] ['infections'] ['months']\n",
      "['...'] ['performers'] ['data']\n",
      "['...'] ['been'] ['health']\n",
      "['...'] ['hospitals'] ['##s']\n",
      "['...'] ['improvement'] ['information']\n",
      "['...'] ['used'] ['care']\n",
      "['...'] ['have'] ['inspector']\n",
      "['...'] ['va'] ['publicly']\n",
      "['...'] ['va'] ['point']\n",
      "['...'] ['facilities'] ['hospitals']\n",
      "['...'] ['sail'] ['problems']\n",
      "['...'] ['higher'] ['general']\n",
      "['...'] ['hospitals'] ['used']\n",
      "['...'] ['inspector'] ['become']\n",
      "['...'] ['internal'] ['significant']\n",
      "['...'] ['general'] ['when']\n",
      "[[401, 10], [0, 0]]\n",
      "['\"'] ['.'] ['va']\n",
      "['.'] ['common'] ['dublin']\n",
      "['.'] ['top'] ['referred']\n",
      "['.'] ['measurement'] ['office']\n",
      "['.'] ['va'] ['hospitals']\n",
      "['...'] ['infections'] ['ga']\n",
      "['.'] ['performers'] ['questions']\n",
      "['.'] ['-'] ['declined']\n",
      "['.'] ['have'] ['atlanta']\n",
      "['...'] ['higher'] ['houston']\n",
      "['...'] ['hospitals'] ['comment']\n",
      "['.'] ['##s'] ['national']\n",
      "['.'] ['internal'] ['va']\n",
      "[[414, 10], [0, 0]]\n",
      "['\"'] ['va'] ['va']\n",
      "['.'] ['hospitals'] ['spokesman']\n",
      "['.'] ['in'] ['care']\n",
      "['.'] ['often'] ['wouldn']\n",
      "['.'] ['higher'] ['##t']\n",
      "[[418, 11], [0, 0]]\n",
      "['...'] ['many'] ['care']\n",
      "['.'] ['to'] ['rate']\n",
      "['.'] ['hospitals'] ['hospitals']\n",
      "['.'] ['va'] ['other']\n",
      "['.'] ['va'] ['more']\n",
      "[\"'\"] ['been'] ['average']\n",
      "['.'] ['in'] ['atlanta']\n",
      "['.'] ['in'] ['star']\n",
      "['.'] ['-'] ['than']\n",
      "['.'] ['improvement'] ['central']\n",
      "['.'] ['va'] ['va']\n",
      "['.'] ['va'] ['hospital']\n",
      "['.'] ['facilities'] ['three']\n",
      "['.'] ['va'] ['iv']\n",
      "['.'] ['the'] ['five']\n",
      "['.'] ['hospitals'] ['medical']\n",
      "['.'] ['that'] ['times']\n",
      "['.'] ['inspector'] ['infections']\n",
      "['.'] ['data'] ['star']\n",
      "['...'] ['among'] ['center']\n",
      "[\"'\"] ['general'] ['than']\n",
      "[\"'\"] ['for'] ['va']\n",
      "[[438, 13], [0, 0]]\n",
      "['.'] ['.'] ['houston']\n",
      "['.'] ['and'] ['care']\n",
      "['.'] ['to'] ['star']\n",
      "['.'] ['va'] ['##s']\n",
      "['...'] ['performers'] ['nu']\n",
      "['.'] ['va'] ['mortality']\n",
      "['.'] ['demonstrate'] ['hospital']\n",
      "['.'] ['hospitals'] ['va']\n",
      "['.'] ['.'] ['star']\n",
      "['.'] ['in'] ['##m']\n",
      "['.'] ['-'] ['rate']\n",
      "['.'] ['improvement'] ['rate']\n",
      "['.'] ['\"'] ['hospital']\n",
      "['.'] ['\"'] ['hospital']\n",
      "['.'] ['programs'] ['than']\n",
      "['.'] ['higher'] ['ranked']\n",
      "['.'] ['##s'] ['higher']\n",
      "['.'] ['fail'] ['five']\n",
      "[[456, 13], [0, 0]]\n",
      "['...'] ['measurement'] ['than']\n",
      "['.'] ['to'] ['hospitals']\n",
      "['.'] ['va'] ['va']\n",
      "['.'] ['infections'] ['health']\n",
      "['.'] ['performers'] ['hospitals']\n",
      "['.'] ['demonstrate'] ['make']\n",
      "['...'] ['in'] ['care']\n",
      "['...'] ['in'] ['often']\n",
      "['...'] ['##s'] ['great']\n",
      "['...'] ['improvement'] ['public']\n",
      "['...'] ['have'] ['disclosed']\n",
      "['...'] ['va'] ['including']\n",
      "['...'] ['hospitals'] ['data']\n",
      "['...'] ['##s'] ['more']\n",
      "['...'] ['mortality'] ['variety']\n",
      "['...'] ['internal'] ['information']\n",
      "['...'] ['failure'] ['private']\n",
      "[[472, 14], [0, 0]]\n",
      "['.'] ['and'] ['that']\n",
      "['.'] ['top'] ['information']\n",
      "['.'] ['measurement'] ['things']\n",
      "['.'] ['to'] ['agency']\n",
      "['.'] ['patients'] ['allow']\n",
      "['.'] ['performers'] ['about']\n",
      "['.'] ['demonstrate'] ['goals']\n",
      "['.'] ['hospitals'] ['built']\n",
      "['.'] ['have'] ['several']\n",
      "['.'] ['va'] ['public']\n",
      "['.'] ['va'] ['rates']\n",
      "['etc'] ['higher'] ['internet']\n",
      "['.'] ['##s'] ['among']\n",
      "['.'] ['independent'] ['other']\n",
      "['.'] ['failure'] ['with']\n",
      "[[487, 14], [0, 0]]\n",
      "['.'] ['common'] ['va']\n",
      "['.'] ['top'] ['less']\n",
      "['.'] ['measurement'] ['sail']\n",
      "['.'] ['performers'] ['ability']\n",
      "['...'] ['hospitals'] ['database']\n",
      "['...'] ['in'] ['less']\n",
      "['...'] ['have'] ['published']\n",
      "['.'] ['##s'] ['hospitals']\n",
      "[']'] ['were'] ['offers']\n",
      "[']'] ['internal'] ['than']\n",
      "[[497, 14], [0, 0]]\n",
      "['.'] ['many'] ['##t']\n",
      "['.'] ['to'] ['##e']\n",
      "['.'] ['va'] ['example']\n",
      "['.'] ['infections'] ['appear']\n",
      "['.'] ['va'] ['website']\n",
      "['.'] ['demonstrate'] ['va']\n",
      "['.'] ['are'] ['phoenix']\n",
      "['.'] ['va'] ['va']\n",
      "['.'] ['facilities'] ['hospital']\n",
      "['.'] ['higher'] ['va']\n",
      "['.'] ['##s'] ['##s']\n",
      "['.'] ['that'] ['##com']\n",
      "['.'] ['often'] ['doesn']\n",
      "['.'] ['failure'] ['##par']\n",
      "[[509, 16], [0, 0]]\n",
      "['...'] ['common'] ['specific']\n",
      "['...'] ['top'] ['other']\n",
      "['...'] ['infections'] ['medical']\n",
      "['...'] ['performers'] ['hospitals']\n",
      "['.'] ['hospitals'] ['pennsylvania']\n",
      "['.'] ['in'] ['outcomes']\n",
      "['.'] ['va'] ['from']\n",
      "['.'] ['va'] ['decades']\n",
      "['...'] ['higher'] ['published']\n",
      "['...'] ['hospitals'] ['private']\n",
      "['...'] ['mortality'] ['hospital']\n",
      "[[520, 16], [0, 0]]\n",
      "['\"'] ['.'] ['they']\n",
      "['...'] ['measurement'] ['among']\n",
      "['...'] ['va'] ['showed']\n",
      "['...'] ['infections'] ['look']\n",
      "['...'] ['performers'] ['appears']\n",
      "['...'] ['hospitals'] ['great']\n",
      "['...'] ['va'] ['show']\n",
      "['...'] ['higher'] ['initially']\n",
      "['...'] ['hospitals'] ['current']\n",
      "['...'] ['##s'] ['less']\n",
      "[\"'\"] ['among'] ['data']\n",
      "[\"'\"] ['internal'] ['variability']\n",
      "[[532, 16], [0, 0]]\n",
      "['...'] ['top'] ['including']\n",
      "['.'] ['measurement'] ['##sse']\n",
      "['.'] ['va'] ['va']\n",
      "['.'] ['in'] ['edge']\n",
      "['...'] ['have'] ['long']\n",
      "['...'] ['va'] ['gathering']\n",
      "['.'] ['facilities'] ['data']\n",
      "['.'] ['higher'] ['been']\n",
      "['.'] ['hospitals'] ['medical']\n",
      "['.'] ['independent'] ['di']\n",
      "[[541, 17], [0, 0]]\n",
      "['...'] ['common'] ['improvement']\n",
      "['...'] ['measurement'] ['performance']\n",
      "['...'] ['infections'] ['program']\n",
      "['...'] ['performers'] ['##ly']\n",
      "['.'] ['in'] ['measured']\n",
      "['...'] ['have'] ['national']\n",
      "['...'] ['va'] ['recent']\n",
      "['...'] ['higher'] ['surgery']\n",
      "['...'] ['hospitals'] ['decades']\n",
      "['.'] ['among'] ['that']\n",
      "[[551, 17], [0, 0]]\n",
      "['.'] ['dangerous'] ['also']\n",
      "['...'] ['top'] ['beginning']\n",
      "['...'] ['measurement'] ['hospitals']\n",
      "['...'] ['to'] ['death']\n",
      "['.'] ['has'] ['rat']\n",
      "['...'] ['infections'] ['took']\n",
      "['...'] ['va'] ['medical']\n",
      "['...'] ['demonstrate'] ['rates']\n",
      "['.'] ['been'] ['##chet']\n",
      "['...'] ['hospitals'] ['nu']\n",
      "['...'] ['and'] ['com']\n",
      "['...'] ['improvement'] ['with']\n",
      "['...'] ['used'] ['##ing']\n",
      "['...'] ['have'] ['##m']\n",
      "['...'] ['va'] ['some']\n",
      "['...'] ['hospitals'] ['step']\n",
      "['...'] ['failure'] ['surgical']\n",
      "['...'] ['general'] ['toward']\n",
      "[[569, 17], [0, 0]]\n",
      "['.'] ['to'] ['said']\n",
      "['.'] ['performers'] ['internal']\n",
      "['.'] ['va'] ['data']\n",
      "['.'] ['demonstrate'] ['current']\n",
      "['...'] ['hospitals'] ['same']\n",
      "['...'] ['in'] ['outcomes']\n",
      "['...'] ['in'] ['battle']\n",
      "['...'] ['patients'] ['should']\n",
      "['.'] ['have'] ['time']\n",
      "['.'] ['va'] ['among']\n",
      "['.'] ['va'] ['over']\n",
      "['.'] ['va'] ['former']\n",
      "['...'] ['hospitals'] ['facilities']\n",
      "['...'] ['that'] ['made']\n",
      "['.'] ['inspector'] ['va']\n",
      "['...'] ['mortality'] ['wide']\n",
      "['...'] ['were'] ['sparked']\n",
      "['...'] ['internal'] ['much']\n",
      "['...'] ['fail'] ['public']\n",
      "['...'] ['general'] ['doctors']\n",
      "[[589, 17], [0, 0]]\n",
      "['.'] ['\"'] ['william']\n",
      "['...'] ['top'] ['nu']\n",
      "['...'] ['to'] ['more']\n",
      "['.'] ['infections'] ['medical']\n",
      "['.'] ['performers'] ['##m']\n",
      "['.'] ['va'] ['interview']\n",
      "['.'] ['demonstrate'] ['data']\n",
      "['.'] ['been'] ['impact']\n",
      "['...'] ['hospitals'] ['duncan']\n",
      "['...'] ['in'] ['outcomes']\n",
      "['.'] ['and'] ['that']\n",
      "['...'] ['va'] ['until']\n",
      "['.'] ['va'] ['posted']\n",
      "['.'] ['##s'] ['said']\n",
      "['.'] ['that'] ['urged']\n",
      "['.'] ['failure'] ['that']\n",
      "[[605, 17], [0, 0]]\n",
      "['...'] ['top'] ['that']\n",
      "['...'] ['measurement'] ['stay']\n",
      "['.'] ['to'] ['va']\n",
      "['.'] ['infections'] ['health']\n",
      "['...'] ['va'] ['private']\n",
      "['.'] ['demonstrate'] ['doctors']\n",
      "['...'] ['in'] ['robert']\n",
      "['...'] ['in'] ['more']\n",
      "['.'] ['have'] ['va']\n",
      "['...'] ['higher'] ['under']\n",
      "['...'] ['##s'] ['outcomes']\n",
      "['...'] ['that'] ['va']\n",
      "['.'] ['mortality'] ['secretary']\n",
      "['.'] ['internal'] ['should']\n",
      "['.'] ['failure'] ['senior']\n",
      "[[620, 17], [0, 0]]\n",
      "['.'] ['\"'] ['efforts']\n",
      "['.'] ['top'] ['recently']\n",
      "['.'] ['performers'] ['weren']\n",
      "['.'] ['hospitals'] ['reach']\n",
      "['.'] ['in'] ['forced']\n",
      "['.'] ['in'] ['##t']\n",
      "['.'] ['va'] ['successful']\n",
      "['.'] ['were'] ['office']\n",
      "[[628, 17], [0, 0]]\n",
      "['.'] ['common'] ['forced']\n",
      "['.'] ['performers'] ['nu']\n",
      "['.'] ['in'] ['##m']\n",
      "['.'] ['higher'] ['duncan']\n",
      "['.'] ['hospitals'] ['agency']\n",
      "['.'] ['independent'] ['said']\n",
      "[[634, 17], [0, 0]]\n",
      "['.'] ['common'] ['questions']\n",
      "['.'] ['va'] ['va']\n",
      "['...'] ['infections'] ['about']\n",
      "['.'] ['hospitals'] ['spokesman']\n",
      "['.'] ['are'] ['didn']\n",
      "['.'] ['va'] ['duncan']\n",
      "['.'] ['higher'] ['##t']\n",
      "['.'] ['hospitals'] ['##s']\n",
      "['.'] ['mortality'] ['answer']\n",
      "[[642, 18], [0, 0]]\n",
      "['...'] ['top'] ['va']\n",
      "['...'] ['measurement'] ['outcomes']\n",
      "['...'] ['has'] ['hospitals']\n",
      "['...'] ['va'] ['duncan']\n",
      "['...'] ['performers'] ['system']\n",
      "['...'] ['data'] ['designed']\n",
      "['.'] ['improvement'] ['goal']\n",
      "['...'] ['have'] ['living']\n",
      "['...'] ['va'] ['washington']\n",
      "['...'] ['va'] ['measuring']\n",
      "['...'] ['facilities'] ['with']\n",
      "['...'] ['the'] ['average']\n",
      "['...'] ['hospitals'] ['said']\n",
      "['...'] ['data'] ['performers']\n",
      "['...'] ['have'] ['##y']\n",
      "[[657, 18], [0, 0]]\n",
      "['.'] ['va'] ['goal']\n",
      "['.'] ['va'] ['nu']\n",
      "['.'] ['hospitals'] ['##m']\n",
      "[[660, 18], [0, 0]]\n",
      "['...'] ['top'] ['have']\n",
      "['...'] ['measurement'] ['they']\n",
      "['...'] ['to'] ['tell']\n",
      "['...'] ['infections'] ['about']\n",
      "['...'] ['performers'] ['little']\n",
      "['...'] ['va'] ['rely']\n",
      "['...'] ['demonstrate'] ['them']\n",
      "['...'] ['hospitals'] ['upset']\n",
      "['...'] ['in'] ['rec']\n",
      "['...'] ['va'] ['va']\n",
      "['...'] ['##s'] ['##e']\n",
      "['...'] ['that'] ['staff']\n",
      "['...'] ['mortality'] ['recent']\n",
      "['...'] ['were'] ['patients']\n",
      "['.'] ['general'] ['said']\n",
      "[[674, 19], [0, 0]]\n",
      "['.'] ['top'] ['care']\n",
      "['.'] ['hospitals'] ['##t']\n",
      "['.'] ['va'] ['just']\n",
      "['so'] ['higher'] ['that']\n",
      "['so'] [')'] ['access']\n",
      "['\"'] ['mortality'] ['medical']\n",
      "[[680, 19], [0, 0]]\n",
      "['.'] ['dangerous'] ['from']\n",
      "['.'] ['top'] ['within']\n",
      "['.'] ['infections'] ['phoenix']\n",
      "['.'] ['phoenix'] ['this']\n",
      "['.'] ['in'] ['department']\n",
      "['.'] ['often'] ['relatively']\n",
      "['.'] ['reduced'] ['poor']\n",
      "['.'] ['##s'] ['said']\n",
      "['.'] ['often'] ['results']\n",
      "['.'] ['among'] ['secret']\n",
      "[[690, 19], [0, 0]]\n",
      "['.'] ['have'] ['their']\n",
      "['.'] ['mortality'] ['data']\n",
      "[[692, 19], [0, 0]]\n",
      "0.026722925457102673\n",
      "Elapsed Time: 29.72987651824951 seconds\n",
      "Summary 7 of batch\n",
      "['...'] ['of'] ['##r']\n",
      "['...'] ['shrink'] ['march']\n",
      "['took'] ['took'] ['bank']\n",
      "['...'] ['to'] ['recent']\n",
      "['...'] ['rate'] ['government']\n",
      "['...'] ['consistently'] ['friday']\n",
      "['\"'] ['banks'] ['interest']\n",
      "['in'] ['in'] ['dismissed']\n",
      "['reserve'] ['\"'] ['monetary']\n",
      "['...'] ['increase'] ['sell']\n",
      "['...'] ['increase'] ['bonds']\n",
      "['\"'] ['\"'] ['rate']\n",
      "['\"'] ['\"'] ['concerns']\n",
      "['blow'] ['blow'] ['moving']\n",
      "['chair'] ['chair'] ['policy']\n",
      "['...'] ['rates'] ['##off']\n",
      "['...'] ['justified'] ['took']\n",
      "['...'] ['economic'] ['federal']\n",
      "['...'] ['when'] ['##en']\n",
      "['the'] ['the'] ['increase']\n",
      "['s'] ['s'] ['that']\n",
      "['...'] ['data'] ['reserve']\n",
      "['...'] ['fed'] ['suggested']\n",
      "['market'] ['sell'] ['likely']\n",
      "['bonds'] ['bonds'] ['central']\n",
      "[[25, 0], [0, 0]]\n",
      "['.'] ['of'] ['move']\n",
      "['...'] ['don'] ['given']\n",
      "['...'] ['to'] ['prepared']\n",
      "['.'] ['take'] ['remarks']\n",
      "['.'] ['solid'] ['march']\n",
      "['.'] ['know'] ['improving']\n",
      "['...'] ['date'] ['##en']\n",
      "['...'] ['how'] ['economy']\n",
      "['.'] ['by'] ['said']\n",
      "['.'] ['data'] ['likely']\n",
      "['...'] ['will'] ['rising']\n",
      "[[36, 0], [0, 0]]\n",
      "['...'] ['don'] ['annual']\n",
      "['...'] ['shrink'] ['from']\n",
      "['...'] ['rate'] ['still']\n",
      "['...'] ['proven'] ['##s']\n",
      "['...'] ['##t'] ['target']\n",
      "['...'] ['bonds'] ['higher']\n",
      "['...'] ['change'] ['also']\n",
      "['...'] ['increase'] ['running']\n",
      "['...'] ['know'] ['despite']\n",
      "['\"'] ['.'] ['energy']\n",
      "['...'] ['economic'] ['nu']\n",
      "['\"'] ['but'] ['prices']\n",
      "['...'] ['in'] ['that']\n",
      "['...'] ['by'] ['below']\n",
      "['...'] ['data'] ['##m']\n",
      "['...'] ['fed'] ['temporary']\n",
      "['...'] ['will'] ['boost']\n",
      "[[53, 0], [0, 0]]\n",
      "['...'] ['of'] ['bond']\n",
      "['...'] ['shrink'] ['moments']\n",
      "['##d'] ['##d'] ['went']\n",
      "['...'] ['to'] ['nu']\n",
      "['...'] ['rate'] ['similarly']\n",
      "['...'] ['data'] ['market']\n",
      "['...'] ['##t'] ['losses']\n",
      "['.'] ['up'] ['after']\n",
      "['message'] ['message'] ['public']\n",
      "['...'] ['solid'] ['which']\n",
      "['...'] ['know'] ['suffered']\n",
      "['...'] ['rates'] ['##d']\n",
      "['...'] ['justified'] ['reaction']\n",
      "['...'] ['economic'] ['quickly']\n",
      "['...'] ['in'] ['message']\n",
      "['...'] ['by'] ['from']\n",
      "['...'] ['data'] ['rec']\n",
      "['\"'] ['nu'] ['##ens']\n",
      "['...'] ['will'] ['initial']\n",
      "['##ance'] ['##ance'] ['remarks']\n",
      "[[73, 0], [0, 0]]\n",
      "['.'] ['don'] ['##m']\n",
      "['.'] ['shrink'] ['##m']\n",
      "['the'] ['the'] ['thursday']\n",
      "['nu'] ['nu'] ['nu']\n",
      "['-'] ['>'] ['direction']\n",
      "['.'] ['to'] ['yield']\n",
      "['.'] ['rate'] ['year']\n",
      "['.'] ['proven'] ['nu']\n",
      "['new'] ['bench'] ['while']\n",
      "['settled'] ['\"'] ['nu']\n",
      "['<'] ['<'] ['nu']\n",
      "['##m'] ['##m'] ['##m']\n",
      "['.'] ['increase'] ['treasury']\n",
      "['.'] ['solid'] ['##m']\n",
      "['.'] ['know'] ['compared']\n",
      "['at'] ['at'] ['##m']\n",
      "['nu'] ['nu'] ['##m']\n",
      "['the'] ['the'] ['move']\n",
      "['note'] ['note'] ['bond']\n",
      "['.'] ['when'] ['with']\n",
      "['the'] ['the'] ['nu']\n",
      "['two'] ['two'] ['yield']\n",
      "['##m'] ['##m'] ['nu']\n",
      "['settled'] ['moved'] ['prices']\n",
      "['.'] ['in'] ['bench']\n",
      "['.'] ['by'] ['settled']\n",
      "['yield'] ['yield'] ['##m']\n",
      "['nu'] ['nu'] ['year']\n",
      "['>'] ['>'] ['##m']\n",
      "['>'] ['>'] ['from']\n",
      "['while'] ['while'] ['nu']\n",
      "['.'] ['investors'] ['nu']\n",
      "['.'] ['will'] ['nu']\n",
      "['the'] ['the'] ['##m']\n",
      "[[105, 0], [0, 2]]\n",
      "['\"'] ['\"'] ['after']\n",
      "['...'] ['of'] ['investors']\n",
      "['...'] ['don'] ['week']\n",
      "['and'] ['\"'] ['take']\n",
      "['...'] ['to'] ['months']\n",
      "['...'] ['up'] ['officials']\n",
      "['##ing'] ['##s'] ['action']\n",
      "['...'] ['solid'] ['changed']\n",
      "['...'] ['justified'] ['march']\n",
      "['...'] ['economic'] ['their']\n",
      "['after'] ['after'] ['appeared']\n",
      "['...'] ['in'] ['##ing']\n",
      "['...'] ['by'] ['rate']\n",
      "['...'] ['fed'] ['series']\n",
      "['months'] ['years'] ['ready']\n",
      "['...'] ['run'] ['increase']\n",
      "['...'] ['investors'] ['this']\n",
      "[[122, 0], [0, 2]]\n",
      "['.'] ['\"'] ['federal']\n",
      "['.'] ['of'] ['policy']\n",
      "['.'] ['don'] ['interest']\n",
      "['.'] ['rate'] ['place']\n",
      "['.'] ['##t'] ['rate']\n",
      "['.'] ['loans'] ['nu']\n",
      "['by'] ['by'] ['nu']\n",
      "['national'] ['banks'] ['nu']\n",
      "['month'] ['month'] ['##e']\n",
      "['.'] ['increase'] ['futures']\n",
      "['.'] ['know'] ['increase']\n",
      "['.'] ['the'] ['##m']\n",
      "['investors'] ['investors'] ['##m']\n",
      "['bank'] ['bank'] ['##m']\n",
      "['an'] ['an'] ['last']\n",
      "['at'] ['at'] ['group']\n",
      "['.'] ['rates'] ['used']\n",
      "['.'] ['when'] ['this']\n",
      "['interest'] ['interest'] ['week']\n",
      "['.'] ['by'] ['central']\n",
      "['.'] ['fed'] ['month']\n",
      "['take'] ['be'] ['thursday']\n",
      "['rate'] ['rate'] ['according']\n",
      "['.'] ['may'] ['investors']\n",
      "['.'] ['run'] ['bank']\n",
      "['and'] ['banks'] ['from']\n",
      "[[148, 0], [0, 2]]\n",
      "['.'] ['fed'] ['increase']\n",
      "['.'] ['of'] ['short']\n",
      "['an'] ['an'] ['seven']\n",
      "['.'] ['proven'] ['term']\n",
      "['.'] ['bonds'] ['highest']\n",
      "['imminent'] ['imminent'] ['years']\n",
      "['.'] ['increase'] ['taken']\n",
      "['.'] ['solid'] ['bonds']\n",
      "['.'] ['.'] ['levels']\n",
      "['...'] ['how'] ['year']\n",
      "['.'] ['in'] ['imminent']\n",
      "['.'] ['by'] ['toll']\n",
      "['prospect'] ['prospect'] ['more']\n",
      "['...'] ['may'] ['rate']\n",
      "['...'] ['investors'] ['yield']\n",
      "['of'] ['of'] ['than']\n",
      "[[164, 0], [0, 2]]\n",
      "['.'] ['fed'] ['also']\n",
      "['.'] ['of'] ['levels']\n",
      "['.'] ['don'] ['nu']\n",
      "['term'] ['term'] ['##m']\n",
      "['.'] ['consistently'] ['from']\n",
      "['.'] ['##t'] ['##m']\n",
      "['.'] ['bonds'] ['nu']\n",
      "['.'] ['take'] ['longer']\n",
      "['.'] ['solid'] ['december']\n",
      "['the'] ['.'] ['##m']\n",
      "['.'] ['rates'] ['term']\n",
      "['.'] ['supported'] ['remain']\n",
      "['.'] ['economic'] ['when']\n",
      "['.'] ['when'] ['year']\n",
      "['.'] ['in'] ['bonds']\n",
      "['.'] ['by'] ['below']\n",
      "['.'] ['fed'] ['yield']\n",
      "['.'] ['may'] ['have']\n",
      "['.'] ['run'] ['their']\n",
      "['.'] ['will'] ['reached']\n",
      "['longer'] ['longer'] ['nu']\n",
      "[[185, 0], [0, 2]]\n",
      "['...'] ['.'] ['##e']\n",
      "['...'] ['don'] ['pressure']\n",
      "['in'] ['in'] ['stone']\n",
      "['['] ['consistently'] ['rate']\n",
      "['.'] ['prefer'] ['unusual']\n",
      "['.'] ['solid'] ['hike']\n",
      "['...'] ['know'] ['going']\n",
      "['that'] ['.'] ['short']\n",
      "['your'] ['you'] ['##n']\n",
      "['the'] ['the'] ['jersey']\n",
      "['.'] ['rates'] ['that']\n",
      "['...'] ['economic'] ['##s']\n",
      "['is'] ['##e'] ['market']\n",
      "['a'] ['a'] ['research']\n",
      "['...'] ['by'] ['more']\n",
      "['...'] ['data'] ['that']\n",
      "['not'] ['not'] ['said']\n",
      "['and'] ['\"'] ['analyst']\n",
      "['.'] ['may'] ['your']\n",
      "['...'] ['will'] ['largely']\n",
      "['so'] ['unusual'] ['john']\n",
      "[[206, 0], [0, 2]]\n",
      "['.'] ['don'] ['could']\n",
      "['.'] ['shrink'] ['that']\n",
      "['many'] ['long'] ['added']\n",
      "['...'] ['##t'] ['also']\n",
      "['bonds'] ['debt'] ['able']\n",
      "['...'] ['prefer'] ['short']\n",
      "['.'] ['some'] ['more']\n",
      "['.'] ['rates'] ['term']\n",
      "['.'] ['justified'] ['longer']\n",
      "['.'] ['economic'] ['long']\n",
      "['.'] ['when'] ['confidence']\n",
      "['or'] ['sellers'] ['active']\n",
      "['be'] ['be'] ['control']\n",
      "['.'] ['in'] ['bonds']\n",
      "['.'] ['by'] ['term']\n",
      "['.'] ['data'] ['term']\n",
      "['.'] ['fed'] ['among']\n",
      "['...'] ['run'] ['bonds']\n",
      "['.'] ['will'] ['investors']\n",
      "['short'] ['short'] ['will']\n",
      "[[226, 0], [0, 2]]\n",
      "['.'] ['or'] ['several']\n",
      "['.'] ['change'] ['##en']\n",
      "['...'] ['increase'] ['officials']\n",
      "['.'] ['by'] ['spoke']\n",
      "['.'] ['use'] ['friday']\n",
      "[[231, 0], [0, 2]]\n",
      "['.'] ['fed'] ['bank']\n",
      "['.'] ['of'] ['bull']\n",
      "['.'] ['don'] ['journal']\n",
      "['.'] ['shrink'] ['would']\n",
      "['.'] ['to'] ['from']\n",
      "['.'] ['consistently'] ['##ard']\n",
      "['.'] ['bonds'] ['prefer']\n",
      "['bank'] ['federal'] ['rather']\n",
      "['.'] ['solid'] ['told']\n",
      "['reserve'] ['reserve'] ['than']\n",
      "['.'] ['when'] ['interview']\n",
      "['departing'] ['independent'] ['raise']\n",
      "['bank'] ['bank'] ['march']\n",
      "['.'] ['in'] ['federal']\n",
      "['.'] ['by'] ['president']\n",
      "['.'] ['data'] ['wall']\n",
      "['.'] ['he'] ['that']\n",
      "['from'] ['from'] ['rates']\n",
      "['.'] ['may'] ['reserve']\n",
      "['.'] ['run'] ['james']\n",
      "['.'] ['investors'] ['street']\n",
      "[[252, 0], [0, 2]]\n",
      "['...'] ['don'] ['##t']\n",
      "['.'] ['to'] ['economy']\n",
      "['.'] ['rate'] ['similar']\n",
      "['.'] ['consistently'] ['january']\n",
      "['.'] ['##t'] ['raise']\n",
      "['...'] ['increase'] ['position']\n",
      "['...'] ['solid'] ['when']\n",
      "['...'] ['know'] ['rates']\n",
      "['...'] ['rates'] ['said']\n",
      "['...'] ['investors'] ['didn']\n",
      "[[262, 0], [0, 2]]\n",
      "['...'] ['don'] ['rate']\n",
      "['...'] ['to'] ['federal']\n",
      "['.'] ['\"'] ['conference']\n",
      "['...'] ['##t'] ['increase']\n",
      "['...'] ['prefer'] ['reserve']\n",
      "['\"'] ['.'] ['consistently']\n",
      "['...'] ['rates'] ['vice']\n",
      "['...'] ['justified'] ['different']\n",
      "['...'] ['when'] ['justified']\n",
      "['\"'] ['\"'] ['solid']\n",
      "['...'] ['in'] ['chairman']\n",
      "['...'] ['a'] ['message']\n",
      "['...'] ['data'] ['saying']\n",
      "['federal'] ['\"'] ['economic']\n",
      "['reserve'] ['reserve'] ['data']\n",
      "[[277, 0], [0, 2]]\n",
      "['.'] ['fed'] ['hangs']\n",
      "['.'] ['rate'] ['over']\n",
      "['.'] ['take'] ['amount']\n",
      "['.'] ['justified'] ['bond']\n",
      "['.'] ['in'] ['uncertainty']\n",
      "['.'] ['by'] ['market']\n",
      "['.'] ['may'] ['still']\n",
      "[[284, 0], [0, 2]]\n",
      "['.'] ['.'] ['investors']\n",
      "['...'] ['or'] ['central']\n",
      "['...'] ['don'] ['balance']\n",
      "['know'] ['know'] ['said']\n",
      "['...'] ['to'] ['don']\n",
      "['...'] ['rate'] ['bank']\n",
      "['to'] ['to'] ['global']\n",
      "['...'] ['take'] ['##t']\n",
      "['...'] ['increase'] ['will']\n",
      "['...'] ['\"'] ['might']\n",
      "['the'] ['the'] ['##ya']\n",
      "['or'] ['shrink'] ['rates']\n",
      "['.'] ['rates'] ['know']\n",
      "['.'] ['justified'] ['begin']\n",
      "['.'] ['economic'] ['bonds']\n",
      "['.'] ['how'] ['what']\n",
      "['banks'] ['banks'] ['york']\n",
      "['.'] ['in'] ['when']\n",
      "['...'] ['fed'] ['kind']\n",
      "['don'] ['don'] ['from']\n",
      "['bank'] ['bank'] ['##ra']\n",
      "['.'] ['use'] ['shrink']\n",
      "['##t'] ['##t'] ['congress']\n",
      "['will'] ['will'] ['head']\n",
      "[[308, 0], [0, 2]]\n",
      "['.'] ['fed'] ['really']\n",
      "['.'] ['of'] ['hike']\n",
      "['.'] ['to'] ['me']\n",
      "['.'] ['data'] ['##d']\n",
      "['.'] ['##t'] ['more']\n",
      "['.'] ['bonds'] ['said']\n",
      "['...'] ['take'] ['longer']\n",
      "['...'] ['increase'] ['about']\n",
      "['...'] ['know'] ['about']\n",
      "['.'] ['rates'] ['term']\n",
      "['.'] ['up'] ['whether']\n",
      "['...'] ['economic'] ['march']\n",
      "['...'] ['when'] ['those']\n",
      "['.'] ['in'] ['rates']\n",
      "['...'] ['bank'] ['other']\n",
      "['...'] ['investors'] ['june']\n",
      "[[324, 0], [0, 2]]\n",
      "[')'] ['\"'] ['write']\n",
      "['.'] ['of'] ['##s']\n",
      "['.'] ['consistently'] ['##j']\n",
      "['.'] ['increase'] ['gold']\n",
      "['.'] ['solid'] ['com']\n",
      "['.'] ['rates'] ['gold']\n",
      "['.'] ['justified'] ['##far']\n",
      "['.'] ['in'] ['##far']\n",
      "['.'] ['by'] ['##b']\n",
      "['.'] ['may'] ['##b']\n",
      "['.'] ['base'] ['w']\n",
      "[[335, 0], [0, 2]]\n",
      "0.0\n",
      "Elapsed Time: 12.002695798873901 seconds\n",
      "Summary 8 of batch\n",
      "['.'] ['but'] ['nu']\n",
      "['.'] ['phone'] ['september']\n",
      "['.'] ['facebook'] ['##m']\n",
      "['nu'] ['nu'] ['phenomenon']\n",
      "['>'] ['>'] ['politics']\n",
      "['.'] ['change'] ['eddie']\n",
      "['.'] ['is'] ['##m']\n",
      "['.'] ['twitter'] ['est']\n",
      "['.'] ['ipad'] ['nu']\n",
      "['\"'] ['\"'] ['september']\n",
      "['>'] ['>'] ['everything']\n",
      "['.'] ['twitter'] ['nu']\n",
      "['.'] ['apps'] ['##m']\n",
      "['.'] ['written'] ['est']\n",
      "['##m'] ['##m'] ['been']\n",
      "['>'] ['>'] ['ever']\n",
      "['updated'] ['published'] ['from']\n",
      "['nu'] ['nu'] ['international']\n",
      "['.'] ['with'] ['##n']\n",
      "['.'] ['facebook'] ['nu']\n",
      "['.'] ['##s'] ['##m']\n",
      "['nu'] ['nu'] ['nu']\n",
      "['<'] ['<'] ['celebrity']\n",
      "['##m'] ['##m'] ['relations']\n",
      "['.'] ['cover'] ['published']\n",
      "['.'] ['link'] ['nu']\n",
      "['.'] ['ipad'] ['##m']\n",
      "['\"'] ['\"'] ['nu']\n",
      "['##m'] ['##m'] ['##m']\n",
      "['nu'] ['nu'] ['culture']\n",
      "['.'] ['to'] ['##m']\n",
      "['.'] ['new'] ['nu']\n",
      "['wren'] ['wren'] ['##m']\n",
      "['<'] ['<'] ['biggest']\n",
      "['nu'] ['nu'] ['internet']\n",
      "[[33, 0], [0, 2]]\n",
      "['.'] ['but'] ['little']\n",
      "['...'] ['phone'] ['gets']\n",
      "['...'] ['app'] ['feature']\n",
      "['...'] ['is'] ['since']\n",
      "['...'] ['apps'] ['when']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#torch.set_printoptions(profile=\"full\")\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m---> 69\u001b[0m     text_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mblanc_help_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 58\u001b[0m, in \u001b[0;36mblanc_help_batch\u001b[1;34m(batch, model, p_mask, N, epochs)\u001b[0m\n\u001b[0;32m     56\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     57\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 58\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mBLANC_help\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n\u001b[0;32m     60\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[10], line 28\u001b[0m, in \u001b[0;36mBLANC_help\u001b[1;34m(sentences, model, model_tuned, summary, M, p_mask, is_blanc_tune)\u001b[0m\n\u001b[0;32m     26\u001b[0m     label_base \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((filler, sentence))\n\u001b[0;32m     27\u001b[0m     label_help \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((summary, sentence))\n\u001b[1;32m---> 28\u001b[0m     out_base \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     29\u001b[0m     out_help \u001b[38;5;241m=\u001b[39m model(input_help\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), attention_mask \u001b[38;5;241m=\u001b[39m (input_help\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1360\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;124;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;124;03m    config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m \u001b[38;5;124;03m    loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1360\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1375\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:355\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    352\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\torch\\nn\\functional.py:1826\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1822\u001b[0m         ret \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[1;32m-> 1826\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, dim: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _stacklevel: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, dtype: Optional[DType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a softmax function.\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m \n\u001b[0;32m   1829\u001b[0m \u001b[38;5;124;03m    Softmax is defined as:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1849\u001b[0m \n\u001b[0;32m   1850\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def BLANC_help(sentences, model, model_tuned, summary = None, M = 6, p_mask = 0.15, is_blanc_tune = False):\n",
    "    S = [[0, 0], [0, 0]]\n",
    "    if is_blanc_tune:\n",
    "        M = int(1/p_mask)\n",
    "    else:\n",
    "        filler = torch.tensor([tokenizer.convert_tokens_to_ids('.')]*summary.size(dim=0)).long()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for i in range(M):\n",
    "            masked_sentence, masked_tokens_ids = mask_sentence(sentence, i, M, word_lengths)\n",
    "            masked_sentence = torch.tensor(masked_sentence).long()\n",
    "\n",
    "\n",
    "            if not is_blanc_tune:\n",
    "\n",
    "                input_help = torch.cat((summary, torch.zeros(1), masked_sentence))\n",
    "                input_base = torch.cat((filler, torch.zeros(1), masked_sentence))\n",
    "                padding = torch.zeros(512-input_help.size(0))\n",
    "\n",
    "                input_help = torch.cat((input_help, padding)).long()\n",
    "                input_base = torch.cat((input_base, padding)).long()\n",
    "\n",
    "                #print(tokenizer.convert_ids_to_tokens(input_help))\n",
    "\n",
    "\n",
    "                label_base = torch.cat((filler, sentence))\n",
    "                label_help = torch.cat((summary, sentence))\n",
    "                out_base = model(input_base.view(1, -1).to(device), attention_mask = (input_base.view(1, -1) != 0).to(device)).logits\n",
    "                out_help = model(input_help.view(1, -1).to(device), attention_mask = (input_help.view(1, -1) != 0).to(device)).logits\n",
    "            else:\n",
    "                out_base = model(masked_sentence, labels = sentence).logits\n",
    "                out_help = model_tuned(masked_sentence, labels = sentence).logits\n",
    "\n",
    "\n",
    "            for j in masked_tokens_ids:\n",
    "                predicted_token_model = torch.argmax(out_base[0, j])\n",
    "                predicted_token_model_tuned = torch.argmax(out_help[0, j])\n",
    "                print(tokenizer.convert_ids_to_tokens(predicted_token_model.view(1, -1)),\n",
    "                       tokenizer.convert_ids_to_tokens(predicted_token_model_tuned.view(1, -1)),\n",
    "                         tokenizer.convert_ids_to_tokens(sentence[j].view(1, -1)))\n",
    "                k = int(predicted_token_model == sentence[j])\n",
    "                m = int(predicted_token_model_tuned == sentence[j])\n",
    "                S[k][m] += 1\n",
    "        print(S)\n",
    "    B = (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
    "    \n",
    "    return B\n",
    "\n",
    "def blanc_help_batch(batch, model, p_mask = 0.15, N = 10, epochs = 10):\n",
    "    batch_tuned_models = []\n",
    "    batch_accuracies = []\n",
    "    \n",
    "    i = 0\n",
    "    for summary, text, sentences in zip(batch['summary_ids'], batch['text_ids'], batch['sentences_ids']):\n",
    "        print(f\"Summary {i} of batch\")\n",
    "        i += 1\n",
    "        start_time = time.time()\n",
    "        accuracy = BLANC_help(sentences, model, None, summary)\n",
    "        print(accuracy)\n",
    "        end_time = time.time()\n",
    "        batch_accuracies.append(accuracy)\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "    return batch_tuned_models, batch_accuracies\n",
    "\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "for batch in dataloader:\n",
    "    text_accuracies = blanc_help_batch(batch, model, epochs = epochs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b978b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 0 of batch\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "0 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_tuned_models, batch_accuracies\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m---> 43\u001b[0m     models_tuned, text_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mblanc_tune_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 31\u001b[0m, in \u001b[0;36mblanc_tune_batch\u001b[1;34m(batch, model, p_mask, N, epochs)\u001b[0m\n\u001b[0;32m     29\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     30\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 31\u001b[0m model_tuned \u001b[38;5;241m=\u001b[39m \u001b[43mblanc_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m batch_tuned_models\u001b[38;5;241m.\u001b[39mappend(model_tuned)\n\u001b[0;32m     33\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m BLANC_help(sentences, model, model_tuned, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0.15\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36mblanc_tune\u001b[1;34m(summary, text, model, p_mask, N, epochs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mblanc_tune\u001b[39m(summary, text, model, p_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.15\u001b[39m, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     N_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(summary[:\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m])\n\u001b[0;32m      3\u001b[0m     N_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(N_summary\u001b[38;5;241m*\u001b[39mp_mask)\n\u001b[0;32m      4\u001b[0m     set_tune \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: 0 is not in list"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def blanc_tune(summary, text, model, p_mask = 0.15, N = 10, epochs = 10):\n",
    "    N_summary = len(summary[:summary.tolist().index(0)])\n",
    "    N_mask = int(N_summary*p_mask)\n",
    "    set_tune = pd.DataFrame(columns = ['summary', 'text'])\n",
    "\n",
    "    for j in range(0, N):\n",
    "        pos = [i for i, token in enumerate(summary.tolist()) if token in word_lengths and word_lengths[token]]\n",
    "        random.shuffle(pos)\n",
    "        # print(len(pos), pos)\n",
    "        # print(N_mask)\n",
    "        while len(pos) != 0:\n",
    "            masked_summary = summary.tolist().copy()\n",
    "            for pos_to_mask in pos[:N_mask]:\n",
    "                masked_summary[pos_to_mask] = '[MASK]'\n",
    "                set_tune.loc[set_tune.shape[0]] = [masked_summary, text]\n",
    "            pos = pos[N_mask:]\n",
    "\n",
    "    model_tuned = training(summary, text, model, epochs)\n",
    "    print('\\n')      \n",
    "    return model_tuned\n",
    "\n",
    "def blanc_tune_batch(batch, model, p_mask = 0.15, N = 10, epochs = 10):\n",
    "    batch_tuned_models = []\n",
    "    batch_accuracies = []\n",
    "    \n",
    "    i = 0\n",
    "    for summary, text, sentences in zip(batch['summary_ids'], batch['text_ids'], batch['sentences_ids']):\n",
    "        print(f\"Summary {i} of batch\")\n",
    "        i += 1\n",
    "        start_time = time.time()\n",
    "        model_tuned = blanc_tune(summary, text, model, p_mask, N, epochs)\n",
    "        batch_tuned_models.append(model_tuned)\n",
    "        accuracy = BLANC_help(sentences, model, model_tuned, None, None, 0.15, True)\n",
    "        print(accuracy)\n",
    "        end_time = time.time()\n",
    "        batch_accuracies.append(accuracy)\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "    return batch_tuned_models, batch_accuracies\n",
    "\n",
    "for batch in dataloader:\n",
    "    models_tuned, text_accuracies = blanc_tune_batch(batch, model, epochs = epochs)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "collabfiltering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
