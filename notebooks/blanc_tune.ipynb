{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d9f8b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b872e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('../datasets/DailyNews_300.json')\n",
    "print(data.shape)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397b468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.features = self.dataset.columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.dataset.iloc[idx, 0], self.dataset.iloc[idx, 1], self.dataset.iloc[idx, 2])\n",
    "    \n",
    "    def map(self, preprocessing_fn, **kwargs):\n",
    "        return CustomDataset(self.dataset.apply(lambda x: preprocessing_fn(x, **kwargs), axis = 1))\n",
    "    \n",
    "    def select_columns(self, columns):\n",
    "        new_dataset = self.dataset[columns] \n",
    "        return CustomDataset(new_dataset)\n",
    "    \n",
    "    def get_sentences(self):\n",
    "        self.dataset['sentences'] = self.dataset['text'].apply(lambda x: x.split('.'))\n",
    "        return CustomDataset(self.dataset)\n",
    "    \n",
    "dataset = CustomDataset(data)\n",
    "dataset = dataset.get_sentences()\n",
    "# print(dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c34df281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_lengths(dataset, tokenizer):\n",
    "    word_lengths = {}\n",
    "    all_tokens = []\n",
    "\n",
    "    for sample in dataset:\n",
    "        summary = sample[0]\n",
    "        preprocessed_result = tokenizer(summary, \n",
    "                                        add_special_tokens = False,\n",
    "                                        truncation = True,\n",
    "                                        max_length = 512,\n",
    "                                        padding = False,\n",
    "                                        return_attention_mask = False)\n",
    "        tokens = preprocessed_result[\"input_ids\"]\n",
    "        decoded_tokens = tokenizer.convert_ids_to_tokens(tokens)\n",
    "        for token in tokens:\n",
    "            if token not in all_tokens:\n",
    "                all_tokens.append(token)\n",
    "\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            if decoded_tokens[i].startswith('##'):\n",
    "                combined_word = decoded_tokens[i - 1] + decoded_tokens[i][2:]\n",
    "                word_lengths[tokens[i - 1]] = len(combined_word)\n",
    "                word_lengths[tokens[i]] = len(combined_word)\n",
    "            else:\n",
    "                word_lengths[tokens[i]] = len(decoded_tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    assert len(all_tokens) == len(word_lengths), \"Association of tokens with word length : FAILED.\"\n",
    "\n",
    "    return word_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e993a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mario Mandzukic pounces to fire the ball past Jordan Pickford and put Croatia into the World Cup final', ' Photo: Reuters Independent', \"ie \\n \\nFormer England defender Gary Neville suggested Gareth Southgate's squad had done more than could have been expected of them at this World Cup as they bowed out with a semi-final defeat against Croatia\", ' \\n \\nhttps://www', 'independent', 'ie/sport/soccer/world-cup-2018/gary-neville-salutes-englands-overachievers-as-alan-shearer-and-rio-ferdinand-give-their-verdicts-37108667', 'html \\n \\nhttps://www', 'independent', 'ie/incoming/article37108634', 'ece/7571a/AUTOCROP/h342/52Man1', \"jpg \\n   Email     \\nFormer England defender Gary Neville suggested Gareth Southgate's squad had done more than could have been expected of them at this World Cup as they bowed out with a semi-final defeat against Croatia\", ' \\n  \\nA jaded England faded after had Kieran Trippier fired England ahead after just five minutes with a superb free-kick, with goals from Ivan Perisic and Mario Mandzukic earned Croatia a date with France after a 2-1 extra-time win in Moscow', ' \\n \\n\"The first thing to say is this team has taken us to a place we never imagined we could get,\" said Neville', ' \\n \\n\"I said before the tournament England never overachieve, this team has overachieved getting to the semi-final and they can all be absolutely proud', ' \\n \\n\"They have taken the nation with them', ' You see all the fans out in the park to see them', \" I never thought I'd see scenes like that in this World Cup\", ' \\n \\n\"They can be absolutely proud', ' We did say before the game these lads have to take this opportunity because it may never come again', ' \\n \\n\"All I hope as I look at them now crying, disappointed, upset is they get another opportunity as good as the one they\\'ve just had', '\" \\n \\n\"They\\'re the youngest team in the tournament', \" I hope they're in that position again, 1-0 up with 20 minutes to go with the opportunity of getting into a World Cup final\", '\" \\n  Croatia\\'s Dejan Lovren and Domagoj Vida celebrate after the match', \" Photo: Reuters   \\nFormer England defender Rio Ferdinand believes the youthful nature of England's squad proved to be their undoing in the semi-final\", ' \\n \\n\"I think experience was a telling factor today,\" Ferdinand told the BBC', ' \"This Croatian team had medals all over the squad but now is not the time to knitpick', \" This bunch of players have brought the nation together and the fans haven't sung like this for years\", ' \\n \\n\"We wanted this team to come out with an identity and a philosophy of playing, and I think they have done that', \" Where we were sat in the stadium, people around us were impressed with England's football and their ability to play out from the back\", ' \\n \\n\"Kieran Trippier\\'s delivery of the ball was brilliant and what a tournament he has had', ' There were question marks over Jordan Pickford but he was the best choice in goal and this team can develop into something very strong', ' I have been an admirer of John Stones for a long time, and he defended unbelievably today', ' We have got a very inexperienced young squad but they have grown and will continue to do so', '\" \\n \\nEx-England striker Alan Shearer also tried to find the positives amid England\\'s anguish', ' \\n \\n\"We said before the tournament that if they gave absolutely everything in every game, everyone at home would be happy,\" said Shearer', ' \\n \\n\"England got off to a very good start and dominated the first 45 minutes but Croatia stepped 10 yards further forward in the second half', ' \\n \\n\"Luka Modric bossed the midfield and we could not get near him with his deft touches and passes, he was superb and a man of the match performance, a vital cog for them', ' We lacked experience to get someone on him and stop him', ' Croatia did not panic when they fell behind', ' \\n \\n\"Kieran Trippier was brilliant in the tournament and so was Jordan Pickford, especially with his delivery', ' Harry Kane was a bit quiet in the knockout games and he had a chance that he could not put away \\n \\n\"So many positives to take out of the tournament, we did not expect to get to the quarters and will go home after this without heads held high', ' Finishing third would be excellent', ' Well done guys, you have given us plenty to shout about', '\" \\n \\nOnline Editors']\n",
      "[[7986, 2158, 2094, 24015, 2278, 13433, 17457, 2015, 2000, 2543, 1996, 3608, 2627, 5207, 4060, 3877, 1998, 2404, 8097, 2046, 1996, 2088, 2452, 2345], [6302, 1024, 26665, 2981], [29464, 2280, 2563, 8291, 5639, 14871, 4081, 20243, 2148, 5867, 1005, 1055, 4686, 2018, 2589, 2062, 2084, 2071, 2031, 2042, 3517, 1997, 2068, 2012, 2023, 2088, 2452, 2004, 2027, 11489, 2041, 2007, 1037, 4100, 1011, 2345, 4154, 2114, 8097], [16770, 1024, 1013, 1013, 7479], [2981], [29464, 1013, 4368, 1013, 4715, 1013, 2088, 1011, 2452, 1011, 2760, 1013, 5639, 1011, 14871, 1011, 17664, 2015, 1011, 2563, 2015, 1011, 2058, 21046, 22507, 2015, 1011, 2004, 1011, 5070, 1011, 18330, 2121, 1011, 1998, 1011, 5673, 1011, 9684, 1011, 2507, 1011, 2037, 1011, 14392, 2015, 1011, 4261, 10790, 20842, 2575, 2581], [16129, 16770, 1024, 1013, 1013, 7479], [2981], [29464, 1013, 14932, 1013, 3720, 24434, 10790, 20842, 22022], [14925, 2063, 1013, 4293, 2581, 2487, 2050, 1013, 8285, 26775, 7361, 1013, 1044, 22022, 2475, 1013, 4720, 2386, 2487], [16545, 2290, 10373, 2280, 2563, 8291, 5639, 14871, 4081, 20243, 2148, 5867, 1005, 1055, 4686, 2018, 2589, 2062, 2084, 2071, 2031, 2042, 3517, 1997, 2068, 2012, 2023, 2088, 2452, 2004, 2027, 11489, 2041, 2007, 1037, 4100, 1011, 2345, 4154, 2114, 8097], [1037, 12323, 2094, 2563, 8105, 2044, 2018, 11382, 23169, 4440, 14756, 2099, 5045, 2563, 3805, 2044, 2074, 2274, 2781, 2007, 1037, 21688, 2489, 1011, 5926, 1010, 2007, 3289, 2013, 7332, 2566, 17417, 2278, 1998, 7986, 2158, 2094, 24015, 2278, 3687, 8097, 1037, 3058, 2007, 2605, 2044, 1037, 1016, 1011, 1015, 4469, 1011, 2051, 2663, 1999, 4924], [1000, 1996, 2034, 2518, 2000, 2360, 2003, 2023, 2136, 2038, 2579, 2149, 2000, 1037, 2173, 2057, 2196, 8078, 2057, 2071, 2131, 1010, 1000, 2056, 14871], [1000, 1045, 2056, 2077, 1996, 2977, 2563, 2196, 2058, 21046, 18697, 1010, 2023, 2136, 2038, 2058, 21046, 18697, 2094, 2893, 2000, 1996, 4100, 1011, 2345, 1998, 2027, 2064, 2035, 2022, 7078, 7098], [1000, 2027, 2031, 2579, 1996, 3842, 2007, 2068], [2017, 2156, 2035, 1996, 4599, 2041, 1999, 1996, 2380, 2000, 2156, 2068], [1045, 2196, 2245, 1045, 1005, 1040, 2156, 5019, 2066, 2008, 1999, 2023, 2088, 2452], [1000, 2027, 2064, 2022, 7078, 7098], [2057, 2106, 2360, 2077, 1996, 2208, 2122, 29126, 2031, 2000, 2202, 2023, 4495, 2138, 2009, 2089, 2196, 2272, 2153], [1000, 2035, 1045, 3246, 2004, 1045, 2298, 2012, 2068, 2085, 6933, 1010, 9364, 1010, 6314, 2003, 2027, 2131, 2178, 4495, 2004, 2204, 2004, 1996, 2028, 2027, 1005, 2310, 2074, 2018], [1000, 1000, 2027, 1005, 2128, 1996, 6587, 2136, 1999, 1996, 2977], [1045, 3246, 2027, 1005, 2128, 1999, 2008, 2597, 2153, 1010, 1015, 1011, 1014, 2039, 2007, 2322, 2781, 2000, 2175, 2007, 1996, 4495, 1997, 2893, 2046, 1037, 2088, 2452, 2345], [1000, 8097, 1005, 1055, 2139, 8405, 8840, 12229, 2078, 1998, 14383, 23692, 3501, 19830, 8439, 2044, 1996, 2674], [6302, 1024, 26665, 2280, 2563, 8291, 5673, 9684, 7164, 1996, 22446, 3267, 1997, 2563, 1005, 1055, 4686, 4928, 2000, 2022, 2037, 25672, 2075, 1999, 1996, 4100, 1011, 2345], [1000, 1045, 2228, 3325, 2001, 1037, 4129, 5387, 2651, 1010, 1000, 9684, 2409, 1996, 4035], [1000, 2023, 7963, 2136, 2018, 6665, 2035, 2058, 1996, 4686, 2021, 2085, 2003, 2025, 1996, 2051, 2000, 22404, 24330, 2243], [2023, 9129, 1997, 2867, 2031, 2716, 1996, 3842, 2362, 1998, 1996, 4599, 4033, 1005, 1056, 7042, 2066, 2023, 2005, 2086], [1000, 2057, 2359, 2023, 2136, 2000, 2272, 2041, 2007, 2019, 4767, 1998, 1037, 4695, 1997, 2652, 1010, 1998, 1045, 2228, 2027, 2031, 2589, 2008], [2073, 2057, 2020, 2938, 1999, 1996, 3346, 1010, 2111, 2105, 2149, 2020, 7622, 2007, 2563, 1005, 1055, 2374, 1998, 2037, 3754, 2000, 2377, 2041, 2013, 1996, 2067], [1000, 11382, 23169, 4440, 14756, 2099, 1005, 1055, 6959, 1997, 1996, 3608, 2001, 8235, 1998, 2054, 1037, 2977, 2002, 2038, 2018], [2045, 2020, 3160, 6017, 2058, 5207, 4060, 3877, 2021, 2002, 2001, 1996, 2190, 3601, 1999, 3125, 1998, 2023, 2136, 2064, 4503, 2046, 2242, 2200, 2844], [1045, 2031, 2042, 2019, 19837, 2099, 1997, 2198, 6386, 2005, 1037, 2146, 2051, 1010, 1998, 2002, 8047, 4895, 8671, 2666, 3567, 6321, 2651], [2057, 2031, 2288, 1037, 2200, 26252, 2402, 4686, 2021, 2027, 2031, 4961, 1998, 2097, 3613, 2000, 2079, 2061], [1000, 4654, 1011, 2563, 11854, 5070, 18330, 2121, 2036, 2699, 2000, 2424, 1996, 3893, 2015, 13463, 2563, 1005, 1055, 21782], [1000, 2057, 2056, 2077, 1996, 2977, 2008, 2065, 2027, 2435, 7078, 2673, 1999, 2296, 2208, 1010, 3071, 2012, 2188, 2052, 2022, 3407, 1010, 1000, 2056, 18330, 2121], [1000, 2563, 2288, 2125, 2000, 1037, 2200, 2204, 2707, 1998, 6817, 1996, 2034, 3429, 2781, 2021, 8097, 3706, 2184, 4210, 2582, 2830, 1999, 1996, 2117, 2431], [1000, 11320, 2912, 16913, 7277, 5795, 2098, 1996, 23071, 1998, 2057, 2071, 2025, 2131, 2379, 2032, 2007, 2010, 13366, 2102, 12817, 1998, 5235, 1010, 2002, 2001, 21688, 1998, 1037, 2158, 1997, 1996, 2674, 2836, 1010, 1037, 8995, 2522, 2290, 2005, 2068], [2057, 10858, 3325, 2000, 2131, 2619, 2006, 2032, 1998, 2644, 2032], [8097, 2106, 2025, 6634, 2043, 2027, 3062, 2369], [1000, 11382, 23169, 4440, 14756, 2099, 2001, 8235, 1999, 1996, 2977, 1998, 2061, 2001, 5207, 4060, 3877, 1010, 2926, 2007, 2010, 6959], [4302, 8472, 2001, 1037, 2978, 4251, 1999, 1996, 11369, 2399, 1998, 2002, 2018, 1037, 3382, 2008, 2002, 2071, 2025, 2404, 2185, 1000, 2061, 2116, 3893, 2015, 2000, 2202, 2041, 1997, 1996, 2977, 1010, 2057, 2106, 2025, 5987, 2000, 2131, 2000, 1996, 7728, 1998, 2097, 2175, 2188, 2044, 2023, 2302, 4641, 2218, 2152], [5131, 2353, 2052, 2022, 6581], [2092, 2589, 4364, 1010, 2017, 2031, 2445, 2149, 7564, 2000, 11245, 2055], [1000, 3784, 10195]]\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_fn(x, tokenizer):\n",
    "    x[\"summary_ids\"] = tokenizer(\n",
    "        x[\"summary\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    x[\"text_ids\"] = tokenizer(\n",
    "        x[\"text\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    x[\"sentences_ids\"] = tokenizer(\n",
    "        x[\"sentences\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    return x\n",
    "\n",
    "splitted_dataset = dataset.select_columns([\"summary\", \"text\", \"sentences\"])\n",
    "# print(splitted_dataset.__getitem__(0))\n",
    "\n",
    "word_lengths = get_word_lengths(splitted_dataset, tokenizer)\n",
    "\n",
    "# Tokenize the dataset\n",
    "splitted_dataset = splitted_dataset.map(\n",
    "    preprocessing_fn, tokenizer = tokenizer\n",
    ")\n",
    "print(splitted_dataset.__getitem__(0)[2])\n",
    "\n",
    "# Remove useless columns\n",
    "splitted_dataset = splitted_dataset.select_columns([\"summary_ids\", \"text_ids\", \"sentences_ids\"])\n",
    "print(splitted_dataset.__getitem__(0)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871c9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Get the tokenized sequences for each item in the batch\n",
    "    text_ids_batch = [torch.tensor(item[1], dtype = torch.int) for item in batch]\n",
    "    summary_ids_batch = [torch.tensor(item[0], dtype = torch.int) for item in batch]\n",
    "    sentences_ids_batch = [\n",
    "        [torch.tensor(sentence, dtype = torch.int) for sentence in item[2]]\n",
    "        for item in batch\n",
    "    ]\n",
    "\n",
    "    # Pad sequences to the maximum length in the batch\n",
    "    padded_text_ids = pad_sequence([torch.cat([item, torch.zeros(max(0, 512 - len(item)))]) for item in text_ids_batch], batch_first = True, padding_value = 0)\n",
    "    padded_summary_ids = pad_sequence([torch.cat([item, torch.zeros(max(0, 512 - len(item)))]) for item in summary_ids_batch], batch_first = True, padding_value = 0)\n",
    "    padded_sentences_ids = [\n",
    "        pad_sequence(\n",
    "            [torch.cat([sentence, torch.zeros(max(0, 512 - len(sentence)), dtype = torch.int)]) for sentence in item],\n",
    "            batch_first = True,\n",
    "            padding_value = 0\n",
    "        )\n",
    "        for item in sentences_ids_batch\n",
    "    ]\n",
    "\n",
    "    return {\"text_ids\": padded_text_ids, \"summary_ids\": padded_summary_ids, \"sentences_ids\": padded_sentences_ids}\n",
    "\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(splitted_dataset, batch_size = batch_size, collate_fn = collate_fn)\n",
    "\n",
    "epochs = 3\n",
    "def training(summary, text, model, epochs = 10):\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    model_copy.train()\n",
    "\n",
    "    summary = summary.unsqueeze(0)\n",
    "    text = text.unsqueeze(0)\n",
    "    if summary.size(1) != text.size(1):\n",
    "        raise RuntimeError(\"Sizes along the sequence length dimension must match.\")\n",
    "    \n",
    "    for epochs in range(epochs):\n",
    "        whole_input = torch.cat((summary, text), dim = 0).long()\n",
    "        outputs = model_copy(whole_input, labels = whole_input)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82de7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sentence(sentence, i, M, word_lengths, l_min):\n",
    "    tokenized_sentence = []\n",
    "    masked_token_ids = []\n",
    "\n",
    "    for j in range(len(sentence)):\n",
    "        if (j - i) % M == 0 and sentence[j].item() in word_lengths and word_lengths[sentence[j].item()] >= l_min:\n",
    "            tokenized_sentence.append(tokenizer.mask_token_id)\n",
    "            masked_token_ids.append(j)\n",
    "        else:\n",
    "            tokenized_sentence.append(sentence[j].item())\n",
    "            \n",
    "    tokenized_sentence= torch.tensor(tokenized_sentence)\n",
    "    \n",
    "    return tokenized_sentence, masked_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe719f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_BLANC_help(sentences, model, model_tuned, p_mask = 0.15, l_min = 4):\n",
    "    S = [[0, 0], [0, 0]]\n",
    "    M = int(1/p_mask)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for i in range(M):\n",
    "            masked_sentence, masked_tokens_ids = mask_sentence(sentence, i, M, word_lengths, l_min)\n",
    "            masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n",
    "            sentence = sentence.long()\n",
    "\n",
    "            out_base = model(masked_sentence, labels = sentence).logits\n",
    "            out_help = model_tuned(masked_sentence, labels = sentence).logits\n",
    "\n",
    "            for j in masked_tokens_ids:\n",
    "                predicted_token_model = torch.argmax(out_base[0][j])\n",
    "                predicted_token_model_tuned = torch.argmax(out_help[0][j])\n",
    "                \n",
    "                k = int(predicted_token_model == sentence[j])\n",
    "                m = int(predicted_token_model_tuned == sentence[j])\n",
    "                S[k][m] += 1\n",
    "        break\n",
    "    try:\n",
    "      B = (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
    "    except ZeroDivisionError:\n",
    "      B = 0.0\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99b978b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 0 of batch\n",
      "67 [18, 87, 42, 37, 7, 102, 78, 111, 19, 88, 11, 51, 43, 27, 23, 83, 34, 66, 80, 109, 24, 32, 14, 68, 103, 93, 116, 71, 35, 106, 4, 59, 29, 95, 13, 0, 21, 97, 41, 86, 38, 99, 69, 15, 114, 92, 62, 49, 110, 16, 98, 1, 2, 39, 60, 5, 54, 107, 74, 6, 84, 8, 118, 44, 56, 3, 17]\n",
      "18\n",
      "67 [1, 19, 29, 38, 0, 111, 44, 43, 59, 5, 39, 99, 49, 11, 14, 41, 7, 24, 8, 88, 66, 98, 118, 80, 51, 93, 109, 102, 23, 6, 83, 92, 37, 60, 2, 87, 3, 27, 17, 114, 116, 97, 35, 42, 84, 18, 54, 106, 110, 62, 4, 69, 74, 78, 21, 71, 16, 32, 107, 13, 34, 95, 68, 103, 56, 86, 15]\n",
      "18\n",
      "67 [118, 32, 4, 102, 17, 41, 16, 2, 114, 78, 37, 106, 95, 92, 34, 1, 80, 44, 43, 3, 38, 18, 71, 88, 68, 66, 84, 111, 5, 110, 60, 11, 15, 59, 24, 6, 109, 14, 49, 103, 99, 107, 13, 39, 23, 93, 29, 69, 21, 86, 54, 116, 7, 83, 74, 0, 98, 56, 19, 51, 42, 62, 35, 87, 8, 97, 27]\n",
      "18\n",
      "67 [24, 110, 42, 11, 8, 62, 5, 83, 15, 88, 13, 78, 43, 99, 35, 19, 38, 14, 32, 27, 109, 6, 86, 116, 98, 54, 118, 23, 107, 59, 103, 16, 44, 21, 97, 49, 114, 111, 2, 74, 80, 3, 68, 93, 0, 84, 87, 95, 56, 60, 1, 29, 4, 17, 18, 7, 106, 51, 102, 41, 34, 69, 71, 92, 66, 37, 39]\n",
      "18\n",
      "67 [27, 66, 15, 84, 87, 14, 51, 88, 2, 95, 8, 7, 78, 17, 59, 62, 24, 74, 49, 1, 118, 11, 93, 103, 83, 71, 29, 110, 68, 111, 32, 39, 23, 109, 19, 60, 86, 35, 80, 99, 37, 16, 43, 44, 38, 13, 107, 5, 0, 54, 69, 3, 6, 56, 114, 106, 92, 41, 4, 98, 18, 42, 116, 34, 97, 21, 102]\n",
      "18\n",
      "67 [83, 34, 29, 54, 13, 102, 23, 15, 49, 74, 78, 1, 118, 39, 32, 3, 109, 97, 111, 68, 35, 21, 17, 103, 11, 41, 7, 107, 14, 56, 95, 86, 88, 98, 6, 106, 0, 4, 84, 42, 24, 69, 87, 8, 37, 116, 114, 93, 80, 99, 16, 19, 27, 51, 59, 110, 71, 38, 5, 66, 2, 62, 60, 44, 18, 92, 43]\n",
      "18\n",
      "67 [92, 18, 59, 51, 38, 27, 88, 116, 44, 74, 35, 17, 15, 118, 23, 32, 69, 16, 103, 42, 3, 60, 71, 98, 111, 43, 1, 66, 37, 86, 14, 24, 62, 106, 83, 93, 78, 34, 102, 54, 11, 4, 7, 99, 97, 107, 80, 56, 41, 84, 13, 19, 109, 8, 87, 29, 0, 2, 21, 95, 39, 68, 5, 6, 49, 110, 114]\n",
      "18\n",
      "67 [35, 60, 106, 80, 83, 51, 111, 78, 43, 11, 95, 44, 66, 18, 5, 27, 0, 38, 62, 8, 92, 23, 98, 3, 68, 102, 16, 13, 74, 34, 56, 39, 6, 2, 59, 14, 19, 7, 99, 118, 54, 87, 49, 69, 114, 84, 116, 21, 29, 37, 110, 71, 1, 97, 17, 88, 109, 24, 32, 42, 103, 93, 15, 41, 107, 4, 86]\n",
      "18\n",
      "67 [21, 110, 8, 32, 103, 54, 107, 99, 51, 87, 34, 3, 93, 116, 111, 78, 17, 97, 18, 98, 1, 88, 4, 6, 83, 11, 44, 7, 106, 109, 2, 29, 80, 86, 5, 13, 43, 49, 102, 68, 41, 42, 27, 118, 62, 114, 39, 16, 23, 95, 0, 56, 37, 24, 59, 66, 14, 84, 74, 35, 71, 38, 15, 19, 60, 92, 69]\n",
      "18\n",
      "67 [88, 54, 1, 14, 99, 23, 24, 37, 3, 0, 17, 102, 80, 5, 35, 16, 34, 114, 29, 15, 84, 69, 78, 2, 59, 38, 98, 110, 107, 11, 118, 4, 68, 60, 93, 111, 109, 21, 18, 19, 74, 43, 13, 87, 95, 39, 49, 83, 66, 41, 86, 27, 62, 56, 51, 71, 116, 92, 8, 42, 7, 97, 103, 44, 6, 106, 32]\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_22756\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Elapsed Time: 18.041014194488525 seconds\n",
      "Summary 1 of batch\n",
      "53 [64, 85, 61, 18, 35, 59, 66, 13, 25, 81, 9, 27, 83, 10, 5, 73, 50, 56, 63, 8, 67, 7, 20, 32, 4, 2, 60, 40, 29, 19, 57, 72, 12, 49, 14, 37, 33, 80, 3, 69, 39, 28, 71, 52, 23, 62, 76, 58, 38, 36, 79, 30, 34]\n",
      "13\n",
      "53 [37, 61, 57, 76, 32, 67, 64, 59, 80, 83, 39, 52, 18, 58, 69, 9, 28, 71, 33, 40, 2, 29, 38, 79, 8, 36, 5, 85, 56, 62, 30, 14, 35, 27, 49, 20, 60, 10, 50, 12, 72, 13, 63, 73, 19, 25, 3, 4, 81, 7, 66, 23, 34]\n",
      "13\n",
      "53 [3, 58, 60, 27, 69, 80, 30, 62, 81, 32, 5, 76, 36, 8, 20, 25, 73, 59, 19, 40, 34, 37, 23, 71, 4, 10, 14, 12, 29, 79, 72, 61, 63, 50, 28, 57, 18, 85, 13, 49, 64, 83, 39, 9, 52, 38, 2, 33, 66, 56, 7, 35, 67]\n",
      "13\n",
      "53 [19, 62, 56, 76, 4, 64, 2, 69, 33, 60, 7, 32, 80, 36, 27, 63, 58, 39, 9, 5, 10, 49, 13, 12, 61, 67, 18, 14, 28, 57, 20, 34, 72, 35, 30, 81, 37, 23, 29, 85, 3, 40, 79, 66, 50, 71, 83, 59, 52, 38, 73, 25, 8]\n",
      "13\n",
      "53 [76, 62, 20, 8, 34, 10, 35, 66, 23, 14, 27, 63, 57, 85, 37, 56, 13, 32, 7, 49, 61, 36, 38, 19, 73, 81, 25, 39, 67, 3, 80, 18, 33, 40, 71, 50, 69, 60, 83, 9, 52, 64, 79, 29, 59, 5, 4, 28, 12, 58, 72, 2, 30]\n",
      "13\n",
      "53 [72, 39, 37, 35, 30, 69, 66, 19, 83, 60, 3, 28, 62, 36, 61, 85, 5, 73, 81, 56, 32, 12, 57, 33, 52, 23, 58, 49, 34, 13, 10, 4, 29, 50, 40, 38, 2, 71, 7, 59, 18, 25, 14, 8, 67, 27, 80, 64, 20, 79, 9, 76, 63]\n",
      "13\n",
      "53 [35, 7, 38, 2, 5, 13, 19, 10, 9, 73, 33, 57, 14, 85, 34, 79, 18, 81, 80, 63, 20, 29, 69, 12, 72, 66, 61, 25, 59, 50, 36, 64, 76, 60, 23, 67, 3, 27, 32, 39, 4, 62, 8, 40, 52, 58, 56, 28, 37, 83, 30, 71, 49]\n",
      "13\n",
      "53 [61, 9, 14, 50, 36, 33, 76, 7, 18, 39, 64, 69, 3, 83, 72, 4, 71, 62, 79, 63, 13, 8, 80, 30, 81, 73, 59, 25, 34, 60, 23, 29, 12, 28, 20, 66, 40, 52, 35, 57, 19, 5, 38, 49, 58, 67, 2, 56, 37, 10, 85, 27, 32]\n",
      "13\n",
      "53 [5, 85, 71, 57, 8, 69, 27, 61, 66, 4, 81, 34, 39, 32, 58, 35, 3, 20, 64, 37, 60, 10, 9, 83, 23, 76, 63, 79, 73, 14, 18, 50, 40, 80, 52, 30, 29, 2, 67, 72, 33, 38, 28, 7, 12, 56, 62, 19, 36, 13, 59, 49, 25]\n",
      "13\n",
      "53 [12, 18, 34, 67, 14, 59, 3, 85, 72, 79, 69, 29, 19, 28, 25, 80, 62, 61, 23, 39, 5, 20, 81, 35, 40, 71, 60, 83, 10, 56, 30, 4, 52, 32, 36, 58, 64, 8, 37, 63, 33, 27, 50, 7, 76, 66, 38, 13, 73, 2, 49, 57, 9]\n",
      "13\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_22756\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12\n",
      "Elapsed Time: 17.784279346466064 seconds\n",
      "Summary 2 of batch\n",
      "51 [51, 1, 26, 37, 39, 32, 42, 30, 49, 62, 4, 69, 72, 34, 28, 7, 3, 64, 15, 6, 35, 47, 8, 31, 17, 29, 60, 46, 74, 66, 2, 77, 27, 55, 0, 61, 57, 22, 41, 20, 9, 56, 44, 21, 63, 71, 33, 59, 5, 13, 10]\n",
      "11\n",
      "51 [41, 34, 66, 33, 44, 30, 0, 56, 35, 3, 51, 55, 7, 1, 63, 42, 9, 21, 29, 37, 47, 69, 61, 13, 26, 4, 62, 46, 17, 49, 10, 77, 5, 64, 32, 71, 39, 28, 2, 6, 8, 22, 59, 15, 60, 72, 31, 57, 20, 74, 27]\n",
      "11\n",
      "51 [44, 57, 34, 27, 30, 0, 5, 66, 2, 69, 62, 8, 46, 61, 10, 13, 49, 15, 37, 26, 7, 31, 39, 21, 9, 35, 64, 47, 3, 17, 55, 28, 77, 4, 59, 29, 51, 1, 42, 20, 6, 74, 60, 33, 56, 22, 72, 71, 63, 32, 41]\n",
      "11\n",
      "51 [47, 46, 59, 30, 20, 42, 28, 13, 8, 22, 60, 66, 0, 9, 55, 35, 69, 37, 29, 33, 62, 56, 2, 63, 27, 61, 4, 51, 10, 57, 44, 1, 72, 5, 41, 7, 15, 26, 34, 3, 31, 49, 77, 6, 74, 21, 71, 39, 17, 32, 64]\n",
      "11\n",
      "51 [61, 27, 60, 37, 57, 62, 26, 10, 2, 5, 33, 41, 77, 66, 59, 63, 17, 15, 74, 49, 0, 71, 44, 9, 64, 30, 34, 51, 69, 28, 72, 20, 55, 6, 46, 32, 39, 42, 4, 7, 47, 35, 8, 3, 22, 13, 1, 29, 56, 21, 31]\n",
      "11\n",
      "51 [44, 1, 33, 26, 22, 31, 66, 5, 72, 56, 9, 0, 74, 27, 15, 47, 3, 49, 28, 29, 32, 2, 21, 59, 4, 13, 8, 62, 42, 60, 10, 69, 55, 34, 77, 30, 35, 20, 39, 71, 17, 51, 63, 61, 7, 64, 6, 37, 57, 46, 41]\n",
      "11\n",
      "51 [1, 47, 56, 60, 74, 10, 41, 21, 2, 49, 44, 22, 4, 15, 13, 72, 5, 63, 8, 35, 0, 39, 29, 30, 59, 77, 33, 62, 37, 61, 34, 71, 26, 7, 32, 51, 66, 64, 20, 42, 9, 17, 46, 55, 6, 31, 28, 57, 27, 3, 69]\n",
      "11\n",
      "51 [7, 46, 27, 15, 64, 2, 1, 34, 66, 31, 44, 0, 4, 49, 61, 37, 51, 59, 69, 13, 72, 22, 6, 8, 39, 42, 60, 21, 74, 63, 20, 26, 56, 57, 62, 9, 3, 77, 55, 29, 28, 32, 10, 30, 41, 35, 33, 17, 47, 71, 5]\n",
      "11\n",
      "51 [28, 59, 30, 35, 74, 64, 71, 26, 32, 21, 6, 47, 22, 66, 63, 61, 5, 60, 72, 55, 3, 9, 42, 77, 57, 15, 39, 17, 27, 10, 62, 56, 41, 1, 69, 2, 34, 4, 31, 51, 46, 20, 49, 33, 8, 13, 37, 44, 0, 7, 29]\n",
      "11\n",
      "51 [32, 3, 44, 49, 77, 8, 26, 0, 61, 39, 13, 17, 1, 62, 35, 63, 69, 56, 41, 27, 72, 51, 34, 42, 2, 29, 37, 33, 66, 28, 5, 59, 22, 55, 6, 21, 9, 57, 31, 15, 64, 47, 7, 60, 46, 4, 10, 74, 20, 30, 71]\n",
      "11\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liora\\AppData\\Local\\Temp\\ipykernel_22756\\682133311.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  masked_sentence = torch.tensor(masked_sentence).view(1, -1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "Elapsed Time: 17.7088725566864 seconds\n",
      "Summary 3 of batch\n",
      "27 [34, 7, 32, 23, 18, 54, 2, 46, 40, 12, 6, 26, 53, 38, 22, 55, 33, 31, 35, 42, 51, 44, 5, 25, 28, 57, 3]\n",
      "8\n",
      "27 [32, 51, 53, 6, 34, 5, 23, 26, 2, 25, 38, 31, 18, 7, 55, 40, 28, 54, 42, 57, 46, 33, 22, 3, 12, 44, 35]\n",
      "8\n",
      "27 [6, 35, 22, 2, 32, 33, 51, 55, 12, 18, 23, 34, 3, 44, 38, 54, 31, 25, 28, 57, 40, 5, 26, 7, 42, 46, 53]\n",
      "8\n",
      "27 [57, 6, 38, 53, 31, 33, 46, 54, 51, 42, 23, 32, 40, 3, 5, 7, 22, 44, 34, 26, 18, 12, 25, 55, 2, 28, 35]\n",
      "8\n",
      "27 [2, 40, 46, 18, 53, 26, 5, 34, 23, 6, 35, 38, 31, 57, 25, 44, 22, 28, 32, 3, 33, 54, 42, 51, 55, 12, 7]\n",
      "8\n",
      "27 [53, 40, 44, 6, 5, 55, 2, 38, 57, 28, 34, 46, 42, 22, 26, 3, 23, 7, 18, 12, 32, 51, 35, 31, 25, 54, 33]\n",
      "8\n",
      "27 [26, 7, 25, 53, 54, 23, 42, 38, 34, 44, 51, 12, 40, 18, 6, 46, 35, 31, 3, 55, 2, 28, 33, 22, 5, 32, 57]\n",
      "8\n",
      "27 [53, 44, 35, 12, 22, 31, 26, 3, 18, 28, 57, 46, 38, 32, 6, 23, 40, 5, 2, 42, 33, 55, 54, 7, 51, 34, 25]\n",
      "8\n",
      "27 [23, 51, 55, 26, 3, 53, 31, 54, 12, 25, 40, 18, 7, 46, 28, 57, 35, 2, 38, 34, 6, 5, 33, 42, 44, 32, 22]\n",
      "8\n",
      "27 [25, 23, 51, 22, 57, 33, 18, 26, 6, 32, 46, 12, 44, 40, 7, 28, 42, 3, 34, 31, 2, 54, 53, 55, 38, 35, 5]\n",
      "8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_tuned_models, batch_accuracies\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m---> 45\u001b[0m     models_tuned, text_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mblanc_tune_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 33\u001b[0m, in \u001b[0;36mblanc_tune_batch\u001b[1;34m(batch, model, p_mask, l_min, N, epochs)\u001b[0m\n\u001b[0;32m     31\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     32\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 33\u001b[0m model_tuned \u001b[38;5;241m=\u001b[39m \u001b[43mblanc_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m batch_tuned_models\u001b[38;5;241m.\u001b[39mappend(model_tuned)\n\u001b[0;32m     35\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m modified_BLANC_help(sentences, model, model_tuned)\n",
      "Cell \u001b[1;32mIn[15], line 20\u001b[0m, in \u001b[0;36mblanc_tune\u001b[1;34m(summary, text, model, p_mask, l_min, N, epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m             set_tune\u001b[38;5;241m.\u001b[39mloc[set_tune\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m [masked_summary, text]\n\u001b[0;32m     18\u001b[0m         pos \u001b[38;5;241m=\u001b[39m pos[N_mask:]\n\u001b[1;32m---> 20\u001b[0m model_tuned \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)      \n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_tuned\n",
      "Cell \u001b[1;32mIn[9], line 39\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(summary, text, model, epochs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epochs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     38\u001b[0m     whole_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((summary, text), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m---> 39\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhole_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwhole_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     41\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1375\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1360\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[0;32m   1361\u001b[0m     input_ids,\n\u001b[0;32m   1362\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1371\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1372\u001b[0m )\n\u001b[0;32m   1374\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1375\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1377\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:707\u001b[0m, in \u001b[0;36mBertOnlyMLMHead.forward\u001b[1;34m(self, sequence_output)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequence_output: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 707\u001b[0m     prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prediction_scores\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:697\u001b[0m, in \u001b[0;36mBertLMPredictionHead.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m    696\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(hidden_states)\n\u001b[1;32m--> 697\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def blanc_tune(summary, text, model, p_mask = 0.15, l_min = 4, N = 10, epochs = 10):\n",
    "    N_summary = len(summary[:summary.tolist().index(0)])\n",
    "    N_mask = int(N_summary*p_mask)\n",
    "    set_tune = pd.DataFrame(columns = ['summary', 'text'])\n",
    "\n",
    "    for j in range(0, N):\n",
    "        pos = [i for i, token in enumerate(summary.tolist()) if token in word_lengths and word_lengths[token] >= l_min]\n",
    "        random.shuffle(pos)\n",
    "        # print(len(pos), pos)\n",
    "        # print(N_mask)\n",
    "        while len(pos) != 0:\n",
    "            masked_summary = summary.tolist().copy()\n",
    "            for pos_to_mask in pos[:N_mask]:\n",
    "                masked_summary[pos_to_mask] = '[MASK]'\n",
    "                set_tune.loc[set_tune.shape[0]] = [masked_summary, text]\n",
    "            pos = pos[N_mask:]\n",
    "\n",
    "    model_tuned = training(summary, text, model, epochs)\n",
    "    print('\\n')      \n",
    "    return model_tuned\n",
    "\n",
    "def blanc_tune_batch(batch, model, p_mask = 0.15, l_min = 4, N = 10, epochs = 10):\n",
    "    batch_tuned_models = []\n",
    "    batch_accuracies = []\n",
    "    \n",
    "    i = 0\n",
    "    for summary, text, sentences in zip(batch['summary_ids'], batch['text_ids'], batch['sentences_ids']):\n",
    "        print(f\"Summary {i} of batch\")\n",
    "        i += 1\n",
    "        start_time = time.time()\n",
    "        model_tuned = blanc_tune(summary, text, model, p_mask, l_min, N, epochs)\n",
    "        batch_tuned_models.append(model_tuned)\n",
    "        accuracy = modified_BLANC_help(sentences, model, model_tuned)\n",
    "        print(accuracy)\n",
    "        end_time = time.time()\n",
    "        batch_accuracies.append(accuracy)\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "    return batch_tuned_models, batch_accuracies\n",
    "\n",
    "for batch in dataloader:\n",
    "    models_tuned, text_accuracies = blanc_tune_batch(batch, model, epochs = epochs)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "collabfiltering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
