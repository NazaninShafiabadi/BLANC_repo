{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d9f8b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b872e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\Liora\\anaconda3\\envs\\blanc\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('./datasets/DailyNews_300.json')\n",
    "print(data.shape)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397b468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.features = self.dataset.columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.dataset.iloc[idx, 0], self.dataset.iloc[idx, 1], self.dataset.iloc[idx, 2])\n",
    "    \n",
    "    def map(self, preprocessing_fn, **kwargs):\n",
    "        return CustomDataset(self.dataset.apply(lambda x: preprocessing_fn(x, **kwargs), axis = 1))\n",
    "    \n",
    "    def select_columns(self, columns):\n",
    "        new_dataset = self.dataset[columns] \n",
    "        return CustomDataset(new_dataset)\n",
    "    \n",
    "    def get_sentences(self):\n",
    "        self.dataset['sentences'] = self.dataset['text'].apply(lambda x: x.split('.'))\n",
    "        return CustomDataset(self.dataset)\n",
    "    \n",
    "dataset = CustomDataset(data)\n",
    "dataset = dataset.get_sentences()\n",
    "# print(dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34df281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_lengths(dataset, tokenizer):\n",
    "    word_lengths = {}\n",
    "    all_tokens = []\n",
    "\n",
    "    for sample in dataset:\n",
    "        summary = sample[0]\n",
    "        preprocessed_result = tokenizer(summary, \n",
    "                                        add_special_tokens = False,\n",
    "                                        truncation = True,\n",
    "                                        max_length = 512,\n",
    "                                        padding = False,\n",
    "                                        return_attention_mask = False)\n",
    "        tokens = preprocessed_result[\"input_ids\"]\n",
    "        decoded_tokens = tokenizer.convert_ids_to_tokens(tokens)\n",
    "        for token in tokens:\n",
    "            if token not in all_tokens:\n",
    "                all_tokens.append(token)\n",
    "\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            if decoded_tokens[i].startswith('##'):\n",
    "                combined_word = decoded_tokens[i - 1] + decoded_tokens[i][2:]\n",
    "                word_lengths[tokens[i - 1]] = len(combined_word)\n",
    "                word_lengths[tokens[i]] = len(combined_word)\n",
    "            else:\n",
    "                word_lengths[tokens[i]] = len(decoded_tokens[i])\n",
    "            i += 1\n",
    "\n",
    "    assert len(all_tokens) == len(word_lengths), \"Association of tokens with word length : FAILED.\"\n",
    "\n",
    "    return word_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e993a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mario Mandzukic pounces to fire the ball past Jordan Pickford and put Croatia into the World Cup final', ' Photo: Reuters Independent', \"ie \\n \\nFormer England defender Gary Neville suggested Gareth Southgate's squad had done more than could have been expected of them at this World Cup as they bowed out with a semi-final defeat against Croatia\", ' \\n \\nhttps://www', 'independent', 'ie/sport/soccer/world-cup-2018/gary-neville-salutes-englands-overachievers-as-alan-shearer-and-rio-ferdinand-give-their-verdicts-37108667', 'html \\n \\nhttps://www', 'independent', 'ie/incoming/article37108634', 'ece/7571a/AUTOCROP/h342/52Man1', \"jpg \\n   Email     \\nFormer England defender Gary Neville suggested Gareth Southgate's squad had done more than could have been expected of them at this World Cup as they bowed out with a semi-final defeat against Croatia\", ' \\n  \\nA jaded England faded after had Kieran Trippier fired England ahead after just five minutes with a superb free-kick, with goals from Ivan Perisic and Mario Mandzukic earned Croatia a date with France after a 2-1 extra-time win in Moscow', ' \\n \\n\"The first thing to say is this team has taken us to a place we never imagined we could get,\" said Neville', ' \\n \\n\"I said before the tournament England never overachieve, this team has overachieved getting to the semi-final and they can all be absolutely proud', ' \\n \\n\"They have taken the nation with them', ' You see all the fans out in the park to see them', \" I never thought I'd see scenes like that in this World Cup\", ' \\n \\n\"They can be absolutely proud', ' We did say before the game these lads have to take this opportunity because it may never come again', ' \\n \\n\"All I hope as I look at them now crying, disappointed, upset is they get another opportunity as good as the one they\\'ve just had', '\" \\n \\n\"They\\'re the youngest team in the tournament', \" I hope they're in that position again, 1-0 up with 20 minutes to go with the opportunity of getting into a World Cup final\", '\" \\n  Croatia\\'s Dejan Lovren and Domagoj Vida celebrate after the match', \" Photo: Reuters   \\nFormer England defender Rio Ferdinand believes the youthful nature of England's squad proved to be their undoing in the semi-final\", ' \\n \\n\"I think experience was a telling factor today,\" Ferdinand told the BBC', ' \"This Croatian team had medals all over the squad but now is not the time to knitpick', \" This bunch of players have brought the nation together and the fans haven't sung like this for years\", ' \\n \\n\"We wanted this team to come out with an identity and a philosophy of playing, and I think they have done that', \" Where we were sat in the stadium, people around us were impressed with England's football and their ability to play out from the back\", ' \\n \\n\"Kieran Trippier\\'s delivery of the ball was brilliant and what a tournament he has had', ' There were question marks over Jordan Pickford but he was the best choice in goal and this team can develop into something very strong', ' I have been an admirer of John Stones for a long time, and he defended unbelievably today', ' We have got a very inexperienced young squad but they have grown and will continue to do so', '\" \\n \\nEx-England striker Alan Shearer also tried to find the positives amid England\\'s anguish', ' \\n \\n\"We said before the tournament that if they gave absolutely everything in every game, everyone at home would be happy,\" said Shearer', ' \\n \\n\"England got off to a very good start and dominated the first 45 minutes but Croatia stepped 10 yards further forward in the second half', ' \\n \\n\"Luka Modric bossed the midfield and we could not get near him with his deft touches and passes, he was superb and a man of the match performance, a vital cog for them', ' We lacked experience to get someone on him and stop him', ' Croatia did not panic when they fell behind', ' \\n \\n\"Kieran Trippier was brilliant in the tournament and so was Jordan Pickford, especially with his delivery', ' Harry Kane was a bit quiet in the knockout games and he had a chance that he could not put away \\n \\n\"So many positives to take out of the tournament, we did not expect to get to the quarters and will go home after this without heads held high', ' Finishing third would be excellent', ' Well done guys, you have given us plenty to shout about', '\" \\n \\nOnline Editors']\n",
      "[[7986, 2158, 2094, 24015, 2278, 13433, 17457, 2015, 2000, 2543, 1996, 3608, 2627, 5207, 4060, 3877, 1998, 2404, 8097, 2046, 1996, 2088, 2452, 2345], [6302, 1024, 26665, 2981], [29464, 2280, 2563, 8291, 5639, 14871, 4081, 20243, 2148, 5867, 1005, 1055, 4686, 2018, 2589, 2062, 2084, 2071, 2031, 2042, 3517, 1997, 2068, 2012, 2023, 2088, 2452, 2004, 2027, 11489, 2041, 2007, 1037, 4100, 1011, 2345, 4154, 2114, 8097], [16770, 1024, 1013, 1013, 7479], [2981], [29464, 1013, 4368, 1013, 4715, 1013, 2088, 1011, 2452, 1011, 2760, 1013, 5639, 1011, 14871, 1011, 17664, 2015, 1011, 2563, 2015, 1011, 2058, 21046, 22507, 2015, 1011, 2004, 1011, 5070, 1011, 18330, 2121, 1011, 1998, 1011, 5673, 1011, 9684, 1011, 2507, 1011, 2037, 1011, 14392, 2015, 1011, 4261, 10790, 20842, 2575, 2581], [16129, 16770, 1024, 1013, 1013, 7479], [2981], [29464, 1013, 14932, 1013, 3720, 24434, 10790, 20842, 22022], [14925, 2063, 1013, 4293, 2581, 2487, 2050, 1013, 8285, 26775, 7361, 1013, 1044, 22022, 2475, 1013, 4720, 2386, 2487], [16545, 2290, 10373, 2280, 2563, 8291, 5639, 14871, 4081, 20243, 2148, 5867, 1005, 1055, 4686, 2018, 2589, 2062, 2084, 2071, 2031, 2042, 3517, 1997, 2068, 2012, 2023, 2088, 2452, 2004, 2027, 11489, 2041, 2007, 1037, 4100, 1011, 2345, 4154, 2114, 8097], [1037, 12323, 2094, 2563, 8105, 2044, 2018, 11382, 23169, 4440, 14756, 2099, 5045, 2563, 3805, 2044, 2074, 2274, 2781, 2007, 1037, 21688, 2489, 1011, 5926, 1010, 2007, 3289, 2013, 7332, 2566, 17417, 2278, 1998, 7986, 2158, 2094, 24015, 2278, 3687, 8097, 1037, 3058, 2007, 2605, 2044, 1037, 1016, 1011, 1015, 4469, 1011, 2051, 2663, 1999, 4924], [1000, 1996, 2034, 2518, 2000, 2360, 2003, 2023, 2136, 2038, 2579, 2149, 2000, 1037, 2173, 2057, 2196, 8078, 2057, 2071, 2131, 1010, 1000, 2056, 14871], [1000, 1045, 2056, 2077, 1996, 2977, 2563, 2196, 2058, 21046, 18697, 1010, 2023, 2136, 2038, 2058, 21046, 18697, 2094, 2893, 2000, 1996, 4100, 1011, 2345, 1998, 2027, 2064, 2035, 2022, 7078, 7098], [1000, 2027, 2031, 2579, 1996, 3842, 2007, 2068], [2017, 2156, 2035, 1996, 4599, 2041, 1999, 1996, 2380, 2000, 2156, 2068], [1045, 2196, 2245, 1045, 1005, 1040, 2156, 5019, 2066, 2008, 1999, 2023, 2088, 2452], [1000, 2027, 2064, 2022, 7078, 7098], [2057, 2106, 2360, 2077, 1996, 2208, 2122, 29126, 2031, 2000, 2202, 2023, 4495, 2138, 2009, 2089, 2196, 2272, 2153], [1000, 2035, 1045, 3246, 2004, 1045, 2298, 2012, 2068, 2085, 6933, 1010, 9364, 1010, 6314, 2003, 2027, 2131, 2178, 4495, 2004, 2204, 2004, 1996, 2028, 2027, 1005, 2310, 2074, 2018], [1000, 1000, 2027, 1005, 2128, 1996, 6587, 2136, 1999, 1996, 2977], [1045, 3246, 2027, 1005, 2128, 1999, 2008, 2597, 2153, 1010, 1015, 1011, 1014, 2039, 2007, 2322, 2781, 2000, 2175, 2007, 1996, 4495, 1997, 2893, 2046, 1037, 2088, 2452, 2345], [1000, 8097, 1005, 1055, 2139, 8405, 8840, 12229, 2078, 1998, 14383, 23692, 3501, 19830, 8439, 2044, 1996, 2674], [6302, 1024, 26665, 2280, 2563, 8291, 5673, 9684, 7164, 1996, 22446, 3267, 1997, 2563, 1005, 1055, 4686, 4928, 2000, 2022, 2037, 25672, 2075, 1999, 1996, 4100, 1011, 2345], [1000, 1045, 2228, 3325, 2001, 1037, 4129, 5387, 2651, 1010, 1000, 9684, 2409, 1996, 4035], [1000, 2023, 7963, 2136, 2018, 6665, 2035, 2058, 1996, 4686, 2021, 2085, 2003, 2025, 1996, 2051, 2000, 22404, 24330, 2243], [2023, 9129, 1997, 2867, 2031, 2716, 1996, 3842, 2362, 1998, 1996, 4599, 4033, 1005, 1056, 7042, 2066, 2023, 2005, 2086], [1000, 2057, 2359, 2023, 2136, 2000, 2272, 2041, 2007, 2019, 4767, 1998, 1037, 4695, 1997, 2652, 1010, 1998, 1045, 2228, 2027, 2031, 2589, 2008], [2073, 2057, 2020, 2938, 1999, 1996, 3346, 1010, 2111, 2105, 2149, 2020, 7622, 2007, 2563, 1005, 1055, 2374, 1998, 2037, 3754, 2000, 2377, 2041, 2013, 1996, 2067], [1000, 11382, 23169, 4440, 14756, 2099, 1005, 1055, 6959, 1997, 1996, 3608, 2001, 8235, 1998, 2054, 1037, 2977, 2002, 2038, 2018], [2045, 2020, 3160, 6017, 2058, 5207, 4060, 3877, 2021, 2002, 2001, 1996, 2190, 3601, 1999, 3125, 1998, 2023, 2136, 2064, 4503, 2046, 2242, 2200, 2844], [1045, 2031, 2042, 2019, 19837, 2099, 1997, 2198, 6386, 2005, 1037, 2146, 2051, 1010, 1998, 2002, 8047, 4895, 8671, 2666, 3567, 6321, 2651], [2057, 2031, 2288, 1037, 2200, 26252, 2402, 4686, 2021, 2027, 2031, 4961, 1998, 2097, 3613, 2000, 2079, 2061], [1000, 4654, 1011, 2563, 11854, 5070, 18330, 2121, 2036, 2699, 2000, 2424, 1996, 3893, 2015, 13463, 2563, 1005, 1055, 21782], [1000, 2057, 2056, 2077, 1996, 2977, 2008, 2065, 2027, 2435, 7078, 2673, 1999, 2296, 2208, 1010, 3071, 2012, 2188, 2052, 2022, 3407, 1010, 1000, 2056, 18330, 2121], [1000, 2563, 2288, 2125, 2000, 1037, 2200, 2204, 2707, 1998, 6817, 1996, 2034, 3429, 2781, 2021, 8097, 3706, 2184, 4210, 2582, 2830, 1999, 1996, 2117, 2431], [1000, 11320, 2912, 16913, 7277, 5795, 2098, 1996, 23071, 1998, 2057, 2071, 2025, 2131, 2379, 2032, 2007, 2010, 13366, 2102, 12817, 1998, 5235, 1010, 2002, 2001, 21688, 1998, 1037, 2158, 1997, 1996, 2674, 2836, 1010, 1037, 8995, 2522, 2290, 2005, 2068], [2057, 10858, 3325, 2000, 2131, 2619, 2006, 2032, 1998, 2644, 2032], [8097, 2106, 2025, 6634, 2043, 2027, 3062, 2369], [1000, 11382, 23169, 4440, 14756, 2099, 2001, 8235, 1999, 1996, 2977, 1998, 2061, 2001, 5207, 4060, 3877, 1010, 2926, 2007, 2010, 6959], [4302, 8472, 2001, 1037, 2978, 4251, 1999, 1996, 11369, 2399, 1998, 2002, 2018, 1037, 3382, 2008, 2002, 2071, 2025, 2404, 2185, 1000, 2061, 2116, 3893, 2015, 2000, 2202, 2041, 1997, 1996, 2977, 1010, 2057, 2106, 2025, 5987, 2000, 2131, 2000, 1996, 7728, 1998, 2097, 2175, 2188, 2044, 2023, 2302, 4641, 2218, 2152], [5131, 2353, 2052, 2022, 6581], [2092, 2589, 4364, 1010, 2017, 2031, 2445, 2149, 7564, 2000, 11245, 2055], [1000, 3784, 10195]]\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_fn(x, tokenizer):\n",
    "    x[\"summary_ids\"] = tokenizer(\n",
    "        x[\"summary\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    x[\"text_ids\"] = tokenizer(\n",
    "        x[\"text\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    x[\"sentences_ids\"] = tokenizer(\n",
    "        x[\"sentences\"],\n",
    "        add_special_tokens = False,\n",
    "        truncation = True,\n",
    "        max_length = 512,\n",
    "        padding = False,\n",
    "        return_attention_mask = True,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    return x\n",
    "\n",
    "splitted_dataset = dataset.select_columns([\"summary\", \"text\", \"sentences\"])\n",
    "# print(splitted_dataset.__getitem__(0))\n",
    "\n",
    "word_lengths = get_word_lengths(splitted_dataset, tokenizer)\n",
    "\n",
    "# Tokenize the dataset\n",
    "splitted_dataset = splitted_dataset.map(\n",
    "    preprocessing_fn, tokenizer = tokenizer\n",
    ")\n",
    "print(splitted_dataset.__getitem__(0)[2])\n",
    "\n",
    "# Remove useless columns\n",
    "splitted_dataset = splitted_dataset.select_columns([\"summary_ids\", \"text_ids\", \"sentences_ids\"])\n",
    "print(splitted_dataset.__getitem__(0)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871c9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Get the tokenized sequences for each item in the batch\n",
    "    text_ids_batch = [torch.tensor(item[1], dtype = torch.int) for item in batch]\n",
    "    summary_ids_batch = [torch.tensor(item[0], dtype = torch.int) for item in batch]\n",
    "    sentences_ids_batch = [\n",
    "        [torch.tensor(sentence, dtype = torch.int) for sentence in item[2]]\n",
    "        for item in batch\n",
    "    ]\n",
    "\n",
    "    # Pad sequences to the maximum length in the batch\n",
    "    padded_text_ids = pad_sequence([torch.cat([item, torch.zeros(max(0, 512 - len(item)))]) for item in text_ids_batch], batch_first = True, padding_value = 0)\n",
    "    padded_summary_ids = pad_sequence([torch.cat([item, torch.zeros(max(0, 512 - len(item)))]) for item in summary_ids_batch], batch_first = True, padding_value = 0)\n",
    "    padded_sentences_ids = [\n",
    "        pad_sequence(\n",
    "            [torch.cat([sentence, torch.zeros(max(0, 512 - len(sentence)), dtype=torch.int)]) for sentence in item],\n",
    "            batch_first=True,\n",
    "            padding_value=0\n",
    "        )\n",
    "        for item in sentences_ids_batch\n",
    "    ]\n",
    "\n",
    "    return {\"text_ids\": padded_text_ids, \"summary_ids\": padded_summary_ids, \"sentences_ids\": padded_sentences_ids}\n",
    "\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(splitted_dataset, batch_size = batch_size, collate_fn = collate_fn)\n",
    "\n",
    "epochs = 3\n",
    "def training(summary, text, model, epochs = 10):\n",
    "    model_copy = copy.deepcopy(model)\n",
    "    model_copy.train()\n",
    "\n",
    "    summary = summary.unsqueeze(0)\n",
    "    text = text.unsqueeze(0)\n",
    "    if summary.size(1) != text.size(1):\n",
    "        raise RuntimeError(\"Sizes along the sequence length dimension must match.\")\n",
    "    \n",
    "    for epochs in range(epochs):\n",
    "        whole_input = torch.cat((summary, text), dim = 0).long()\n",
    "        outputs = model_copy(whole_input, labels = whole_input)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe719f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_BLANC_help(text, model, model_tuned, p_mask = 0.15, l_min = 4):\n",
    "    S = [[0, 0], [0, 0]]\n",
    "    \n",
    "    for sentence in text_sents:\n",
    "        sentence = word_tokenize(sentence)\n",
    "        for i in range(M):\n",
    "            masked_sentence = ''.join(['<MASK>' if (j - i) % M == 0 and len(sentence[j]) >= L_min else sentence[j] for j in range(len(sentence))])\n",
    "            input_base = filler + sep + masked_sentence\n",
    "            input_help = summary + sep + masked_sentence\n",
    "            tokenized_input_base = tokenizer(input_base, return_tensors='pt', max_length=512, padding='max_length', truncation=True).to(device)\n",
    "            tokenized_input_help = tokenizer(input_help, return_tensors='pt', max_length=512, padding='max_length', truncation=True).to(device)\n",
    "            out_base = model(**tokenized_input_base)\n",
    "            out_help = model(**tokenized_input_help)\n",
    "            masked_tokens = [idx for idx, word in enumerate(masked_sentence) if word == '<MASK>']\n",
    "\n",
    "            for j in masked_tokens:\n",
    "                k = int(out_base[j] == sentence[j])\n",
    "                m = int(out_help[j] == sentence[j])\n",
    "                S[k][m] += 1\n",
    "        break\n",
    "    try:\n",
    "      B = (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
    "    except ZeroDivisionError:\n",
    "      B = 0.0\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b978b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_ids': tensor([[ 7986.,  2158.,  2094.,  ...,  4100.,  1011.,  2345.],\n",
      "        [ 2005.,  1996.,  3822.,  ...,  2606., 11917.,  3737.],\n",
      "        [ 6264.,  1517.,  1996.,  ...,  2005.,  1996.,  2110.],\n",
      "        ...,\n",
      "        [ 5655., 16216., 19020.,  ..., 19723., 24454.,  3686.],\n",
      "        [ 1996.,  4501.,  2966.,  ..., 12763.,  3378.,  2007.],\n",
      "        [ 2062.,  2084.,  1002.,  ...,  2095.,  1011.,  2214.]]), 'summary_ids': tensor([[ 2280.,  2563.,  8291.,  ...,     0.,     0.,     0.],\n",
      "        [ 1048.,  1005., 10848.,  ...,     0.,     0.,     0.],\n",
      "        [ 2655., 21293.,  2100.,  ...,     0.,     0.,     0.],\n",
      "        ...,\n",
      "        [ 5655., 16216., 19020.,  ...,     0.,     0.,     0.],\n",
      "        [ 2151.,  6926.,  1010.,  ...,     0.,     0.,     0.],\n",
      "        [ 3533.,  7226.,  2368.,  ...,     0.,     0.,     0.]]), 'sentences_ids': [tensor([[ 7986,  2158,  2094,  ...,     0,     0,     0],\n",
      "        [ 6302,  1024, 26665,  ...,     0,     0,     0],\n",
      "        [29464,  2280,  2563,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 5131,  2353,  2052,  ...,     0,     0,     0],\n",
      "        [ 2092,  2589,  4364,  ...,     0,     0,     0],\n",
      "        [ 1000,  3784, 10195,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 2005,  1996,  3822,  ...,     0,     0,     0],\n",
      "        [ 1523,  1996,  2047,  ...,     0,     0,     0],\n",
      "        [ 1999,  2169,  2181,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2000, 13398,  2129,  ...,     0,     0,     0],\n",
      "        [ 1014,  1007,  1010,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 6264,  1517,  1996,  ...,     0,     0,     0],\n",
      "        [ 2023,  2733,  1010,  ...,     0,     0,     0],\n",
      "        [ 2005, 12455,  1999,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [18712,     0,     0,  ...,     0,     0,     0],\n",
      "        [18079,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 1000,  1045,  2228,  ...,     0,     0,     0],\n",
      "        [ 1000,  2008,  6251,  ...,     0,     0,     0],\n",
      "        [ 2021, 14103,  1010,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2431,  1011,  3606,  ...,     0,     0,     0],\n",
      "        [ 1000,  2023,  2466,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 1996,  2645,  1997,  ...,     0,     0,     0],\n",
      "        [ 2188,  2217,  9389,  ...,     0,     0,     0],\n",
      "        [ 2004,  2005,  8955,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 7861,  5162,  1998,  ...,     0,     0,     0],\n",
      "        [ 4895,  2072,  1060,  ...,     0,     0,     0],\n",
      "        [20950,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[16510,  2319,  8405,  ...,     0,     0,     0],\n",
      "        [ 1000,  2009,  2106,  ...,     0,     0,     0],\n",
      "        [ 3071,  2001, 17662,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1000,  3071,  2106,  ...,     0,     0,     0],\n",
      "        [ 2004,  2002,  7837,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 2000, 20462,  2169,  ...,     0,     0,     0],\n",
      "        [ 2720,  4027,  2003,  ...,     0,     0,     0],\n",
      "        [ 2720,  2214,  2075,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 4406,  1996,  2060,  ...,     0,     0,     0],\n",
      "        [ 2065,  2009,  9353,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 2009,  1005,  1055,  ...,     0,     0,     0],\n",
      "        [ 5696, 22452,  1010,  ...,     0,     0,     0],\n",
      "        [ 6733,  3242,  1999,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2021,  2023, 16819,  ...,     0,     0,     0],\n",
      "        [ 1996,  2613, 19728,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 7986,  2158,  2094,  ...,     0,     0,     0],\n",
      "        [ 6302,  1024, 26665,  ...,     0,     0,     0],\n",
      "        [29464,  2280,  2563,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 5131,  2353,  2052,  ...,     0,     0,     0],\n",
      "        [ 2092,  2589,  4364,  ...,     0,     0,     0],\n",
      "        [ 1000,  3784, 10195,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 2702,  1997,  1996,  ...,     0,     0,     0],\n",
      "        [ 1996,  2311,  2038,  ...,     0,     0,     0],\n",
      "        [ 2009,  2038,  2053,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2017,  2089, 16360,  ...,     0,     0,     0],\n",
      "        [ 3531,  2421,  1037,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[9295, 2402, 6238,  ...,    0,    0,    0],\n",
      "        [1000, 2017, 8688,  ...,    0,    0,    0],\n",
      "        [1000, 1996, 9295,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [5327, 2114, 3246,  ...,    0,    0,    0],\n",
      "        [3712, 6655, 2852,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]], dtype=torch.int32), tensor([[14408,  2953,  3007,  ...,     0,     0,     0],\n",
      "        [ 2038,  3133,  2046,  ...,     0,     0,     0],\n",
      "        [ 1999, 10388,  2007,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1075, 10476,  2064,  ...,     0,     0,     0],\n",
      "        [ 2035,  2916,  9235,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 1996,  5166,  5649,  ...,     0,     0,     0],\n",
      "        [ 2429,  2000, 15381,  ...,     0,     0,     0],\n",
      "        [ 1015,  1010, 11075,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2525,  1996,  3171,  ...,     0,     0,     0],\n",
      "        [ 2144,  1996,  3472,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 1999,  1996,  7579,  ...,     0,     0,     0],\n",
      "        [ 1010,  1002,  2321,  ...,     0,     0,     0],\n",
      "        [ 4406, 14537,  4674,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1998,  1999,  1037,  ...,     0,     0,     0],\n",
      "        [ 2138,  1997,  1996,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 5958,  1010, 11703,  ...,     0,     0,     0],\n",
      "        [ 9089,  2063,  2026,  ...,     0,     0,     0],\n",
      "        [ 1996,  2345,  6996,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2116,  2270,  1998,  ...,     0,     0,     0],\n",
      "        [ 5678,  1010,  2149,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 1996,  2645,  1997,  ...,     0,     0,     0],\n",
      "        [ 2188,  2217,  9389,  ...,     0,     0,     0],\n",
      "        [ 2004,  2005,  8955,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 7861,  5162,  1998,  ...,     0,     0,     0],\n",
      "        [ 4895,  2072,  1060,  ...,     0,     0,     0],\n",
      "        [20950,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 4923,  1024,  8909,  ...,     0,     0,     0],\n",
      "        [ 2651,  1010,  7513,  ...,     0,     0,     0],\n",
      "        [ 2070,  5621, 26233,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2035,  2008, 27566,  ...,     0,     0,     0],\n",
      "        [ 3693,  1996, 17178,  ...,     0,     0,     0],\n",
      "        [22073,  7513,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[17151, 11741, 12696,  ...,     0,     0,     0],\n",
      "        [ 1996, 21443,  3158,  ...,     0,     0,     0],\n",
      "        [ 1996,  2194,  4216,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2000,  5926,  2477,  ...,     0,     0,     0],\n",
      "        [ 1996,  2194,  2059,  ...,     0,     0,     0],\n",
      "        [ 3191,  1996,  2717,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 3539,  2704,  6583,  ...,     0,     0,     0],\n",
      "        [ 1523,  2634,  1521,  ...,     0,     0,     0],\n",
      "        [ 1523,  1045, 26478,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2634,  2038,  2048,  ...,     0,     0,     0],\n",
      "        [ 1037, 28283, 24413,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 1045,  2031,  1037,  ...,     0,     0,     0],\n",
      "        [ 1045,  1521,  1049,  ...,     0,     0,     0],\n",
      "        [ 2521,  2013,  2009,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 7149,  2007,  2769,  ...,     0,     0,     0],\n",
      "        [ 2009,  1521,  1055,  ...,     0,     0,     0],\n",
      "        [10958,  7507,  2884,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 2000, 20462,  2169,  ...,     0,     0,     0],\n",
      "        [ 2720,  4027,  2003,  ...,     0,     0,     0],\n",
      "        [ 2720,  2214,  2075,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 4406,  1996,  2060,  ...,     0,     0,     0],\n",
      "        [ 2065,  2009,  9353,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 1999,  2019,  3041,  ...,     0,     0,     0],\n",
      "        [ 2122,  1999,  2063,  ...,     0,     0,     0],\n",
      "        [ 2027,  2031,  3734,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 3568,  1010, 12786,  ...,     0,     0,     0],\n",
      "        [ 1996,  3213,  2003,  ...,     0,     0,     0],\n",
      "        [ 2405,  1999,  6440,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 5958,  1010, 11703,  ...,     0,     0,     0],\n",
      "        [ 9089,  2063,  2026,  ...,     0,     0,     0],\n",
      "        [ 1996,  2345,  6996,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2116,  2270,  1998,  ...,     0,     0,     0],\n",
      "        [ 5678,  1010,  2149,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 2004,  1996,  2451,  ...,     0,     0,     0],\n",
      "        [ 2111,  2024,  4815,  ...,     0,     0,     0],\n",
      "        [ 2174,  1010,  2007,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1528,  2196, 13354,  ...,     0,     0,     0],\n",
      "        [ 1528,  2735,  2068,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[17151, 11741, 12696,  ...,     0,     0,     0],\n",
      "        [ 1996, 21443,  3158,  ...,     0,     0,     0],\n",
      "        [ 1996,  2194,  4216,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2000,  5926,  2477,  ...,     0,     0,     0],\n",
      "        [ 1996,  2194,  2059,  ...,     0,     0,     0],\n",
      "        [ 3191,  1996,  2717,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 2057,  6160,  1996,  ...,     0,     0,     0],\n",
      "        [ 1996,  4539,  2003,  ...,     0,     0,     0],\n",
      "        [ 1996,  2693,  2003,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1999,  2023,  4044,  ...,     0,     0,     0],\n",
      "        [ 2027, 11276,  2000,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 1996, 10556,  8197,  ...,     0,     0,     0],\n",
      "        [ 1996,  3364,  2038,  ...,     0,     0,     0],\n",
      "        [ 2005,  1996,  4895,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1996,  3185,  4830,  ...,     0,     0,     0],\n",
      "        [ 1996, 13583, 19043,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 3744, 26447,  2003,  ...,     0,     0,     0],\n",
      "        [ 2426,  2216,  9085,  ...,     0,     0,     0],\n",
      "        [ 2016,  2453,  2031,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2522,     0,     0,  ...,     0,     0,     0],\n",
      "        [ 2866,  1010,  4214,  ...,     0,     0,     0],\n",
      "        [ 2062,  1024,  8958,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 2011,  2198, 20704,  ...,     0,     0,     0],\n",
      "        [ 2292,  1005,  1055,  ...,     0,     0,     0],\n",
      "        [ 1999,  1996,  2343,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2061,  2191,  2053,  ...,     0,     0,     0],\n",
      "        [ 2123,  1005,  1056,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 5655, 16216, 19020,  ...,     0,     0,     0],\n",
      "        [ 2008,  1005,  1055,  ...,     0,     0,     0],\n",
      "        [ 2005,  2062,  2592,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 1000,  2065,  1045,  ...,     0,     0,     0],\n",
      "        [ 1000,  2926,  2065,  ...,     0,     0,     0],\n",
      "        [ 1000,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 1996,  4501,  2966,  ...,     0,     0,     0],\n",
      "        [ 2151,  6926,  1010,  ...,     0,     0,     0],\n",
      "        [ 2027,  2056,  1999,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2027,  2036, 12068,  ...,     0,     0,     0],\n",
      "        [ 1005,  2057,  2036,  ...,     0,     0,     0],\n",
      "        [ 1005,     0,     0,  ...,     0,     0,     0]], dtype=torch.int32), tensor([[ 2062,  2084,  1002,  ...,     0,     0,     0],\n",
      "        [ 1523,  2009,  2001,  ...,     0,     0,     0],\n",
      "        [ 2062,  2084,  1002,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 7226,  2368,  3475,  ...,     0,     0,     0],\n",
      "        [ 5205, 18342, 16674,  ...,     0,     0,     0],\n",
      "        [ 9735,  2000,  1996,  ...,     0,     0,     0]], dtype=torch.int32)]}\n",
      "Summary 0 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "\n",
      "\n",
      "Elapsed Time: 7.626105546951294 seconds\n",
      "Summary 1 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n",
      "Elapsed Time: 6.819201231002808 seconds\n",
      "Summary 2 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n",
      "Elapsed Time: 7.377008676528931 seconds\n",
      "Summary 3 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "\n",
      "Elapsed Time: 7.52235221862793 seconds\n",
      "Summary 4 of batch\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def blanc_tune(summary, text, model, p_mask = 0.15, l_min = 4, N = 10, epochs = 10):\n",
    "    N_summary = len(summary)\n",
    "    N_mask = int(N_summary*p_mask)\n",
    "    set_tune = pd.DataFrame(columns = ['summary', 'text'])\n",
    "\n",
    "    for j in range(0, N):\n",
    "        print(j)\n",
    "        pos = [i for i, token in enumerate(summary.tolist()) if token in word_lengths and word_lengths[token] >= l_min]\n",
    "        random.shuffle(pos)\n",
    "        while len(pos) != 0:\n",
    "            masked_summary = summary.tolist().copy()\n",
    "            for pos_to_mask in pos[:N_mask]:\n",
    "                masked_summary[pos_to_mask] = '<MASK>'\n",
    "                set_tune.loc[set_tune.shape[0]] = [masked_summary, text]\n",
    "            pos = pos[N_mask:]\n",
    "\n",
    "    model_tuned = training(summary, text, model, epochs)\n",
    "    print('\\n')      \n",
    "    return model_tuned\n",
    "\n",
    "def blanc_tune_batch(batch, model, p_mask = 0.15, l_min = 4, N = 10, epochs = 10):\n",
    "    batch_tuned_models = []\n",
    "    \n",
    "    i = 0\n",
    "    for summary, text in zip(batch['summary_ids'], batch['text_ids']):\n",
    "        print(f\"Summary {i} of batch\")\n",
    "        i += 1\n",
    "        start_time = time.time()\n",
    "        tuned_model = blanc_tune(summary, text, model, p_mask, l_min, N, epochs)\n",
    "        end_time = time.time()\n",
    "        batch_tuned_models.append(tuned_model)\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "    return batch_tuned_models\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    tuned_models = blanc_tune_batch(batch, model, epochs = epochs)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "collabfiltering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
