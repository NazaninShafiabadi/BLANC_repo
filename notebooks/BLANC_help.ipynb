{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bljHOyIaeuP0"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install datasets\n",
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P8tU6_dY9yu",
        "outputId": "31a779b9-f62c-4ec8-c9a7-3784c750eb42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\clara\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import nltk\n",
        "import asyncio\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from datasets import load_dataset\n",
        "from tqdm.notebook import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "# The models the authors used:\n",
        "from transformers import BertForMaskedLM, BertTokenizer, BertModel\n",
        "from transformers import AlbertForMaskedLM, AlbertTokenizer\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAZUT7rXMBeO",
        "outputId": "a9ee9d19-56a4-4d4b-f2a4-7f5004520879"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mask_sentence(sentence, mask_token, i, M, L_min):\n",
        "    return [mask_token\n",
        "            if (j - i) % M == 0\n",
        "            and (len(sentence[j]) >= L_min\n",
        "                 or sentence[j].startswith('##')\n",
        "                 or sentence[min(j+1, len(sentence)-1)].startswith('##'))\n",
        "            else sentence[j]\n",
        "            for j in range(len(sentence))]\n",
        "\n",
        "def no_copy_guard(sentence, summary):\n",
        "    sentence = ' '.join(sentence)\n",
        "    summary = ' '.join(summary)\n",
        "    return sentence in summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def BLANC_help(text, summary, model, tokenizer, M=6, L_min=4, sep='[SEP]', device='cpu', word_sim_model = None):\n",
        "    \"\"\"\n",
        "    Calculates BLANC score between a given text and its summary using a specified model.\n",
        "\n",
        "    Parameters:\n",
        "    - text (List[List[str]]): List of sentences represented as a list of tokens.\n",
        "    - summary (List[str]): The tokenized summary of the text.\n",
        "    - model: BERT-type model\n",
        "    - tokenizer: The tokenizer associated with the model used.\n",
        "    - M (int): Parameter M for the algorithm (default is 6).\n",
        "    - L_min (int): Minimum length requirement for masked words (default is 4).\n",
        "    - sep (str): Separator between the inference help (filler/summary) and a sentence from the text (default is '[SEP]').\n",
        "\n",
        "    Returns:\n",
        "    - float: BLANC score for the given text and its summary.\n",
        "    \"\"\"\n",
        "\n",
        "    filler = ['.'] * len(summary)\n",
        "    S = [[0, 0], [0, 0]]\n",
        "\n",
        "    score = 0\n",
        "\n",
        "    for sentence in text:\n",
        "        if no_copy_guard(sentence, summary): \n",
        "           continue\n",
        "        for i in range(M):\n",
        "            masked_sentence = mask_sentence(sentence, tokenizer.mask_token, i, M, L_min)\n",
        "\n",
        "            input_base = filler + [sep] + masked_sentence\n",
        "            input_help = summary + [sep] + masked_sentence\n",
        "\n",
        "            tokenized_input_base = torch.tensor(tokenizer.convert_tokens_to_ids(input_base)).to(device) # Shape: [sequence_length]\n",
        "            tokenized_input_help = torch.tensor(tokenizer.convert_tokens_to_ids(input_help)).to(device) # Shape: [sequence_length]\n",
        "            with torch.no_grad():\n",
        "                out_base = model(input_ids=tokenized_input_base.unsqueeze(0)).logits  # Shape: [1, sequence_length, Bert_vocab_size]\n",
        "                out_help = model(input_ids=tokenized_input_help.unsqueeze(0)).logits  # Shape: [1, sequence_length, Bert_vocab_size]\n",
        "\n",
        "            out_base = torch.argmax(out_base.squeeze(0), dim=-1)  # Shape: [sequence_length]\n",
        "            out_help = torch.argmax(out_help.squeeze(0), dim=-1)  # Shape: [sequence_length]\n",
        "\n",
        "            masked_tokens = [idx for idx, word in enumerate(masked_sentence) if word == tokenizer.mask_token]\n",
        "\n",
        "            for j in masked_tokens:\n",
        "                idx = len(summary + [sep]) + j\n",
        "                predicted_word_base = tokenizer.convert_ids_to_tokens(out_base[idx].item())\n",
        "                predicted_word_help = tokenizer.convert_ids_to_tokens(out_help[idx].item())\n",
        "\n",
        "                if word_sim_model is not None:\n",
        "                    predicted_sentence_base = tokenizer.convert_tokens_to_ids(masked_sentence)\n",
        "                    predicted_sentence_base[j] = out_base[idx].item()\n",
        "\n",
        "                    predicted_sentence_help = tokenizer.convert_tokens_to_ids(masked_sentence)\n",
        "                    predicted_sentence_help[j] = out_help[idx].item()\n",
        "\n",
        "                    predicted_sentence_base_tensor = torch.tensor([predicted_sentence_base]).to(device)\n",
        "                    predicted_sentence_help_tensor = torch.tensor([predicted_sentence_help]).to(device)\n",
        "\n",
        "                    tokenized_sentence = masked_sentence.copy()\n",
        "                    tokenized_sentence[j] = sentence[j]\n",
        "                    tokenized_sentence = tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "                    tokenized_sentence_tensor = torch.tensor([tokenized_sentence]).to(device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        predicted_sentence_base_embedding = word_sim_model(predicted_sentence_base_tensor).last_hidden_state[0, j, :]\n",
        "                        predicted_sentence_help_embedding = word_sim_model(predicted_sentence_help_tensor).last_hidden_state[0, j, :]\n",
        "                        correct_embedding = word_sim_model(tokenized_sentence_tensor).last_hidden_state[0, j, :]\n",
        "\n",
        "                    cos_sim = torch.nn.CosineSimilarity(dim=0)\n",
        "                    \n",
        "                    sim_base = cos_sim(predicted_sentence_base_embedding, correct_embedding)\n",
        "                    sim_help = cos_sim(predicted_sentence_help_embedding, correct_embedding)\n",
        "\n",
        "                    k = int(predicted_word_base == sentence[j])\n",
        "                    m = int(predicted_word_help == sentence[j])\n",
        "                    S[k][m] += 1\n",
        "\n",
        "                    score += sim_help - sim_base\n",
        "                    \"\"\"print(tokenizer.convert_ids_to_tokens(predicted_sentence_base_tensor[0]),\n",
        "                          tokenizer.convert_ids_to_tokens(predicted_sentence_help_tensor[0]),\n",
        "                          tokenizer.convert_ids_to_tokens(tokenized_sentence_tensor[0]), sep=\"\\n\")\n",
        "                    print(k, m, sim_base.item(), sim_help.item())\"\"\"\n",
        "\n",
        "                else:\n",
        "                \n",
        "                    \"\"\"print(f'predicted_word_base[{idx - len(summary + [sep])}]: {predicted_word_base}')\n",
        "                    print(f'predicted_word_help[{idx - len(summary + [sep])}]: {predicted_word_help}')\n",
        "                    print(f'sentence[{j}]: {sentence[j]}')\"\"\"\n",
        "\n",
        "                    k = int(predicted_word_base == sentence[j])\n",
        "                    m = int(predicted_word_help == sentence[j])\n",
        "                    S[k][m] += 1\n",
        "\n",
        "\n",
        "    B = (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
        "\n",
        "    return B, score / (S[0][0] + S[1][1] + S[0][1] + S[1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def BLANC_help_optimized(text, summary, model, tokenizer, M=6, L_min=4, sep='[SEP]', device='cpu', word_sim_model=None):\n",
        "    \"\"\"\n",
        "    Optimized version of the BLANC_help function for calculating BLANC score.\n",
        "    \"\"\"\n",
        "\n",
        "    filler = ['.'] * len(summary)\n",
        "    S = [[0, 0], [0, 0]]\n",
        "    score = 0\n",
        "\n",
        "    # Batch preparation for model inference\n",
        "    base_inputs = []\n",
        "    help_inputs = []\n",
        "    attention_masks_base = []\n",
        "    attention_masks_help = []\n",
        "\n",
        "    # Precompute and store tokenized summary and separator\n",
        "    tokenized_summary = tokenizer.convert_tokens_to_ids(summary)\n",
        "    tokenized_sep = tokenizer.convert_tokens_to_ids([sep])\n",
        "    tokenized_filler = tokenizer.convert_tokens_to_ids(filler)\n",
        "    max_length = 0\n",
        "\n",
        "    batch_sentences = []\n",
        "    masked_tokens_batch = []\n",
        "\n",
        "    for sentence in text:\n",
        "        if no_copy_guard(sentence, summary): \n",
        "            continue\n",
        "        for i in range(M):\n",
        "            masked_sentence = mask_sentence(sentence, tokenizer.mask_token, i, M, L_min)\n",
        "            masked_sentence_ids = tokenizer.convert_tokens_to_ids(masked_sentence)\n",
        "\n",
        "            input_base = tokenized_filler + tokenized_sep + masked_sentence_ids\n",
        "            input_help = tokenized_summary + tokenized_sep + masked_sentence_ids\n",
        "\n",
        "            base_inputs.append(input_base)\n",
        "            help_inputs.append(input_help)\n",
        "\n",
        "            attention_masks_base.append([1] * len(input_base))\n",
        "            attention_masks_help.append([1] * len(input_help))\n",
        "\n",
        "            # Track the maximum length\n",
        "            max_length = max(max_length, len(input_base), len(input_help))\n",
        "\n",
        "            masked_tokens_batch.append([idx for idx, word in enumerate(masked_sentence_ids) if word == tokenizer.mask_token_id])\n",
        "\n",
        "            batch_sentences.append(tokenizer.convert_tokens_to_ids(sentence))\n",
        "\n",
        "    # Pad the sequences and convert to tensors\n",
        "    base_inputs_tensor = torch.stack([torch.nn.functional.pad(torch.tensor(seq), (0, max_length - len(seq)), value=tokenizer.pad_token_id) for seq in base_inputs]).to(device)\n",
        "    help_inputs_tensor = torch.stack([torch.nn.functional.pad(torch.tensor(seq), (0, max_length - len(seq)), value=tokenizer.pad_token_id) for seq in help_inputs]).to(device)\n",
        "    attention_mask_base_tensor = torch.stack([torch.nn.functional.pad(torch.tensor(mask), (0, max_length - len(mask))) for mask in attention_masks_base]).to(device)\n",
        "    attention_mask_help_tensor = torch.stack([torch.nn.functional.pad(torch.tensor(mask), (0, max_length - len(mask))) for mask in attention_masks_help]).to(device)\n",
        "\n",
        "    # Model inference in batches with attention masks\n",
        "    with torch.no_grad():\n",
        "        out_base = model(input_ids=base_inputs_tensor, attention_mask=attention_mask_base_tensor).logits\n",
        "        out_help = model(input_ids=help_inputs_tensor, attention_mask=attention_mask_help_tensor).logits\n",
        "\n",
        "    out_base = torch.argmax(out_base.squeeze(0), dim=-1)\n",
        "    out_help = torch.argmax(out_help.squeeze(0), dim=-1)\n",
        "    print(out_base.shape)\n",
        "\n",
        "    # Iterate through the batches\n",
        "    for b_idx in range(len(base_inputs)):\n",
        "        out_base_batch = out_base[b_idx]\n",
        "        out_help_batch = out_help[b_idx]\n",
        "        for j in masked_tokens_batch[b_idx]:\n",
        "            idx = len(tokenized_summary) + 1 + j\n",
        "            predicted_word_base = out_base_batch[idx].item()\n",
        "            predicted_word_help = out_help_batch[idx].item()\n",
        "\n",
        "            # Rest of your logic here...\n",
        "            # Make sure to adjust indexing and access according to batch processing\n",
        "            \"\"\"print(f'predicted_word_base[{idx - len(summary + [sep])}]: {tokenizer.convert_ids_to_tokens(predicted_word_base)}')\n",
        "            print(f'predicted_word_help[{idx - len(summary + [sep])}]: {tokenizer.convert_ids_to_tokens(predicted_word_help)}')\n",
        "            print(f'sentence[{j}]: {tokenizer.convert_ids_to_tokens(batch_sentences[b_idx][j])}')\"\"\"\n",
        "\n",
        "            k = int(predicted_word_base == batch_sentences[b_idx][j])\n",
        "            m = int(predicted_word_help == batch_sentences[b_idx][j])\n",
        "            S[k][m] += 1\n",
        "\n",
        "    B = (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
        "\n",
        "    return B, score / (S[0][0] + S[1][1] + S[0][1] + S[1][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o_Wn0bSqeTAk"
      },
      "outputs": [],
      "source": [
        "# cnn_dailymail_ds = load_dataset(\"cnn_dailymail\", '3.0.0', split='test')\n",
        "# print(cnn_dailymail_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "e99d05b19a5c4138aca173d07660e957",
            "9446b067785c415ab3c595ef2710d1de",
            "a15dcd5f78fb41a3b3d6de0fedaa1184",
            "30187123bedc4d6c9ffadaa1dab27a82",
            "f015814a7f6b4a89a9f75827de143256",
            "253c5509188b44c7ab8aa1f6ea2003d1",
            "0a0e36b6cfca42d89bac31eae8d6b605",
            "6205a3c6d99e450e95bf035a8d07d56e",
            "712370bf3c4b469c99e77514335fcd6d",
            "192fb41a76b94130b6299197c719b70c",
            "4fbb29aac32b477ba98645fd25680ca6"
          ]
        },
        "id": "9tmYbuTDg7Yh",
        "outputId": "d250dd69-b767-4476-a19e-6c69d5f9520a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['summary', 'text', 'scores', 'annotators_ids'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DailyNews_ds = load_dataset('json', data_files='../datasets/DailyNews_300.json', split='train')\n",
        "DailyNews_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "01z4jmL7Y9yy",
        "outputId": "8e872475-a3e5-4d77-ad19-62b42da57d0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased').to(DEVICE)\n",
        "word_sim_model = BertModel.from_pretrained('bert-base-uncased').to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fNs_l53IB5nz"
      },
      "outputs": [],
      "source": [
        "summaries = DailyNews_ds['summary'] # (List[str])\n",
        "texts = DailyNews_ds['text']  # (List[str]) each string is a paragraph made of a few sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Zcf_roESB_bb"
      },
      "outputs": [],
      "source": [
        "# each text in texts is a list of sentences (each sentence is a string)\n",
        "texts = [sent_tokenize(text.strip()) for text in texts] # List[List[str]]\n",
        "assert len(texts) == len(summaries) == 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zTEaHWPkCIht"
      },
      "outputs": [],
      "source": [
        "tokenized_texts = [[tokenizer.tokenize(sentence) for sentence in text] for text in texts]\n",
        "tokenized_summaries = [tokenizer.tokenize(summary) for summary in summaries]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHOsrrWZLsDj",
        "outputId": "2d74612c-e08b-41b9-b049-22834209b47e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([216, 263])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.11069418386491557, 0.0)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BLANC_help_optimized(tokenized_texts[0], tokenized_summaries[0], model, tokenizer, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.11069418386491557, 0.0)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BLANC_help(tokenized_texts[0], tokenized_summaries[0], model, tokenizer, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7ec00d0734c94561a0a97be0f2de3f4a",
            "77eb02b005c84784abc8c26119c73b7e",
            "8a71567152674946b7192f06f7338e21",
            "27d4ab6496f5415db5dff0a992f83c97",
            "235fc9caede94554a858295dd4647d56",
            "f52a45e839564994b6183ab6245dd241",
            "e4e4fcb188a24acd904daa23caf38d79",
            "b571a574e58540bd87d7419f224fadbb",
            "0229065e07544c79ab4741e0077a1383",
            "dcb73195ff8e4f4582519743df4b45bb",
            "5771a9b761dc42bdb475bba3f511f42c"
          ]
        },
        "id": "5XG1Cuo7LvO8",
        "outputId": "5faa3d1d-db1a-4e69-bb91-9f34e6b155b8"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m scores \u001b[38;5;241m=\u001b[39m [BLANC_help(text, summary, model, tokenizer, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m----> 2\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m summary, text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenized_summaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenized_texts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m      3\u001b[0m scores\n",
            "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\tqdm\\notebook.py:238\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    237\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\clara\\anaconda3\\envs\\LLM\\Lib\\site-packages\\tqdm\\notebook.py:113\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    115\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
            "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
          ]
        }
      ],
      "source": [
        "scores = [BLANC_help(text, summary, model, tokenizer, device=DEVICE)\n",
        "          for summary, text in tqdm(zip(tokenized_summaries, tokenized_texts))]\n",
        "scores"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0229065e07544c79ab4741e0077a1383": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a0e36b6cfca42d89bac31eae8d6b605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "192fb41a76b94130b6299197c719b70c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235fc9caede94554a858295dd4647d56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253c5509188b44c7ab8aa1f6ea2003d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d4ab6496f5415db5dff0a992f83c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcb73195ff8e4f4582519743df4b45bb",
            "placeholder": "​",
            "style": "IPY_MODEL_5771a9b761dc42bdb475bba3f511f42c",
            "value": " 300/? [21:10&lt;00:00,  3.39s/it]"
          }
        },
        "30187123bedc4d6c9ffadaa1dab27a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_192fb41a76b94130b6299197c719b70c",
            "placeholder": "​",
            "style": "IPY_MODEL_4fbb29aac32b477ba98645fd25680ca6",
            "value": " 300/0 [00:00&lt;00:00, 3685.04 examples/s]"
          }
        },
        "4fbb29aac32b477ba98645fd25680ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5771a9b761dc42bdb475bba3f511f42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6205a3c6d99e450e95bf035a8d07d56e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "712370bf3c4b469c99e77514335fcd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77eb02b005c84784abc8c26119c73b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52a45e839564994b6183ab6245dd241",
            "placeholder": "​",
            "style": "IPY_MODEL_e4e4fcb188a24acd904daa23caf38d79",
            "value": ""
          }
        },
        "7ec00d0734c94561a0a97be0f2de3f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77eb02b005c84784abc8c26119c73b7e",
              "IPY_MODEL_8a71567152674946b7192f06f7338e21",
              "IPY_MODEL_27d4ab6496f5415db5dff0a992f83c97"
            ],
            "layout": "IPY_MODEL_235fc9caede94554a858295dd4647d56"
          }
        },
        "8a71567152674946b7192f06f7338e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b571a574e58540bd87d7419f224fadbb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0229065e07544c79ab4741e0077a1383",
            "value": 1
          }
        },
        "9446b067785c415ab3c595ef2710d1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_253c5509188b44c7ab8aa1f6ea2003d1",
            "placeholder": "​",
            "style": "IPY_MODEL_0a0e36b6cfca42d89bac31eae8d6b605",
            "value": "Generating train split: "
          }
        },
        "a15dcd5f78fb41a3b3d6de0fedaa1184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6205a3c6d99e450e95bf035a8d07d56e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_712370bf3c4b469c99e77514335fcd6d",
            "value": 1
          }
        },
        "b571a574e58540bd87d7419f224fadbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dcb73195ff8e4f4582519743df4b45bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e4fcb188a24acd904daa23caf38d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e99d05b19a5c4138aca173d07660e957": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9446b067785c415ab3c595ef2710d1de",
              "IPY_MODEL_a15dcd5f78fb41a3b3d6de0fedaa1184",
              "IPY_MODEL_30187123bedc4d6c9ffadaa1dab27a82"
            ],
            "layout": "IPY_MODEL_f015814a7f6b4a89a9f75827de143256"
          }
        },
        "f015814a7f6b4a89a9f75827de143256": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52a45e839564994b6183ab6245dd241": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
