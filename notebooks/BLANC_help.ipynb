{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nazanin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# The models the authors used:\n",
    "try:\n",
    "    from transformers import BertForMaskedLM, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "    from transformers import AlbertForMaskedLM, AlbertTokenizer\n",
    "except ModuleNotFoundError:\n",
    "    %pip install transformers\n",
    "    from transformers import BertForMaskedLM, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "    from transformers import AlbertForMaskedLM, AlbertTokenizer\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json('./datasets/DailyNews_300.json')\n",
    "summary = dataset.iloc[0,2]\n",
    "text = dataset.iloc[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLANC_help(summary, text, model, M=6, L_min=4, sep=' '):\n",
    "    \"\"\"\n",
    "    Calculate BLANC similarity between summary and text using a specified model.\n",
    "\n",
    "    Parameters:\n",
    "    - summary (str): The summary text.\n",
    "    - text (List[List[str]]): List of sentences represented as a list of words.\n",
    "    - model: BERT model type\n",
    "    - M (int): Parameter M for the algorithm (default is 6).\n",
    "    - L_min (int): Minimum length requirement for masked words (default is 4).\n",
    "    - sep (str): Separator between the inference help (filler/summary) and a sentence from the text (default is '').\n",
    "\n",
    "    Returns:\n",
    "    - float: BLANC similarity score.\n",
    "    \"\"\"\n",
    "    \n",
    "    text_sents = sent_tokenize(text)\n",
    "\n",
    "    filler = '.' * len(summary)\n",
    "    S = [[0, 0], [0, 0]]\n",
    "\n",
    "    for sentence in text_sents:\n",
    "        for i in range(1, M + 1):\n",
    "            masked_sentence = ''.join(['<MASK>' if (j - i) % M == 0 and len(sentence[j]) >= L_min else sentence[j] for j in range(len(sentence))])\n",
    "            print(masked_sentence)\n",
    "            input_base = filler + sep + masked_sentence\n",
    "            input_help = summary + sep + masked_sentence\n",
    "            tokenized_input_base = tokenizer(input_base, return_tensors='pt', max_length=512, padding='max_length', truncation=True).to(device)\n",
    "            tokenized_input_help = tokenizer(input_help, return_tensors='pt', max_length=512, padding='max_length', truncation=True).to(device)\n",
    "            out_base = model(**tokenized_input_base)\n",
    "            out_help = model(**tokenized_input_help)\n",
    "            masked_tokens = [idx for idx, word in enumerate(masked_sentence) if word == '<MASK>']\n",
    "\n",
    "            for j in masked_tokens:\n",
    "                k = int(out_base[j] == sentence[j])\n",
    "                m = int(out_help[j] == sentence[j])\n",
    "                S[k][m] += 1\n",
    "        break\n",
    "\n",
    "    try:\n",
    "      B = (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
    "    except ZeroDivisionError:\n",
    "      B = 0.0\n",
    "    \n",
    "    return B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mario Mandzukic pounces to fire the ball past Jordan Pickford and put Croatia into the World Cup final.\n",
      "Mario Mandzukic pounces to fire the ball past Jordan Pickford and put Croatia into the World Cup final.\n",
      "Mario Mandzukic pounces to fire the ball past Jordan Pickford and put Croatia into the World Cup final.\n",
      "Mario Mandzukic pounces to fire the ball past Jordan Pickford and put Croatia into the World Cup final.\n",
      "Mario Mandzukic pounces to fire the ball past Jordan Pickford and put Croatia into the World Cup final.\n",
      "Mario Mandzukic pounces to fire the ball past Jordan Pickford and put Croatia into the World Cup final.\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "acc = BLANC_help(summary, text, model)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for improvement:\n",
    "1. add error handling to ensure that the input to the function (summary, text, model) are of the expected types or shapes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BLANC_repo-_IGNgo0f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
