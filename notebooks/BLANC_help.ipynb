{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-1.26.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nazanin/.local/share/virtualenvs/BLANC_repo-_IGNgo0f/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests (from transformers)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Using cached tokenizers-0.15.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.2-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Using cached PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl (165 kB)\n",
      "Downloading regex-2023.12.25-cp312-cp312-macosx_11_0_arm64.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.1-cp312-cp312-macosx_11_0_arm64.whl (425 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.2/425.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.15.0-cp312-cp312-macosx_11_0_arm64.whl (2.5 MB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl (119 kB)\n",
      "Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2023.11.17 charset-normalizer-3.3.2 filelock-3.13.1 fsspec-2023.12.2 huggingface-hub-0.20.1 idna-3.6 numpy-1.26.2 pyyaml-6.0.1 regex-2023.12.25 requests-2.31.0 safetensors-0.4.1 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.36.2 typing-extensions-4.9.0 urllib3-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nazanin/.local/share/virtualenvs/BLANC_repo-_IGNgo0f/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "# The models the authors used:\n",
    "try:\n",
    "    from transformers import BertForMaskedLM, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "    from transformers import AlbertForMaskedLM, AlbertTokenizer\n",
    "except ModuleNotFoundError:\n",
    "    %pip install transformers\n",
    "    from transformers import BertForMaskedLM, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "    from transformers import AlbertForMaskedLM, AlbertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLANC_help(summary, text, model, M=6, L_min=4, sep=''):\n",
    "    \"\"\"\n",
    "    Calculate BLANC similarity between summary and text using a specified model.\n",
    "\n",
    "    Parameters:\n",
    "    - summary (str): The summary text.\n",
    "    - text (List[List[str]]): List of sentences represented as a list of words.\n",
    "    - model: BERT model type\n",
    "    - M (int): Parameter M for the algorithm (default is 6).\n",
    "    - L_min (int): Minimum length requirement for masked words (default is 4).\n",
    "    - sep (str): Separator between the inference help (filler/summary) and a sentence from the text (default is '').\n",
    "\n",
    "    Returns:\n",
    "    - float: BLANC similarity score.\n",
    "    \"\"\"\n",
    "\n",
    "    filler = '.' * len(summary)\n",
    "    S = [[0, 0], [0, 0]]\n",
    "\n",
    "    for sentence in text:\n",
    "        for i in range(1, M + 1):\n",
    "            masked_sentence = ['<MASK>' if (j - i) % M == 0 and len(sentence[j]) >= L_min else sentence[j] \n",
    "                        for j in range(len(sentence))]\n",
    "            input_base = filler + sep + masked_sentence\n",
    "            input_help = summary + sep + masked_sentence\n",
    "            out_base = model(input_base)\n",
    "            out_help = model(input_help)\n",
    "            masked_tokens = [idx for idx, word in enumerate(masked_sentence) if word == '<MASK>']\n",
    "\n",
    "            for j in masked_tokens:\n",
    "                k = int(out_base[j] == sentence[j])\n",
    "                m = int(out_help[j] == sentence[j])\n",
    "                S[k][m] += 1\n",
    "\n",
    "    return (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for improvement:\n",
    "1. add error handling to ensure that the input to the function (summary, text, model) are of the expected types or shapes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BLANC_repo-_IGNgo0f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
