{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bljHOyIaeuP0"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install datasets\n",
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P8tU6_dY9yu",
        "outputId": "31a779b9-f62c-4ec8-c9a7-3784c750eb42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\clara\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import nltk\n",
        "import asyncio\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from datasets import load_dataset\n",
        "from tqdm.notebook import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "# The models the authors used:\n",
        "from transformers import BertForMaskedLM, BertTokenizer, BertModel\n",
        "from transformers import AlbertForMaskedLM, AlbertTokenizer\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAZUT7rXMBeO",
        "outputId": "a9ee9d19-56a4-4d4b-f2a4-7f5004520879"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mask_sentence(sentence, mask_token, i, M, L_min):\n",
        "    return [mask_token\n",
        "            if (j - i) % M == 0\n",
        "            and (len(sentence[j]) >= L_min\n",
        "                 or sentence[j].startswith('##')\n",
        "                 or sentence[min(j+1, len(sentence)-1)].startswith('##'))\n",
        "            else sentence[j]\n",
        "            for j in range(len(sentence))]\n",
        "\n",
        "def no_copy_guard(sentence, summary):\n",
        "    sentence = ' '.join(sentence)\n",
        "    summary = ' '.join(summary)\n",
        "    return sentence in summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def BLANC_help(text, summary, model, tokenizer, M=6, L_min=4, sep='[SEP]', device='cpu', word_sim_model = None):\n",
        "    \"\"\"\n",
        "    Calculates BLANC score between a given text and its summary using a specified model.\n",
        "\n",
        "    Parameters:\n",
        "    - text (List[List[str]]): List of sentences represented as a list of tokens.\n",
        "    - summary (List[str]): The tokenized summary of the text.\n",
        "    - model: BERT-type model\n",
        "    - tokenizer: The tokenizer associated with the model used.\n",
        "    - M (int): Parameter M for the algorithm (default is 6).\n",
        "    - L_min (int): Minimum length requirement for masked words (default is 4).\n",
        "    - sep (str): Separator between the inference help (filler/summary) and a sentence from the text (default is '[SEP]').\n",
        "\n",
        "    Returns:\n",
        "    - float: BLANC score for the given text and its summary.\n",
        "    \"\"\"\n",
        "\n",
        "    filler = ['.'] * len(summary)\n",
        "    S = [[0, 0], [0, 0]]\n",
        "\n",
        "    score = torch.zeros(1).to(device)[0]\n",
        "\n",
        "    for sentence in text:\n",
        "        if no_copy_guard(sentence, summary): \n",
        "           continue\n",
        "        for i in range(M):\n",
        "            masked_sentence = mask_sentence(sentence, tokenizer.mask_token, i, M, L_min)\n",
        "\n",
        "            input_base = filler + [sep] + masked_sentence\n",
        "            input_help = summary + [sep] + masked_sentence\n",
        "\n",
        "            tokenized_input_base = torch.tensor(tokenizer.convert_tokens_to_ids(input_base)).to(device) # Shape: [sequence_length]\n",
        "            tokenized_input_help = torch.tensor(tokenizer.convert_tokens_to_ids(input_help)).to(device) # Shape: [sequence_length]\n",
        "            with torch.no_grad():\n",
        "                input_stacked = torch.stack((tokenized_input_base, tokenized_input_help))\n",
        "                out_stacked = model(input_ids=input_stacked).logits  # Shape: [1, sequence_length, Bert_vocab_size]\n",
        "                out_base = out_stacked[0]\n",
        "                out_help = out_stacked[1]\n",
        "\n",
        "            out_base = torch.argmax(out_base.squeeze(0), dim=-1)  # Shape: [sequence_length]\n",
        "            out_help = torch.argmax(out_help.squeeze(0), dim=-1)  # Shape: [sequence_length]\n",
        "\n",
        "            masked_tokens = [idx for idx, word in enumerate(masked_sentence) if word == tokenizer.mask_token]\n",
        "\n",
        "            for j in masked_tokens:\n",
        "                idx = len(summary + [sep]) + j\n",
        "                predicted_word_base = tokenizer.convert_ids_to_tokens(out_base[idx].item())\n",
        "                predicted_word_help = tokenizer.convert_ids_to_tokens(out_help[idx].item())\n",
        "\n",
        "                if word_sim_model is not None:\n",
        "                    predicted_sentence_base = tokenizer.convert_tokens_to_ids(masked_sentence)\n",
        "                    predicted_sentence_base[j] = out_base[idx].item()\n",
        "\n",
        "                    predicted_sentence_help = tokenizer.convert_tokens_to_ids(masked_sentence)\n",
        "                    predicted_sentence_help[j] = out_help[idx].item()\n",
        "\n",
        "\n",
        "                    tokenized_sentence = masked_sentence.copy()\n",
        "                    tokenized_sentence[j] = sentence[j]\n",
        "                    tokenized_sentence = tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        word_sim_input = torch.stack([torch.tensor(predicted_sentence_base), torch.tensor(predicted_sentence_help), torch.tensor(tokenized_sentence)]).to(device)\n",
        "                        word_sim_out = word_sim_model(word_sim_input)\n",
        "                        predicted_sentence_base_embedding = word_sim_out.last_hidden_state[0, j, :]\n",
        "                        predicted_sentence_help_embedding = word_sim_out.last_hidden_state[1, j, :]\n",
        "                        correct_embedding = word_sim_out.last_hidden_state[2, j, :]\n",
        "\n",
        "                    cos_sim = torch.nn.CosineSimilarity(dim=0)\n",
        "                    \n",
        "                    sim_base = cos_sim(predicted_sentence_base_embedding, correct_embedding)\n",
        "                    sim_help = cos_sim(predicted_sentence_help_embedding, correct_embedding)\n",
        "\n",
        "                    k = int(sim_base > 0.98)\n",
        "                    m = int(sim_help > 0.98)\n",
        "                    S[k][m] += 1\n",
        "\n",
        "                    score += (sim_help - sim_base)/(sim_base)\n",
        "                    \"\"\"print(tokenizer.convert_ids_to_tokens(predicted_sentence_base_tensor[0]),\n",
        "                          tokenizer.convert_ids_to_tokens(predicted_sentence_help_tensor[0]),\n",
        "                          tokenizer.convert_ids_to_tokens(tokenized_sentence_tensor[0]), sep=\"\\n\")\n",
        "                    print(k, m, sim_base.item(), sim_help.item())\"\"\"\n",
        "\n",
        "                else:\n",
        "                \n",
        "                    \"\"\"print(f'predicted_word_base[{idx - len(summary + [sep])}]: {predicted_word_base}')\n",
        "                    print(f'predicted_word_help[{idx - len(summary + [sep])}]: {predicted_word_help}')\n",
        "                    print(f'sentence[{j}]: {sentence[j]}')\"\"\"\n",
        "\n",
        "                    k = int(predicted_word_base == sentence[j])\n",
        "                    m = int(predicted_word_help == sentence[j])\n",
        "                    S[k][m] += 1\n",
        "\n",
        "\n",
        "    B = (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
        "    print(S)\n",
        "\n",
        "    return B, score.item() / (S[0][0] + S[1][1] + S[0][1] + S[1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def BLANC_help_optimized(text, summary, model, tokenizer, M=6, L_min=4, sep='[SEP]', device='cpu', word_sim_model=None):\n",
        "    \"\"\"\n",
        "    Optimized version of the BLANC_help function for calculating BLANC score.\n",
        "    \"\"\"\n",
        "\n",
        "    filler = ['.'] * len(summary)\n",
        "    S = [[0, 0], [0, 0]]\n",
        "    score = torch.zeros(1)[0]\n",
        "\n",
        "    # Batch preparation for model inference\n",
        "    base_inputs = []\n",
        "    help_inputs = []\n",
        "    attention_masks_base = []\n",
        "    attention_masks_help = []\n",
        "\n",
        "    # Precompute and store tokenized summary and separator\n",
        "    tokenized_summary = tokenizer.convert_tokens_to_ids(summary)\n",
        "    tokenized_sep = tokenizer.convert_tokens_to_ids([sep])\n",
        "    tokenized_filler = tokenizer.convert_tokens_to_ids(filler)\n",
        "    max_length = 0\n",
        "\n",
        "    batch_sentences = []\n",
        "    masked_tokens_batch = []\n",
        "\n",
        "    for sentence in text:\n",
        "        if no_copy_guard(sentence, summary): \n",
        "            continue\n",
        "        for i in range(M):\n",
        "            masked_sentence = mask_sentence(sentence, tokenizer.mask_token, i, M, L_min)\n",
        "            masked_sentence_ids = tokenizer.convert_tokens_to_ids(masked_sentence)\n",
        "\n",
        "            input_base = tokenized_filler + tokenized_sep + masked_sentence_ids\n",
        "            input_help = tokenized_summary + tokenized_sep + masked_sentence_ids\n",
        "\n",
        "            base_inputs.append(input_base)\n",
        "            help_inputs.append(input_help)\n",
        "\n",
        "            attention_masks_base.append([1] * len(input_base))\n",
        "            attention_masks_help.append([1] * len(input_help))\n",
        "\n",
        "            # Track the maximum length\n",
        "            max_length = max(max_length, len(input_base), len(input_help))\n",
        "\n",
        "            masked_tokens_batch.append([idx for idx, word in enumerate(masked_sentence_ids) if word == tokenizer.mask_token_id])\n",
        "\n",
        "            batch_sentences.append(tokenizer.convert_tokens_to_ids(sentence))\n",
        "\n",
        "    # Pad the sequences and convert to tensors\n",
        "    base_inputs_tensor = torch.stack([torch.nn.functional.pad(torch.tensor(seq), (0, max_length - len(seq)), value=tokenizer.pad_token_id) for seq in base_inputs]).to(device)\n",
        "    help_inputs_tensor = torch.stack([torch.nn.functional.pad(torch.tensor(seq), (0, max_length - len(seq)), value=tokenizer.pad_token_id) for seq in help_inputs]).to(device)\n",
        "    attention_mask_base_tensor = torch.stack([torch.nn.functional.pad(torch.tensor(mask), (0, max_length - len(mask))) for mask in attention_masks_base]).to(device)\n",
        "    attention_mask_help_tensor = torch.stack([torch.nn.functional.pad(torch.tensor(mask), (0, max_length - len(mask))) for mask in attention_masks_help]).to(device)\n",
        "\n",
        "    # Model inference in batches with attention masks\n",
        "    with torch.no_grad():\n",
        "        out_base = model(input_ids=base_inputs_tensor, attention_mask=attention_mask_base_tensor).logits\n",
        "        out_help = model(input_ids=help_inputs_tensor, attention_mask=attention_mask_help_tensor).logits\n",
        "\n",
        "    out_base = torch.argmax(out_base.squeeze(0), dim=-1)\n",
        "    out_help = torch.argmax(out_help.squeeze(0), dim=-1)\n",
        "    print(out_base.shape)\n",
        "\n",
        "    # Iterate through the batches\n",
        "    for b_idx in range(len(base_inputs)):\n",
        "        print(b_idx)\n",
        "        out_base_batch = out_base[b_idx]\n",
        "        out_help_batch = out_help[b_idx]\n",
        "        for j in masked_tokens_batch[b_idx]:\n",
        "            print(\"j:\", j)\n",
        "            idx = len(tokenized_summary) + 1 + j\n",
        "            print(idx)\n",
        "            predicted_word_base = out_base_batch[idx].item()\n",
        "            print(predicted_word_base)\n",
        "            predicted_word_help = out_help_batch[idx].item()\n",
        "            print(predicted_word_help)\n",
        "\n",
        "            # Rest of your logic here...\n",
        "            # Make sure to adjust indexing and access according to batch processing\n",
        "            \"\"\"print(f'predicted_word_base[{idx - len(summary + [sep])}]: {tokenizer.convert_ids_to_tokens(predicted_word_base)}')\n",
        "            print(f'predicted_word_help[{idx - len(summary + [sep])}]: {tokenizer.convert_ids_to_tokens(predicted_word_help)}')\n",
        "            print(f'sentence[{j}]: {tokenizer.convert_ids_to_tokens(batch_sentences[b_idx][j])}')\"\"\"\n",
        "\n",
        "            k = int(predicted_word_base == batch_sentences[b_idx][j])\n",
        "            m = int(predicted_word_help == batch_sentences[b_idx][j])\n",
        "            S[k][m] += 1\n",
        "            print(S)\n",
        "\n",
        "    B = (S[0][1] - S[1][0]) / (S[0][0] + S[1][1] + S[0][1] + S[1][0])\n",
        "    print(S)\n",
        "\n",
        "    return B, score / (S[0][0] + S[1][1] + S[0][1] + S[1][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o_Wn0bSqeTAk"
      },
      "outputs": [],
      "source": [
        "# cnn_dailymail_ds = load_dataset(\"cnn_dailymail\", '3.0.0', split='test')\n",
        "# print(cnn_dailymail_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "e99d05b19a5c4138aca173d07660e957",
            "9446b067785c415ab3c595ef2710d1de",
            "a15dcd5f78fb41a3b3d6de0fedaa1184",
            "30187123bedc4d6c9ffadaa1dab27a82",
            "f015814a7f6b4a89a9f75827de143256",
            "253c5509188b44c7ab8aa1f6ea2003d1",
            "0a0e36b6cfca42d89bac31eae8d6b605",
            "6205a3c6d99e450e95bf035a8d07d56e",
            "712370bf3c4b469c99e77514335fcd6d",
            "192fb41a76b94130b6299197c719b70c",
            "4fbb29aac32b477ba98645fd25680ca6"
          ]
        },
        "id": "9tmYbuTDg7Yh",
        "outputId": "d250dd69-b767-4476-a19e-6c69d5f9520a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['summary', 'text', 'scores', 'annotators_ids'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DailyNews_ds = load_dataset('json', data_files='../datasets/DailyNews_300.json', split='train')\n",
        "DailyNews_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "01z4jmL7Y9yy",
        "outputId": "8e872475-a3e5-4d77-ad19-62b42da57d0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased').to(DEVICE)\n",
        "word_sim_model = BertModel.from_pretrained('bert-base-uncased').to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fNs_l53IB5nz"
      },
      "outputs": [],
      "source": [
        "summaries = DailyNews_ds['summary'] # (List[str])\n",
        "texts = DailyNews_ds['text']  # (List[str]) each string is a paragraph made of a few sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Zcf_roESB_bb"
      },
      "outputs": [],
      "source": [
        "# each text in texts is a list of sentences (each sentence is a string)\n",
        "texts = [sent_tokenize(text.strip()) for text in texts] # List[List[str]]\n",
        "assert len(texts) == len(summaries) == 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zTEaHWPkCIht"
      },
      "outputs": [],
      "source": [
        "tokenized_texts = [[tokenizer.tokenize(sentence) for sentence in text] for text in texts]\n",
        "tokenized_summaries = [tokenizer.tokenize(summary) for summary in summaries]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[238, 76], [19, 200]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.10694183864915573, 0.04585169493369269)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BLANC_help(tokenized_texts[0], tokenized_summaries[0], model, tokenizer, device=DEVICE, word_sim_model = word_sim_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHOsrrWZLsDj",
        "outputId": "2d74612c-e08b-41b9-b049-22834209b47e"
      },
      "outputs": [],
      "source": [
        "#BLANC_help_optimized(tokenized_texts[0], tokenized_summaries[0], model, tokenizer, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7ec00d0734c94561a0a97be0f2de3f4a",
            "77eb02b005c84784abc8c26119c73b7e",
            "8a71567152674946b7192f06f7338e21",
            "27d4ab6496f5415db5dff0a992f83c97",
            "235fc9caede94554a858295dd4647d56",
            "f52a45e839564994b6183ab6245dd241",
            "e4e4fcb188a24acd904daa23caf38d79",
            "b571a574e58540bd87d7419f224fadbb",
            "0229065e07544c79ab4741e0077a1383",
            "dcb73195ff8e4f4582519743df4b45bb",
            "5771a9b761dc42bdb475bba3f511f42c"
          ]
        },
        "id": "5XG1Cuo7LvO8",
        "outputId": "5faa3d1d-db1a-4e69-bb91-9f34e6b155b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50607c6895f84cc7b143782ff48264b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[238, 76], [19, 200]]\n",
            "[[153, 49], [12, 154]]\n",
            "[[149, 49], [10, 159]]\n",
            "[[324, 79], [23, 277]]\n",
            "[[183, 18], [12, 128]]\n",
            "[[167, 60], [6, 140]]\n",
            "[[189, 100], [18, 303]]\n",
            "[[290, 37], [14, 281]]\n",
            "[[242, 48], [21, 184]]\n",
            "[[139, 19], [9, 113]]\n",
            "[[253, 85], [14, 270]]\n",
            "[[112, 38], [2, 138]]\n",
            "[[127, 22], [7, 105]]\n",
            "[[248, 71], [21, 235]]\n",
            "[[44, 29], [4, 47]]\n",
            "[[171, 48], [16, 134]]\n",
            "[[325, 80], [12, 160]]\n",
            "[[141, 35], [7, 107]]\n",
            "[[151, 91], [8, 257]]\n",
            "[[220, 66], [14, 196]]\n",
            "[[201, 101], [17, 312]]\n",
            "[[392, 49], [15, 308]]\n",
            "[[35, 44], [4, 55]]\n",
            "[[148, 66], [17, 162]]\n",
            "[[143, 50], [8, 126]]\n",
            "[[125, 37], [6, 126]]\n",
            "[[73, 38], [3, 112]]\n",
            "[[134, 25], [6, 133]]\n",
            "[[231, 104], [14, 245]]\n",
            "[[194, 49], [14, 236]]\n",
            "[[133, 28], [6, 165]]\n",
            "[[118, 70], [6, 155]]\n",
            "[[161, 57], [11, 128]]\n",
            "[[145, 50], [5, 154]]\n",
            "[[236, 120], [18, 224]]\n",
            "[[247, 72], [19, 240]]\n",
            "[[239, 105], [23, 226]]\n",
            "[[157, 40], [9, 122]]\n",
            "[[380, 73], [23, 294]]\n",
            "[[265, 139], [16, 243]]\n",
            "[[203, 56], [11, 210]]\n",
            "[[107, 31], [9, 131]]\n",
            "[[114, 22], [5, 129]]\n",
            "[[192, 74], [18, 346]]\n",
            "[[333, 89], [17, 332]]\n",
            "[[224, 68], [16, 311]]\n",
            "[[38, 25], [1, 69]]\n",
            "[[155, 90], [13, 252]]\n",
            "[[177, 40], [9, 182]]\n",
            "[[123, 67], [5, 123]]\n",
            "[[74, 54], [8, 135]]\n",
            "[[123, 33], [3, 127]]\n",
            "[[107, 43], [10, 140]]\n",
            "[[137, 32], [10, 126]]\n",
            "[[127, 35], [6, 131]]\n",
            "[[190, 22], [10, 181]]\n",
            "[[267, 132], [18, 246]]\n",
            "[[62, 42], [2, 101]]\n",
            "[[54, 23], [2, 87]]\n",
            "[[256, 61], [21, 234]]\n",
            "[[113, 82], [14, 118]]\n",
            "[[148, 55], [16, 212]]\n",
            "[[101, 67], [6, 145]]\n",
            "[[189, 72], [19, 318]]\n",
            "[[168, 80], [8, 142]]\n",
            "[[236, 91], [11, 178]]\n",
            "[[224, 57], [16, 220]]\n",
            "[[130, 33], [4, 165]]\n",
            "[[101, 47], [12, 140]]\n",
            "[[178, 88], [13, 259]]\n",
            "[[122, 32], [9, 142]]\n",
            "[[245, 53], [12, 302]]\n",
            "[[212, 89], [18, 283]]\n",
            "[[133, 27], [6, 132]]\n",
            "[[209, 100], [18, 206]]\n",
            "[[132, 31], [11, 219]]\n",
            "[[334, 79], [26, 382]]\n",
            "[[374, 76], [18, 305]]\n",
            "[[238, 113], [12, 266]]\n",
            "[[113, 35], [11, 194]]\n",
            "[[93, 41], [7, 99]]\n",
            "[[35, 13], [2, 41]]\n",
            "[[81, 41], [5, 110]]\n",
            "[[70, 32], [1, 55]]\n",
            "[[75, 54], [4, 84]]\n",
            "[[128, 83], [17, 159]]\n",
            "[[81, 27], [5, 101]]\n",
            "[[71, 28], [8, 102]]\n",
            "[[105, 37], [3, 79]]\n",
            "[[85, 26], [5, 107]]\n",
            "[[59, 9], [5, 78]]\n",
            "[[102, 73], [4, 172]]\n",
            "[[281, 130], [11, 167]]\n",
            "[[132, 58], [5, 117]]\n",
            "[[170, 39], [12, 182]]\n",
            "[[72, 35], [4, 84]]\n",
            "[[78, 31], [7, 106]]\n",
            "[[102, 53], [10, 123]]\n",
            "[[57, 38], [2, 99]]\n",
            "[[97, 46], [9, 114]]\n",
            "[[222, 61], [9, 204]]\n",
            "[[30, 37], [2, 51]]\n",
            "[[77, 47], [4, 71]]\n",
            "[[91, 48], [8, 68]]\n",
            "[[278, 78], [10, 302]]\n",
            "[[160, 37], [16, 215]]\n",
            "[[137, 28], [5, 135]]\n",
            "[[221, 53], [13, 280]]\n",
            "[[81, 61], [9, 115]]\n",
            "[[185, 65], [8, 193]]\n",
            "[[72, 61], [4, 106]]\n",
            "[[94, 41], [4, 100]]\n",
            "[[319, 85], [25, 333]]\n",
            "[[66, 34], [1, 69]]\n",
            "[[94, 42], [9, 104]]\n",
            "[[63, 38], [2, 99]]\n",
            "[[83, 59], [4, 124]]\n",
            "[[117, 26], [7, 122]]\n",
            "[[79, 27], [7, 75]]\n",
            "[[193, 64], [16, 181]]\n",
            "[[58, 35], [2, 79]]\n",
            "[[80, 53], [5, 73]]\n",
            "[[340, 62], [20, 281]]\n",
            "[[90, 23], [1, 121]]\n",
            "[[304, 91], [24, 254]]\n",
            "[[219, 93], [13, 287]]\n",
            "[[124, 52], [7, 124]]\n",
            "[[126, 44], [11, 109]]\n",
            "[[110, 42], [7, 141]]\n",
            "[[149, 42], [4, 187]]\n",
            "[[121, 49], [3, 134]]\n",
            "[[56, 39], [3, 86]]\n",
            "[[86, 39], [6, 68]]\n",
            "[[68, 44], [3, 72]]\n",
            "[[76, 20], [3, 87]]\n",
            "[[74, 47], [4, 112]]\n",
            "[[51, 36], [5, 53]]\n",
            "[[77, 32], [6, 102]]\n",
            "[[105, 36], [8, 121]]\n",
            "[[100, 52], [12, 101]]\n",
            "[[79, 38], [2, 76]]\n",
            "[[77, 29], [6, 110]]\n",
            "[[86, 34], [5, 96]]\n",
            "[[100, 27], [4, 69]]\n",
            "[[195, 79], [12, 209]]\n",
            "[[90, 57], [4, 115]]\n",
            "[[379, 149], [25, 413]]\n",
            "[[331, 74], [28, 338]]\n",
            "[[67, 34], [1, 56]]\n",
            "[[88, 29], [4, 102]]\n",
            "[[69, 35], [3, 70]]\n",
            "[[102, 32], [8, 103]]\n",
            "[[82, 30], [10, 101]]\n",
            "[[59, 27], [3, 89]]\n",
            "[[86, 43], [1, 70]]\n",
            "[[62, 18], [2, 54]]\n",
            "[[212, 79], [9, 177]]\n",
            "[[86, 45], [4, 103]]\n",
            "[[44, 31], [4, 72]]\n",
            "[[102, 41], [6, 121]]\n",
            "[[197, 74], [4, 148]]\n",
            "[[151, 67], [12, 238]]\n",
            "[[121, 36], [6, 132]]\n",
            "[[49, 20], [3, 43]]\n",
            "[[204, 19], [8, 183]]\n",
            "[[120, 43], [7, 181]]\n",
            "[[36, 34], [6, 75]]\n",
            "[[127, 43], [10, 127]]\n",
            "[[113, 42], [5, 99]]\n",
            "[[58, 43], [5, 94]]\n",
            "[[56, 19], [1, 50]]\n",
            "[[87, 49], [9, 108]]\n",
            "[[107, 29], [9, 120]]\n",
            "[[247, 64], [20, 249]]\n",
            "[[121, 52], [4, 113]]\n",
            "[[97, 38], [1, 65]]\n",
            "[[65, 11], [1, 85]]\n",
            "[[73, 32], [7, 94]]\n",
            "[[89, 71], [5, 86]]\n",
            "[[133, 60], [5, 130]]\n",
            "[[191, 71], [15, 250]]\n",
            "[[218, 48], [7, 260]]\n",
            "[[56, 40], [2, 73]]\n",
            "[[66, 16], [4, 64]]\n",
            "[[197, 59], [4, 198]]\n",
            "[[196, 72], [24, 346]]\n",
            "[[75, 22], [5, 107]]\n",
            "[[179, 100], [10, 166]]\n",
            "[[47, 17], [1, 73]]\n",
            "[[239, 112], [14, 264]]\n",
            "[[204, 84], [19, 210]]\n",
            "[[71, 37], [6, 101]]\n",
            "[[212, 73], [18, 202]]\n",
            "[[170, 103], [10, 160]]\n",
            "[[76, 32], [9, 92]]\n",
            "[[141, 62], [14, 166]]\n",
            "[[53, 13], [2, 96]]\n",
            "[[131, 57], [7, 173]]\n",
            "[[183, 5], [2, 178]]\n",
            "[[63, 17], [5, 98]]\n",
            "[[124, 54], [12, 238]]\n",
            "[[223, 45], [17, 211]]\n",
            "[[120, 25], [6, 121]]\n",
            "[[76, 25], [2, 61]]\n",
            "[[91, 35], [4, 76]]\n",
            "[[65, 22], [8, 74]]\n",
            "[[160, 63], [13, 132]]\n",
            "[[92, 48], [7, 68]]\n",
            "[[71, 35], [4, 116]]\n",
            "[[61, 50], [3, 84]]\n",
            "[[36, 18], [2, 58]]\n",
            "[[46, 17], [3, 70]]\n",
            "[[81, 36], [9, 93]]\n",
            "[[80, 18], [6, 82]]\n",
            "[[137, 20], [7, 120]]\n",
            "[[140, 39], [13, 162]]\n",
            "[[92, 29], [11, 128]]\n",
            "[[216, 68], [12, 271]]\n",
            "[[227, 87], [20, 218]]\n",
            "[[70, 35], [4, 96]]\n",
            "[[79, 54], [5, 107]]\n",
            "[[99, 43], [6, 114]]\n",
            "[[351, 57], [19, 396]]\n",
            "[[51, 37], [2, 86]]\n",
            "[[352, 67], [23, 374]]\n",
            "[[131, 45], [7, 112]]\n",
            "[[50, 47], [5, 96]]\n",
            "[[55, 25], [1, 55]]\n",
            "[[113, 27], [6, 225]]\n",
            "[[162, 42], [11, 153]]\n",
            "[[176, 30], [10, 125]]\n",
            "[[58, 13], [2, 81]]\n",
            "[[82, 36], [7, 115]]\n",
            "[[130, 50], [8, 231]]\n",
            "[[128, 39], [6, 134]]\n",
            "[[87, 50], [6, 204]]\n",
            "[[99, 48], [4, 145]]\n",
            "[[168, 80], [7, 139]]\n",
            "[[92, 29], [2, 72]]\n",
            "[[54, 22], [5, 75]]\n",
            "[[53, 13], [3, 95]]\n",
            "[[102, 44], [4, 101]]\n",
            "[[186, 64], [13, 180]]\n",
            "[[138, 66], [13, 166]]\n",
            "[[85, 51], [6, 100]]\n",
            "[[39, 8], [1, 25]]\n",
            "[[138, 45], [6, 168]]\n",
            "[[131, 18], [6, 175]]\n",
            "[[72, 26], [3, 58]]\n",
            "[[222, 70], [13, 168]]\n",
            "[[81, 34], [3, 75]]\n",
            "[[237, 96], [28, 241]]\n",
            "[[116, 53], [10, 219]]\n",
            "[[82, 53], [3, 110]]\n",
            "[[46, 16], [2, 63]]\n",
            "[[50, 18], [3, 68]]\n",
            "[[69, 33], [3, 102]]\n",
            "[[128, 81], [16, 174]]\n",
            "[[120, 54], [10, 105]]\n",
            "[[69, 51], [6, 102]]\n",
            "[[283, 59], [16, 300]]\n",
            "[[205, 64], [5, 149]]\n",
            "[[43, 23], [0, 62]]\n",
            "[[153, 86], [9, 135]]\n",
            "[[236, 55], [12, 174]]\n",
            "[[66, 20], [2, 59]]\n",
            "[[66, 35], [6, 94]]\n",
            "[[299, 111], [13, 163]]\n",
            "[[209, 66], [15, 215]]\n",
            "[[47, 27], [3, 74]]\n",
            "[[214, 41], [8, 152]]\n",
            "[[112, 37], [4, 98]]\n",
            "[[172, 58], [14, 172]]\n",
            "[[94, 30], [3, 133]]\n",
            "[[72, 36], [7, 99]]\n",
            "[[151, 69], [10, 218]]\n",
            "[[142, 58], [12, 215]]\n",
            "[[59, 43], [3, 59]]\n",
            "[[237, 55], [10, 179]]\n",
            "[[84, 36], [4, 88]]\n",
            "[[123, 37], [6, 139]]\n",
            "[[146, 50], [10, 158]]\n",
            "[[69, 15], [4, 47]]\n",
            "[[377, 154], [41, 425]]\n",
            "[[65, 31], [2, 71]]\n",
            "[[383, 151], [29, 421]]\n",
            "[[233, 95], [11, 196]]\n",
            "[[54, 22], [2, 47]]\n",
            "[[111, 28], [8, 208]]\n",
            "[[265, 103], [15, 221]]\n",
            "[[110, 42], [10, 116]]\n",
            "[[92, 37], [3, 141]]\n",
            "[[74, 29], [2, 55]]\n",
            "[[85, 18], [7, 94]]\n",
            "[[107, 39], [5, 100]]\n",
            "[[159, 52], [11, 212]]\n",
            "[[140, 16], [2, 136]]\n",
            "[[114, 31], [6, 107]]\n",
            "[[56, 16], [2, 36]]\n",
            "[[145, 63], [15, 176]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0.10694183864915573, 0.04585169493369269),\n",
              " (0.10054347826086957, 0.028698128202687138),\n",
              " (0.10626702997275204, 0.03547636234792766),\n",
              " (0.07965860597439545, 0.03565559007365198),\n",
              " (0.017595307917888565, 0.00911830597259432),\n",
              " (0.1447721179624665, 0.05863033223088242),\n",
              " (0.13442622950819672, 0.04655642587630475),\n",
              " (0.03697749196141479, 0.016811691296445594),\n",
              " (0.05454545454545454, 0.023568139895044193),\n",
              " (0.03571428571428571, 0.02239389419555664),\n",
              " (0.11414790996784566, 0.04760255230968022),\n",
              " (0.12413793103448276, 0.04337234825923525),\n",
              " (0.05747126436781609, 0.021921663905468937),\n",
              " (0.08695652173913043, 0.032379349418308424),\n",
              " (0.20161290322580644, 0.03706898996906896),\n",
              " (0.08672086720867209, 0.03473842434766816),\n",
              " (0.11785095320623917, 0.052930779019096284),\n",
              " (0.09655172413793103, 0.04678612084224306),\n",
              " (0.16370808678500987, 0.04985008390227248),\n",
              " (0.10483870967741936, 0.03639613812969577),\n",
              " (0.13312202852614896, 0.0452209478701729),\n",
              " (0.04450261780104712, 0.012952697214655851),\n",
              " (0.2898550724637681, 0.05378100837486378),\n",
              " (0.12468193384223919, 0.03435218849861592),\n",
              " (0.12844036697247707, 0.046678828901471715),\n",
              " (0.1054421768707483, 0.028275995838398835),\n",
              " (0.15486725663716813, 0.030800300361835852),\n",
              " (0.06375838926174497, 0.03290482335442665),\n",
              " (0.15151515151515152, 0.05905653571440315),\n",
              " (0.07099391480730223, 0.024823678192695788),\n",
              " (0.06626506024096386, 0.013498561928071171),\n",
              " (0.1833810888252149, 0.05401139682890009),\n",
              " (0.12885154061624648, 0.0540406416778137),\n",
              " (0.1271186440677966, 0.03271361259417345),\n",
              " (0.1705685618729097, 0.041854057822339114),\n",
              " (0.09169550173010381, 0.03227421651662015),\n",
              " (0.13827993254637436, 0.035359905300815835),\n",
              " (0.09451219512195122, 0.04392520974322063),\n",
              " (0.06493506493506493, 0.023078403225192775),\n",
              " (0.18552036199095023, 0.07274959098159997),\n",
              " (0.09375, 0.054233797391255695),\n",
              " (0.07913669064748201, 0.024679478981512057),\n",
              " (0.06296296296296296, 0.015170252764666521),\n",
              " (0.08888888888888889, 0.02685267130533854),\n",
              " (0.0933852140077821, 0.04295441643582553),\n",
              " (0.0840064620355412, 0.030079759958294944),\n",
              " (0.18045112781954886, 0.03655615068019781),\n",
              " (0.15098039215686274, 0.05018459768856273),\n",
              " (0.07598039215686274, 0.020620112325630935),\n",
              " (0.1949685534591195, 0.06041521396277086),\n",
              " (0.16974169741697417, 0.058709496501627004),\n",
              " (0.1048951048951049, 0.02453562429734877),\n",
              " (0.11, 0.03857765197753906),\n",
              " (0.07213114754098361, 0.030770686415375257),\n",
              " (0.09698996655518395, 0.02567979244882845),\n",
              " (0.02977667493796526, 0.01300749293627869),\n",
              " (0.17194570135746606, 0.06704397187153859),\n",
              " (0.1932367149758454, 0.060554997356617506),\n",
              " (0.12650602409638553, 0.03478883835206549),\n",
              " (0.06993006993006994, 0.02711838275402576),\n",
              " (0.20795107033639143, 0.08174732919862146),\n",
              " (0.09048723897911833, 0.02635642934564648),\n",
              " (0.19122257053291536, 0.060533673038303294),\n",
              " (0.08862876254180602, 0.0313510671507156),\n",
              " (0.18090452261306533, 0.05290675043460712),\n",
              " (0.15503875968992248, 0.06252150572547617),\n",
              " (0.07930367504835589, 0.03587999841922487),\n",
              " (0.08734939759036145, 0.019810642104551017),\n",
              " (0.11666666666666667, 0.10020648956298828),\n",
              " (0.13940520446096655, 0.0408100106902282),\n",
              " (0.07540983606557378, 0.0238955059989554),\n",
              " (0.06699346405228758, 0.035335949043822444),\n",
              " (0.11794019933554817, 0.04745858531457641),\n",
              " (0.07046979865771812, 0.020266134466900922),\n",
              " (0.15384615384615385, 0.05453728466499143),\n",
              " (0.05089058524173028, 0.013780834110638568),\n",
              " (0.06455542021924482, 0.02265096146354722),\n",
              " (0.07503234152652005, 0.023965386493085734),\n",
              " (0.16057233704292528, 0.06079093071917851),\n",
              " (0.0679886685552408, 0.03510878241433638),\n",
              " (0.14166666666666666, 0.030380642414093016),\n",
              " (0.12087912087912088, 0.0448864004114172),\n",
              " (0.1518987341772152, 0.049472189150782074),\n",
              " (0.1962025316455696, 0.06652235079415236),\n",
              " (0.2304147465437788, 0.07991519172070763),\n",
              " (0.17054263565891473, 0.04947280390934119),\n",
              " (0.102803738317757, 0.026839127050381953),\n",
              " (0.09569377990430622, 0.03091514167603123),\n",
              " (0.15178571428571427, 0.06289444225175041),\n",
              " (0.09417040358744394, 0.025963139640910744),\n",
              " (0.026490066225165563, 0.01309680701881055),\n",
              " (0.19658119658119658, 0.05506367696995749),\n",
              " (0.20203735144312393, 0.06582453781153835),\n",
              " (0.16987179487179488, 0.059311457169361606),\n",
              " (0.06699751861042183, 0.024833227209654397),\n",
              " (0.15897435897435896, 0.051133918762207034),\n",
              " (0.10810810810810811, 0.042489331047814174),\n",
              " (0.14930555555555555, 0.05524467759662204),\n",
              " (0.1836734693877551, 0.033027926269842654),\n",
              " (0.13909774436090225, 0.03909218938727128),\n",
              " (0.10483870967741936, 0.03824127874066753),\n",
              " (0.2916666666666667, 0.053112900257110594),\n",
              " (0.21608040201005024, 0.07089421257900833),\n",
              " (0.18604651162790697, 0.06901552067246548),\n",
              " (0.10179640718562874, 0.029382694267227265),\n",
              " (0.04906542056074766, 0.018634063061152662),\n",
              " (0.07540983606557378, 0.024728981393282532),\n",
              " (0.07054673721340388, 0.03546325575947972),\n",
              " (0.19548872180451127, 0.04692295619419643),\n",
              " (0.12638580931263857, 0.0505935812736562),\n",
              " (0.2345679012345679, 0.07609923091935522),\n",
              " (0.15481171548117154, 0.03927550455516352),\n",
              " (0.07874015748031496, 0.04171196494515487),\n",
              " (0.19411764705882353, 0.05071428523344152),\n",
              " (0.13253012048192772, 0.045159006693277014),\n",
              " (0.1782178217821782, 0.035776024997824486),\n",
              " (0.2037037037037037, 0.06381479192663123),\n",
              " (0.06985294117647059, 0.0343132685212528),\n",
              " (0.10638297872340426, 0.08206148857766009),\n",
              " (0.10572687224669604, 0.031137957972051815),\n",
              " (0.1896551724137931, 0.04529163207130871),\n",
              " (0.22748815165876776, 0.06625413216685797),\n",
              " (0.059743954480796585, 0.029966012512467496),\n",
              " (0.09361702127659574, 0.021736449383674784),\n",
              " (0.09955423476968796, 0.041722160214655114),\n",
              " (0.13071895424836602, 0.0519554474774529),\n",
              " (0.1465798045602606, 0.04868480359304223),\n",
              " (0.11379310344827587, 0.04689718443771888),\n",
              " (0.11666666666666667, 0.03646830240885417),\n",
              " (0.09947643979057591, 0.04321658049578442),\n",
              " (0.1498371335504886, 0.04068760763162122),\n",
              " (0.1956521739130435, 0.03422920859378317),\n",
              " (0.1658291457286432, 0.06135696142762151),\n",
              " (0.2192513368983957, 0.05848381226075524),\n",
              " (0.0913978494623656, 0.03921712854857086),\n",
              " (0.18143459915611815, 0.05794540839859202),\n",
              " (0.21379310344827587, 0.06878649612952922),\n",
              " (0.11981566820276497, 0.04275853293282645),\n",
              " (0.1037037037037037, 0.039153734842936196),\n",
              " (0.1509433962264151, 0.0493220383266233),\n",
              " (0.18461538461538463, 0.09742214496319111),\n",
              " (0.1036036036036036, 0.039317556329675624),\n",
              " (0.13122171945701358, 0.05750586220581607),\n",
              " (0.115, 0.04496047973632813),\n",
              " (0.13535353535353536, 0.055654822455512155),\n",
              " (0.19924812030075187, 0.051069331348390506),\n",
              " (0.12836438923395446, 0.04539250044102007),\n",
              " (0.05966277561608301, 0.0338394249150416),\n",
              " (0.2088607594936709, 0.07049052322967143),\n",
              " (0.11210762331838565, 0.03792803811385492),\n",
              " (0.1807909604519774, 0.06615766428284726),\n",
              " (0.09795918367346938, 0.04300929478236607),\n",
              " (0.08968609865470852, 0.027514312299377716),\n",
              " (0.1348314606741573, 0.018919575080442966),\n",
              " (0.21, 0.06631457328796386),\n",
              " (0.11764705882352941, 0.027964609510758343),\n",
              " (0.14675052410901468, 0.051114872066729725),\n",
              " (0.1722689075630252, 0.05661930757410386),\n",
              " (0.17880794701986755, 0.06867276753810857),\n",
              " (0.12962962962962962, 0.04688997621889467),\n",
              " (0.16548463356973994, 0.06200567204901512),\n",
              " (0.11752136752136752, 0.03647183556841989),\n",
              " (0.1016949152542373, 0.034946389925681935),\n",
              " (0.14782608695652175, 0.04478923134181811),\n",
              " (0.026570048309178744, 0.012818162567949525),\n",
              " (0.10256410256410256, 0.025906858960447827),\n",
              " (0.18543046357615894, 0.03849099645551467),\n",
              " (0.10749185667752444, 0.03838109193485024),\n",
              " (0.14285714285714285, 0.04484249910332522),\n",
              " (0.19, 0.0575358772277832),\n",
              " (0.14285714285714285, 0.045046866886199466),\n",
              " (0.15810276679841898, 0.046083657637886376),\n",
              " (0.07547169811320754, 0.03261984339300192),\n",
              " (0.07586206896551724, 0.037177878412707095),\n",
              " (0.16551724137931034, 0.062401528194032864),\n",
              " (0.18407960199004975, 0.07469365608632861),\n",
              " (0.06172839506172839, 0.013086301309091074),\n",
              " (0.12135922330097088, 0.03029505720416319),\n",
              " (0.26294820717131473, 0.09739156168295568),\n",
              " (0.1676829268292683, 0.057660364523166564),\n",
              " (0.1062618595825427, 0.03480690118257642),\n",
              " (0.07692307692307693, 0.030807237464088883),\n",
              " (0.2222222222222222, 0.06385728490282917),\n",
              " (0.08, 0.025280950864156087),\n",
              " (0.12008733624454149, 0.04800950595905687),\n",
              " (0.07523510971786834, 0.025496982108089244),\n",
              " (0.08133971291866028, 0.02294119465294067),\n",
              " (0.1978021978021978, 0.047534569541176595),\n",
              " (0.11594202898550725, 0.035195015478825226),\n",
              " (0.15580286168521462, 0.052889334188925254),\n",
              " (0.12572533849129594, 0.056316866404313874),\n",
              " (0.14418604651162792, 0.04994551636451899),\n",
              " (0.10891089108910891, 0.045065613548354345),\n",
              " (0.20993227990970656, 0.052167285376693004),\n",
              " (0.11004784688995216, 0.04135311163213264),\n",
              " (0.12532637075718014, 0.03518203655671202),\n",
              " (0.06707317073170732, 0.013616977668390042),\n",
              " (0.1358695652173913, 0.057944043822910477),\n",
              " (0.008152173913043478, 0.00716778506403384),\n",
              " (0.06557377049180328, 0.022762004143553352),\n",
              " (0.09813084112149532, 0.026906984988774096),\n",
              " (0.056451612903225805, 0.026597763261487408),\n",
              " (0.06985294117647059, 0.028949770857306087),\n",
              " (0.1402439024390244, 0.036746231521048195),\n",
              " (0.15048543689320387, 0.04302904906782132),\n",
              " (0.08284023668639054, 0.03545617210794483),\n",
              " (0.1358695652173913, 0.04696758933689283),\n",
              " (0.19069767441860466, 0.07124240342960801),\n",
              " (0.13716814159292035, 0.03203138629947089),\n",
              " (0.23737373737373738, 0.06719784303144975),\n",
              " (0.14035087719298245, 0.0411691289199026),\n",
              " (0.10294117647058823, 0.039702818674199725),\n",
              " (0.1232876712328767, 0.04177358270235802),\n",
              " (0.06451612903225806, 0.026484422786261445),\n",
              " (0.045774647887323945, 0.02104639839118635),\n",
              " (0.07344632768361582, 0.020167971734946732),\n",
              " (0.06923076923076923, 0.025807778651897723),\n",
              " (0.09876543209876543, 0.04445111646433566),\n",
              " (0.1213768115942029, 0.038776518642038536),\n",
              " (0.15121951219512195, 0.044076510173518484),\n",
              " (0.2, 0.06936602689781968),\n",
              " (0.14122137404580154, 0.053991798226159946),\n",
              " (0.046172539489671933, 0.014529352199698132),\n",
              " (0.19886363636363635, 0.06259704719890248),\n",
              " (0.05392156862745098, 0.026604696816089107),\n",
              " (0.1288135593220339, 0.05161105010469081),\n",
              " (0.21212121212121213, 0.061674826072924065),\n",
              " (0.17647058823529413, 0.048061746008255905),\n",
              " (0.05660377358490566, 0.01703817439529131),\n",
              " (0.08423913043478261, 0.030598313912101414),\n",
              " (0.05865102639296188, 0.0196593947424567),\n",
              " (0.07142857142857142, 0.029319527861359832),\n",
              " (0.12083333333333333, 0.054805239041646324),\n",
              " (0.10023866348448687, 0.028989063526963847),\n",
              " (0.10749185667752444, 0.02708891082664266),\n",
              " (0.12680115273775217, 0.02618874871421616),\n",
              " (0.14864864864864866, 0.04259610176086426),\n",
              " (0.18527918781725888, 0.05051726617183782),\n",
              " (0.13846153846153847, 0.03964997071486253),\n",
              " (0.10897435897435898, 0.04316822076455141),\n",
              " (0.06097560975609756, 0.013514784778036722),\n",
              " (0.1593625498007968, 0.03833504027104473),\n",
              " (0.11512415349887133, 0.034212146870976914),\n",
              " (0.13838120104438642, 0.047361662742674504),\n",
              " (0.1859504132231405, 0.05670292121319732),\n",
              " (0.0958904109589041, 0.042669146028283526),\n",
              " (0.1092436974789916, 0.036059061686197914),\n",
              " (0.03636363636363636, 0.018851809068159624),\n",
              " (0.14465408805031446, 0.031152158413293225),\n",
              " (0.12050739957716702, 0.041521278042621894),\n",
              " (0.16062176165803108, 0.03814324937336185),\n",
              " (0.11295681063122924, 0.0500965086724671),\n",
              " (0.10804020100502512, 0.04098134064794186),\n",
              " (0.20161290322580644, 0.07130992028021044),\n",
              " (0.11023622047244094, 0.026220545055359368),\n",
              " (0.1079136690647482, 0.053838836203376164),\n",
              " (0.14492753623188406, 0.05279804543020645),\n",
              " (0.16290726817042606, 0.05528459572851807),\n",
              " (0.1522491349480969, 0.06675889170293577),\n",
              " (0.19736842105263158, 0.049627350087751425),\n",
              " (0.06534954407294832, 0.016733124625719065),\n",
              " (0.13947990543735225, 0.06644813501524868),\n",
              " (0.1796875, 0.07033729553222656),\n",
              " (0.2010443864229765, 0.08432117392437888),\n",
              " (0.09014675052410902, 0.038252668560675857),\n",
              " (0.12244897959183673, 0.06787758133038371),\n",
              " (0.14427860696517414, 0.04648405046605352),\n",
              " (0.16723549488054607, 0.06236710401932127),\n",
              " (0.100990099009901, 0.04691233115621132),\n",
              " (0.15894039735099338, 0.0635113747704108),\n",
              " (0.07951807228915662, 0.0489619335496282),\n",
              " (0.13147410358565736, 0.05482553200892718),\n",
              " (0.10576923076923077, 0.02898369156397306),\n",
              " (0.10384615384615385, 0.02528845713688777),\n",
              " (0.13551401869158877, 0.02689956504607869),\n",
              " (0.13169642857142858, 0.05234062245913914),\n",
              " (0.10772833723653395, 0.03198254918047081),\n",
              " (0.24390243902439024, 0.0878787273313941),\n",
              " (0.09355509355509356, 0.03761491755685786),\n",
              " (0.1509433962264151, 0.042202594145289006),\n",
              " (0.10163934426229508, 0.03178337284776031),\n",
              " (0.10989010989010989, 0.05377599695226648),\n",
              " (0.08148148148148149, 0.02603351275126139),\n",
              " (0.11334002006018054, 0.04089050905156877),\n",
              " (0.17159763313609466, 0.054805930549576436),\n",
              " (0.12398373983739837, 0.04371814029972728),\n",
              " (0.15700934579439252, 0.06252270279643692),\n",
              " (0.16, 0.04810312271118164),\n",
              " (0.056338028169014086, 0.015172227671448614),\n",
              " (0.1456953642384106, 0.051472329146025196),\n",
              " (0.11510791366906475, 0.03724727013128267),\n",
              " (0.12454212454212454, 0.02951421143807771),\n",
              " (0.16875, 0.04191071093082428),\n",
              " (0.05392156862745098, 0.02043770808799594),\n",
              " (0.13545816733067728, 0.02679969020098804),\n",
              " (0.0944700460829493, 0.043933912356328306),\n",
              " (0.047619047619047616, 0.023767602686979333),\n",
              " (0.09689922480620156, 0.02526565300401791),\n",
              " (0.12727272727272726, 0.05130105452104048),\n",
              " (0.12030075187969924, 0.04194966653235873)]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = [BLANC_help(text, summary, model, tokenizer, device=DEVICE, word_sim_model = word_sim_model)\n",
        "          for summary, text in tqdm(zip(tokenized_summaries, tokenized_texts))]\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been added to ./results.json\n"
          ]
        }
      ],
      "source": [
        "data = {}\n",
        "blanc_scores, sim_scores = zip(*scores)\n",
        "#data['BLANC_help_300'] = list(blanc_scores)\n",
        "data['BLANC_help_300_similarity3'] = list(blanc_scores)\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "def add_results_to_json(new_data, file_path = \"./results.json\"):\n",
        "    try:\n",
        "        with open(file_path, 'r') as json_file:\n",
        "            existing_data = json.load(json_file)\n",
        "    except FileNotFoundError:\n",
        "        existing_data = {}\n",
        "\n",
        "    for key, value in new_data.items():\n",
        "        existing_data[key] = value\n",
        "\n",
        "    with open(file_path, 'w') as json_file:\n",
        "        json.dump(existing_data, json_file, indent=2)\n",
        "\n",
        "    print(f\"Data has been added to {file_path}\")\n",
        "\n",
        "add_results_to_json(data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0229065e07544c79ab4741e0077a1383": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a0e36b6cfca42d89bac31eae8d6b605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "192fb41a76b94130b6299197c719b70c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235fc9caede94554a858295dd4647d56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253c5509188b44c7ab8aa1f6ea2003d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d4ab6496f5415db5dff0a992f83c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcb73195ff8e4f4582519743df4b45bb",
            "placeholder": "​",
            "style": "IPY_MODEL_5771a9b761dc42bdb475bba3f511f42c",
            "value": " 300/? [21:10&lt;00:00,  3.39s/it]"
          }
        },
        "30187123bedc4d6c9ffadaa1dab27a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_192fb41a76b94130b6299197c719b70c",
            "placeholder": "​",
            "style": "IPY_MODEL_4fbb29aac32b477ba98645fd25680ca6",
            "value": " 300/0 [00:00&lt;00:00, 3685.04 examples/s]"
          }
        },
        "4fbb29aac32b477ba98645fd25680ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5771a9b761dc42bdb475bba3f511f42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6205a3c6d99e450e95bf035a8d07d56e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "712370bf3c4b469c99e77514335fcd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77eb02b005c84784abc8c26119c73b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52a45e839564994b6183ab6245dd241",
            "placeholder": "​",
            "style": "IPY_MODEL_e4e4fcb188a24acd904daa23caf38d79",
            "value": ""
          }
        },
        "7ec00d0734c94561a0a97be0f2de3f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77eb02b005c84784abc8c26119c73b7e",
              "IPY_MODEL_8a71567152674946b7192f06f7338e21",
              "IPY_MODEL_27d4ab6496f5415db5dff0a992f83c97"
            ],
            "layout": "IPY_MODEL_235fc9caede94554a858295dd4647d56"
          }
        },
        "8a71567152674946b7192f06f7338e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b571a574e58540bd87d7419f224fadbb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0229065e07544c79ab4741e0077a1383",
            "value": 1
          }
        },
        "9446b067785c415ab3c595ef2710d1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_253c5509188b44c7ab8aa1f6ea2003d1",
            "placeholder": "​",
            "style": "IPY_MODEL_0a0e36b6cfca42d89bac31eae8d6b605",
            "value": "Generating train split: "
          }
        },
        "a15dcd5f78fb41a3b3d6de0fedaa1184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6205a3c6d99e450e95bf035a8d07d56e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_712370bf3c4b469c99e77514335fcd6d",
            "value": 1
          }
        },
        "b571a574e58540bd87d7419f224fadbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dcb73195ff8e4f4582519743df4b45bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e4fcb188a24acd904daa23caf38d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e99d05b19a5c4138aca173d07660e957": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9446b067785c415ab3c595ef2710d1de",
              "IPY_MODEL_a15dcd5f78fb41a3b3d6de0fedaa1184",
              "IPY_MODEL_30187123bedc4d6c9ffadaa1dab27a82"
            ],
            "layout": "IPY_MODEL_f015814a7f6b4a89a9f75827de143256"
          }
        },
        "f015814a7f6b4a89a9f75827de143256": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52a45e839564994b6183ab6245dd241": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
