{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9f8b7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random as rd\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b978b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def blanc_tune(summary, text, model, p_mask = 0.15, l_min = 4, N = 10):\n",
    "    words_in_summary = summary.split()\n",
    "    N_summary = len(words_in_summary)\n",
    "    N_mask = int(N_summary*p_mask)\n",
    "    set_tune = pd.DataFrame(columns = ['summary', 'text']) # change if needed when importing true dataset\n",
    "    for i in range(1, N + 1):\n",
    "        pos = [i for i, word in enumerate(words_in_summary) if len(word) >= l_min]\n",
    "        pos = rd.shuffle(pos)\n",
    "        while len(pos) != 0:\n",
    "            masked_summary = words_in_summary.copy()\n",
    "            for pos_to_mask in pos[:N_mask]:\n",
    "                masked_summary[pos_to_mask] = '<MASK>'\n",
    "                set_tune.loc[set_tune.shape[0]] = [masked_summary, text]\n",
    "    # add tuning of model (see below, from chatgpt, also look at homework 2)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649df27",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd7949",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ClozeDataset(Dataset):\n",
    "    def __init__(self, texts, summaries):\n",
    "        self.texts = texts\n",
    "        self.summaries = summaries\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'text': self.texts[idx], 'summary': self.summaries[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a45757",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6577af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloze_dataset = ClozeDataset(set_tune['text'], set_tune['summary'])\n",
    "cloze_dataloader = DataLoader(cloze_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training loop:\n",
    "for epoch in range(3):  # Replace with the desired number of epochs\n",
    "    model.train()\n",
    "    for batch in cloze_dataloader:\n",
    "        inputs = tokenizer(batch['text'], return_tensors='pt', padding=True, truncation=True, return_special_tokens_mask=True)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        labels = tokenizer(batch['summary'], return_tensors='pt', padding=True, truncation=True)['input_ids'].to(device)\n",
    "\n",
    "        # Ensure that labels are masked only at the [MASK] token positions\n",
    "        labels[inputs['input_ids'] == tokenizer.mask_token_id] = -100\n",
    "\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f97eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save the fine-tuned model\n",
    "model.save_pretrained('fine_tuned_bert_cloze_model')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
